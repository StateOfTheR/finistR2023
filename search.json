[
  {
    "objectID": "torch_test-brulee.html",
    "href": "torch_test-brulee.html",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "",
    "text": "L’idée ici est d’explorer la régression logistique en utilisant {torch} à l’aide du package {brulee}.\n\nlibrary(torch)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.7\n✔ dials        1.2.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.2     ✔ tibble       3.2.1\n✔ ggplot2      3.4.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.1\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(brulee)"
  },
  {
    "objectID": "torch_test-brulee.html#introduction",
    "href": "torch_test-brulee.html#introduction",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "",
    "text": "L’idée ici est d’explorer la régression logistique en utilisant {torch} à l’aide du package {brulee}.\n\nlibrary(torch)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.7\n✔ dials        1.2.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.2     ✔ tibble       3.2.1\n✔ ggplot2      3.4.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.1\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(brulee)"
  },
  {
    "objectID": "torch_test-brulee.html#exemple",
    "href": "torch_test-brulee.html#exemple",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "Exemple",
    "text": "Exemple\nOn reprend l’exemple détaillé l’an dernier pour la régression logistique, disponible à la page https://stateofther.github.io/finistR2022/autodiff.html.\n\nset.seed(45)\nn &lt;- 100\np &lt;- 3\nX &lt;- matrix(rnorm(n = n*p), ncol = p, nrow = n)\ntheta &lt;- rnorm(3) %&gt;% round(digits = 2)\nprobs &lt;- (X %*% theta) %&gt;% as.vector()\nY &lt;- purrr::rbernoulli(n = n, p = probs) + 0.\n\nWarning: `rbernoulli()` was deprecated in purrr 1.0.0.\n\nx &lt;- torch_tensor(X)\ny &lt;- torch_tensor(Y)\n\nlogistic_loss &lt;- function(theta, x, y) {\n  if (!is(theta, \"torch_tensor\")) {\n    stop(\"theta must be a torch tensor\")\n  }\n  odds &lt;- torch_matmul(x, theta)\n  log_lik &lt;- torch_dot(y, odds) - torch_sum(torch_log(1 + torch_exp(odds)))\n  return(-log_lik)\n}\nlogistic_loss(theta = torch_tensor(theta), x = x, y = y)\n\ntorch_tensor\n50.4573\n[ CPUFloatType{} ]\n\neval_loss &lt;- function(theta, verbose = TRUE) {\n  loss &lt;- logistic_loss(theta, x, y)\n  if (verbose) {\n    cat(paste(theta |&gt; as.numeric(), collapse=\", \"), \": \", as.numeric(loss), \"\\n\")\n  }\n  return(loss)\n}\neval_loss(torch_tensor(theta), verbose = FALSE)\n\ntorch_tensor\n50.4573\n[ CPUFloatType{} ]\n\ntheta_current &lt;- torch_tensor(rep(0, length(theta)), requires_grad = TRUE)\ntheta_optimizer &lt;- optim_rprop(theta_current)\nloss &lt;- eval_loss(theta_current, verbose = FALSE)\nloss$backward()\ntheta_optimizer$step()\n\nNULL\n\nnum_iterations &lt;- 100\nloss_vector &lt;- vector(\"numeric\", length = num_iterations)\nfor (i in 1:num_iterations) {\n  theta_optimizer$zero_grad()\n  loss &lt;- eval_loss(theta_current, verbose = FALSE)\n  loss$backward()\n  theta_optimizer$step()\n  loss_vector[i] &lt;- loss %&gt;% as.numeric()\n}\ndplyr::tibble(\n  torch = theta_current |&gt; as.numeric(),\n  glm   = glm(Y ~ 0 + X, family = \"binomial\") |&gt; coefficients()\n)\n\n# A tibble: 3 × 2\n   torch    glm\n   &lt;dbl&gt;  &lt;dbl&gt;\n1  1.79   1.79 \n2 -1.04  -1.04 \n3 -0.973 -0.973"
  },
  {
    "objectID": "torch_test-brulee.html#tidymodels",
    "href": "torch_test-brulee.html#tidymodels",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "Tidymodels",
    "text": "Tidymodels\nIl est possible d’effectuer une régression logistique à l’aide de plusieurs engine dans {tidymodels} :\n\nshow_engines(\"logistic_reg\")\n\n# A tibble: 7 × 2\n  engine    mode          \n  &lt;chr&gt;     &lt;chr&gt;         \n1 glm       classification\n2 glmnet    classification\n3 LiblineaR classification\n4 spark     classification\n5 keras     classification\n6 stan      classification\n7 brulee    classification\n\n\nOn vérifie qu’on retrouve bien les mêmes coefficient en utilisant le package {glm} dans {tidymodels} pour effectuer notre régression logistique :\n\nset.seed(20)\ndata_df &lt;- data.frame(Y = as.factor(Y), X = X)\nlogistic_reg(engine = \"glm\") %&gt;% \n  fit(Y ~ 0 + X.1 + X.2 + X.3, family = \"binomial\", data = data_df) %&gt;% \n  extract_fit_engine() %&gt;% # besoin d'extraire l'objet lm\n  coef()\n\n       X.1        X.2        X.3 \n 1.7914697 -1.0379660 -0.9728552 \n\n\nLe package {brulee} de l’univers tidymodels propose différents modèles classiques (réseau de neurones, régression logistique, régression linéaire, régression multinomiale) via l’infrastructure torch. La liste des loss disponibles dans le package :\n\nls(pattern = \"loss$\", envir = asNamespace(\"torch\"))\n\n [1] \"nn_adaptive_log_softmax_with_loss\"    \n [2] \"nn_bce_loss\"                          \n [3] \"nn_bce_with_logits_loss\"              \n [4] \"nn_cosine_embedding_loss\"             \n [5] \"nn_cross_entropy_loss\"                \n [6] \"nn_ctc_loss\"                          \n [7] \"nn_hinge_embedding_loss\"              \n [8] \"nn_kl_div_loss\"                       \n [9] \"nn_l1_loss\"                           \n[10] \"nn_loss\"                              \n[11] \"nn_margin_ranking_loss\"               \n[12] \"nn_mse_loss\"                          \n[13] \"nn_multi_margin_loss\"                 \n[14] \"nn_multilabel_margin_loss\"            \n[15] \"nn_multilabel_soft_margin_loss\"       \n[16] \"nn_nll_loss\"                          \n[17] \"nn_poisson_nll_loss\"                  \n[18] \"nn_smooth_l1_loss\"                    \n[19] \"nn_soft_margin_loss\"                  \n[20] \"nn_triplet_margin_loss\"               \n[21] \"nn_triplet_margin_with_distance_loss\" \n[22] \"nn_weighted_loss\"                     \n[23] \"nnf_cosine_embedding_loss\"            \n[24] \"nnf_ctc_loss\"                         \n[25] \"nnf_hinge_embedding_loss\"             \n[26] \"nnf_l1_loss\"                          \n[27] \"nnf_margin_ranking_loss\"              \n[28] \"nnf_mse_loss\"                         \n[29] \"nnf_multi_margin_loss\"                \n[30] \"nnf_multilabel_margin_loss\"           \n[31] \"nnf_multilabel_soft_margin_loss\"      \n[32] \"nnf_nll_loss\"                         \n[33] \"nnf_poisson_nll_loss\"                 \n[34] \"nnf_smooth_l1_loss\"                   \n[35] \"nnf_soft_margin_loss\"                 \n[36] \"nnf_triplet_margin_loss\"              \n[37] \"nnf_triplet_margin_with_distance_loss\"\n[38] \"torch__ctc_loss\"                      \n[39] \"torch__cudnn_ctc_loss\"                \n[40] \"torch__use_cudnn_ctc_loss\"            \n[41] \"torch_cosine_embedding_loss\"          \n[42] \"torch_cross_entropy_loss\"             \n[43] \"torch_ctc_loss\"                       \n[44] \"torch_hinge_embedding_loss\"           \n[45] \"torch_huber_loss\"                     \n[46] \"torch_l1_loss\"                        \n[47] \"torch_margin_ranking_loss\"            \n[48] \"torch_mse_loss\"                       \n[49] \"torch_multi_margin_loss\"              \n[50] \"torch_multilabel_margin_loss\"         \n[51] \"torch_nll_loss\"                       \n[52] \"torch_poisson_nll_loss\"               \n[53] \"torch_smooth_l1_loss\"                 \n[54] \"torch_soft_margin_loss\"               \n[55] \"torch_triplet_margin_loss\"            \n\n\nOn va regarder ici comment faire la même régression logistique que précédemment. Il est possible de spécifier soit avec les données sous forme de data.frame soit en utilisant des matrices. Deux procédures d’optimisation sont disponibles : ‘LBFGS’ et ‘SGD’.\nA noter qu’il n’est pas possible de spécifier un modèle sans intercept, ni avec 0+ ni avec -1.\n\nreg_log_brulee2 &lt;- brulee_logistic_reg(x = as.matrix(X), y = as.factor(Y),\n                         epochs = num_iterations, optimizer = \"SGD\", validation = 0)\n\nreg_log_brulee1 &lt;- brulee_logistic_reg(Y ~ X.1 + X.2 + X.3, data = data_df,\n                         epochs = num_iterations, optimizer = \"SGD\", validation = 0)\n\nEn théorie il est possible récupérer les coefficients du modèle ajusté avec la méthode coef en spécifiant l’epoch désirée. Si epoch = NULL la meilleure epoch est choisie.\n\nreg_log_brulee2 %&gt;% coef()\n\n\nreg_log_brulee2$estimates[[100]]\n\n$fc1.weight\n          [,1]       [,2]      [,3]\n[1,] -1.096883  0.5906312  1.178145\n[2,]  1.788497 -0.9432783 -1.099946\n\n$fc1.bias\n[1]  1.451596 -1.311797"
  },
  {
    "objectID": "torch_R_PLN.html",
    "href": "torch_R_PLN.html",
    "title": "PLN version R",
    "section": "",
    "text": "On charge le jeu de données oaks contenu dans PLNmodels\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\ndata(oaks)\n\nPour référence, on optimise avec le package dédié (qui utilise le backend NLOpt, une bilbiothèque C++ d’optimisation non linéaire. La variance CCSQA, utilisant les gradients explicites, est utilisée).\n\nsystem.time(myPLN_nlopt &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks))\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  4.415   1.346   2.983 \n\n\n\n\n\nOn définit une simple classe avec une routine d’optimisation utilisant Rprop et l’auto-differentiation sur le critère à optimiser (l’ELBO = Expected Lower BOund).\n\nlibrary(torch)\nlibrary(R6)\n\nlog_stirling &lt;- function(n_){\n  n_ &lt;- n_+ (n_==0)\n  torch_log(torch_sqrt(2*pi*n_)) + n_*log(n_/exp(1))\n}\n\nPLN &lt;-\n  R6Class(\"PLN\",\n    public = list(\n      Y = NULL,\n      O = NULL,\n      X = NULL,\n      n = NULL,\n      p = NULL,\n      d = NULL,\n      M = NULL,\n      S = NULL,\n      A = NULL,\n      B = NULL,\n      Sigma = NULL,\n      Omega = NULL,\n      loglik = NULL,\n      ELBO_list = NULL,\n\n      ## Constructor\n      initialize = function(Y, O, X){\n        self$Y &lt;- torch_tensor(Y)\n        self$O &lt;- torch_tensor(O)\n        self$X &lt;- torch_tensor(X)\n        self$n &lt;- nrow(Y)\n        self$p &lt;- ncol(Y)\n        self$d &lt;- ncol(X)\n        ## Variational parameters\n        self$M &lt;- torch_zeros(self$n, self$p, requires_grad = TRUE)\n        self$S &lt;- torch_ones(self$n , self$p, requires_grad = TRUE)\n        ## Model parameters\n        self$B &lt;- torch_full(c(self$d, self$p), -8.0, requires_grad = TRUE)\n        self$Sigma &lt;- torch_eye(self$p)\n        self$Omega &lt;- torch_eye(self$p)\n        ## Monitoring\n        self$ELBO_list &lt;- c()\n      },\n\n      get_Sigma = function(M, S){\n        1/self$n * (torch_mm(torch_t(M),M) + torch_diag(torch_sum(S**2, dim = 1)))\n      },\n\n      get_ELBO = function(B, M, S, Omega){\n        S2 &lt;- torch_square(S)\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        self$n/2 * torch_logdet(Omega) -\n          torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2))\n      },\n    \n      get_loglik = function(B, M, S, Omega) {\n        S2 &lt;- S**2\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        J &lt;- self$n/2 * torch_logdet(Omega) + \n            .5 * self$n * self$p - torch_sum(log_stirling(self$Y)) -\n            torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2)) -\n          .5 * torch_sum(torch_mm(M, Omega) * M + S2 * torch_diag(Omega))\n        J\n      },\n\n      fit = function(N_iter, lr, tol = 1e-8, verbose = FALSE){\n        self$ELBO_list &lt;- double(length = N_iter)\n        optimizer &lt;- optim_rprop(c(self$B, self$M, self$S), lr = lr)\n        objective0 &lt;- Inf\n        for (i in 1:N_iter){\n          ## reinitialize gradients\n          optimizer$zero_grad()\n\n          ## compute current ELBO\n          loss &lt;- - self$get_ELBO(self$B, self$M, self$S, self$Omega)\n\n          ## backward propagation and optimization\n          loss$backward()\n          optimizer$step()\n\n          ## update parameters with close form\n          self$Sigma &lt;- self$get_Sigma(self$M, self$S)\n          self$Omega &lt;- torch_inverse(self$Sigma)\n\n          objective &lt;- -loss$item()\n          if(verbose && (i %% 50 == 0)){\n            pr('i : ', i )\n            pr('ELBO', objective)\n          }\n          self$ELBO_list[i] &lt;- objective\n          if (abs(objective0 - objective)/abs(objective) &lt; tol) {\n            self$ELBO_list &lt;- self$ELBO_list[1:i]\n            break\n          } else {\n            objective0 &lt;- objective\n          }\n        }\n        self$loglik &lt;- self$get_loglik(self$B, self$M, self$S, self$Omega)\n      },\n\n      plotLogNegElbo = function(from = 10){\n        plot(log(-self$ELBO_list[from:length(self$ELBO_list) ]), type = \"l\")\n      }\n    )\n  )\n\n\n\n\nOn crée une instance avec les données appropriées\n\nY &lt;- oaks$Abundance\nX &lt;- cbind(rep(1, nrow(Y)))\nO &lt;- log(oaks$Offset)\nmyPLN &lt;- PLN$new(Y = Y, O = O, X = X)\n\nTestons notre implémentation simple de PLN utilisant R-torch:\n\nsystem.time(myPLN$fit(1000, lr = 0.05, tol = 1e-9))\n\n   user  system elapsed \n  1.945   0.643   1.351 \n\nplot(-myPLN$ELBO_list, type=\"l\")\n\n\n\n\nEn fait, un backend torch est déjà disponible dans le package PLNmodels\n\nsystem.time(myPLN_torch &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks, control = PLN_param(backend = 'torch', config_optim = list(lr = 0.01))))\n\n\n Initialization...\n Adjusting a full covariance PLN model with torch optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  6.114   1.331   3.819 \n\n\nLes vraisemblances finales sont comparables\n\nmyPLN_nlopt$loglik\n\n[1] -32091.64\n\nmyPLN_torch$loglik\n\n[1] -32184.54\n\nmyPLN$loglik\n\ntorch_tensor\n-31816.1191\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward0&gt; ]\n\n\nAinsi que les paramètres\n\nplot(myPLN$B,\n     myPLN_nlopt$model_par$B, \n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Regression coefficients\"); abline(0, 1, col = \"red\")\nplot(myPLN_torch$model_par$Sigma,\n     myPLN$Sigma,\n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Covariance matrix\"); abline(0, 1, col = \"red\")"
  },
  {
    "objectID": "torch_R_PLN.html#pln-with-r-torch",
    "href": "torch_R_PLN.html#pln-with-r-torch",
    "title": "PLN version R",
    "section": "",
    "text": "On charge le jeu de données oaks contenu dans PLNmodels\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\ndata(oaks)\n\nPour référence, on optimise avec le package dédié (qui utilise le backend NLOpt, une bilbiothèque C++ d’optimisation non linéaire. La variance CCSQA, utilisant les gradients explicites, est utilisée).\n\nsystem.time(myPLN_nlopt &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks))\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  4.415   1.346   2.983 \n\n\n\n\n\nOn définit une simple classe avec une routine d’optimisation utilisant Rprop et l’auto-differentiation sur le critère à optimiser (l’ELBO = Expected Lower BOund).\n\nlibrary(torch)\nlibrary(R6)\n\nlog_stirling &lt;- function(n_){\n  n_ &lt;- n_+ (n_==0)\n  torch_log(torch_sqrt(2*pi*n_)) + n_*log(n_/exp(1))\n}\n\nPLN &lt;-\n  R6Class(\"PLN\",\n    public = list(\n      Y = NULL,\n      O = NULL,\n      X = NULL,\n      n = NULL,\n      p = NULL,\n      d = NULL,\n      M = NULL,\n      S = NULL,\n      A = NULL,\n      B = NULL,\n      Sigma = NULL,\n      Omega = NULL,\n      loglik = NULL,\n      ELBO_list = NULL,\n\n      ## Constructor\n      initialize = function(Y, O, X){\n        self$Y &lt;- torch_tensor(Y)\n        self$O &lt;- torch_tensor(O)\n        self$X &lt;- torch_tensor(X)\n        self$n &lt;- nrow(Y)\n        self$p &lt;- ncol(Y)\n        self$d &lt;- ncol(X)\n        ## Variational parameters\n        self$M &lt;- torch_zeros(self$n, self$p, requires_grad = TRUE)\n        self$S &lt;- torch_ones(self$n , self$p, requires_grad = TRUE)\n        ## Model parameters\n        self$B &lt;- torch_full(c(self$d, self$p), -8.0, requires_grad = TRUE)\n        self$Sigma &lt;- torch_eye(self$p)\n        self$Omega &lt;- torch_eye(self$p)\n        ## Monitoring\n        self$ELBO_list &lt;- c()\n      },\n\n      get_Sigma = function(M, S){\n        1/self$n * (torch_mm(torch_t(M),M) + torch_diag(torch_sum(S**2, dim = 1)))\n      },\n\n      get_ELBO = function(B, M, S, Omega){\n        S2 &lt;- torch_square(S)\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        self$n/2 * torch_logdet(Omega) -\n          torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2))\n      },\n    \n      get_loglik = function(B, M, S, Omega) {\n        S2 &lt;- S**2\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        J &lt;- self$n/2 * torch_logdet(Omega) + \n            .5 * self$n * self$p - torch_sum(log_stirling(self$Y)) -\n            torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2)) -\n          .5 * torch_sum(torch_mm(M, Omega) * M + S2 * torch_diag(Omega))\n        J\n      },\n\n      fit = function(N_iter, lr, tol = 1e-8, verbose = FALSE){\n        self$ELBO_list &lt;- double(length = N_iter)\n        optimizer &lt;- optim_rprop(c(self$B, self$M, self$S), lr = lr)\n        objective0 &lt;- Inf\n        for (i in 1:N_iter){\n          ## reinitialize gradients\n          optimizer$zero_grad()\n\n          ## compute current ELBO\n          loss &lt;- - self$get_ELBO(self$B, self$M, self$S, self$Omega)\n\n          ## backward propagation and optimization\n          loss$backward()\n          optimizer$step()\n\n          ## update parameters with close form\n          self$Sigma &lt;- self$get_Sigma(self$M, self$S)\n          self$Omega &lt;- torch_inverse(self$Sigma)\n\n          objective &lt;- -loss$item()\n          if(verbose && (i %% 50 == 0)){\n            pr('i : ', i )\n            pr('ELBO', objective)\n          }\n          self$ELBO_list[i] &lt;- objective\n          if (abs(objective0 - objective)/abs(objective) &lt; tol) {\n            self$ELBO_list &lt;- self$ELBO_list[1:i]\n            break\n          } else {\n            objective0 &lt;- objective\n          }\n        }\n        self$loglik &lt;- self$get_loglik(self$B, self$M, self$S, self$Omega)\n      },\n\n      plotLogNegElbo = function(from = 10){\n        plot(log(-self$ELBO_list[from:length(self$ELBO_list) ]), type = \"l\")\n      }\n    )\n  )\n\n\n\n\nOn crée une instance avec les données appropriées\n\nY &lt;- oaks$Abundance\nX &lt;- cbind(rep(1, nrow(Y)))\nO &lt;- log(oaks$Offset)\nmyPLN &lt;- PLN$new(Y = Y, O = O, X = X)\n\nTestons notre implémentation simple de PLN utilisant R-torch:\n\nsystem.time(myPLN$fit(1000, lr = 0.05, tol = 1e-9))\n\n   user  system elapsed \n  1.945   0.643   1.351 \n\nplot(-myPLN$ELBO_list, type=\"l\")\n\n\n\n\nEn fait, un backend torch est déjà disponible dans le package PLNmodels\n\nsystem.time(myPLN_torch &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks, control = PLN_param(backend = 'torch', config_optim = list(lr = 0.01))))\n\n\n Initialization...\n Adjusting a full covariance PLN model with torch optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  6.114   1.331   3.819 \n\n\nLes vraisemblances finales sont comparables\n\nmyPLN_nlopt$loglik\n\n[1] -32091.64\n\nmyPLN_torch$loglik\n\n[1] -32184.54\n\nmyPLN$loglik\n\ntorch_tensor\n-31816.1191\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward0&gt; ]\n\n\nAinsi que les paramètres\n\nplot(myPLN$B,\n     myPLN_nlopt$model_par$B, \n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Regression coefficients\"); abline(0, 1, col = \"red\")\nplot(myPLN_torch$model_par$Sigma,\n     myPLN$Sigma,\n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Covariance matrix\"); abline(0, 1, col = \"red\")"
  },
  {
    "objectID": "learnr.html",
    "href": "learnr.html",
    "title": "Nouveautés {learnr}",
    "section": "",
    "text": "Introduction\nNous allons ici présenter les nouveautés dans le packages {learnr} qui permet de créer des tutoriaux interactifs. {learnr} avait déjà été discuté durant la [semaine Finist’R 2020] (https://stateofther.github.io/finistR2020/teach_learnr_gradethis.html){.uri}\n{learnr} repose sur {shiny}. Le tutoriel est construit à partir d’un fichier Rmarkdown et peut être soit executé en local via le bouton run app soit en déployant le fichier sur un serveur Shiny.\nDepuis 2020 environ, il est possible d’intégrer un tutoriel {learnr] dans un package, ce qui rend interactif les classiques vignettes. Les nouvelles versions de Rstudio ont de plus inclus un bouton tutorial disponible dans le panel “Environnement, Git etc…”.\nL’idée est de partager un tutoriel facilement à une large audience et pour cela il est maintenant possible de les intégrer dans un package. Cela peut être intéressant autant pour des tutoriaux à destination d’étudiants mais également pour des tutoriaux à intégrer dans les packages que vous développez pour rendre l’initiation aux méthodes développées plus interactives qu’une vignette.\nL’avantage technique d’intégrer un tutoriel {learnr} dans un package est qu’il est alors possible, après avoir installé le package, d’executer le tutoriel en local sans avoir à le déployer sur un serveur Shiny. C’est donc gratuit et simple d’utilisation.\nA noter qu’il n’est pas nécessaire que le package contenant le tutoriel soit déposé sur le CRAN ou autre, qu’il contienne d’autres ficheirs que le tutoriel. Tout est donc possible.\nLes étapes pour créer un package contenant un tutoriel:\n\nSi le package n’est pas déjà créé:\n\n\nusethis::create_package(\"&lt;path_to_folder/name_of_package&gt;\")\n\n\nPour créer le fichier du tutoriel:\n\n\nusethis::use_tutorial(\"&lt;name-of-learnr-file&gt;\", \"&lt;Title You'd Like the User to See&gt;\")\n\n\nPuis dans Rstudio, cliquer sur “Build &gt; Install and Restart”.\nSi nécessaire, rajouter le package {gradethis} (noter la fonction de {usethis} spécifique pour les install de package en développement),\n\n\nusethis::use_dev_package(\"gradethis\")\n\n\nSi nécessaire, rajouter les packages présent sur le CRAN toujours avec {usethis}\n\n\nusethis::use_package(\"palmerpenguins\")\n\n\nSi nécessaire, éditer le fichier DESCRIPTION\nExécuter usethis::use_readme_rmd() pour rajouter un fichier README. puis compiler le tout.\nDéposer le package sur gitlab ou github puis partager le repository qui peut être installer avec les lignes de code suivantes:\n\n\ndevtools::install_github(\"&lt;your-repo&gt;/&lt;package-name&gt;\")\ndevtools::install_gitlab(\"&lt;your-repo&gt;/&lt;package-name&gt;\")\n\n\nLorsque le package est installé, aller dans le panel Tutorial dans Rstudio et c’est parti…\n\n\n\nRéférences\n\nhttps://rstudio.github.io/learnr/\nhttps://education.rstudio.com/blog/2020/09/delivering-learnr-tutorials-in-a-package/"
  },
  {
    "objectID": "issue_reprex.html",
    "href": "issue_reprex.html",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "",
    "text": "L’objectif de ce tuto est de présenter des conseils pour écrire une issue pour demander des améliorations ou soumettre des bugs dans un code déposé sur GitHub."
  },
  {
    "objectID": "issue_reprex.html#objectif",
    "href": "issue_reprex.html#objectif",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "",
    "text": "L’objectif de ce tuto est de présenter des conseils pour écrire une issue pour demander des améliorations ou soumettre des bugs dans un code déposé sur GitHub."
  },
  {
    "objectID": "issue_reprex.html#recommandations",
    "href": "issue_reprex.html#recommandations",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Recommandations",
    "text": "Recommandations\nLes recommandations proposées sur les dépôts des packages du tidyverse :\n\nInclure un exemple minimal reproductible, dit reprex.\n\nLire What is a reprex pour plus de détails.\n\nSi les données sont confidentielles, utiliser des données disponibles dans modeldata, simuler des données ou anonymiser les données.\nUtiliser des graines set.seed()\nVérifier sur les blogs ou forums que le problème n’a pas déjà été signalé ou réglé.\n\nD’autres recommandations sont proposées dans le cas d’utilisation de calculs parallèles."
  },
  {
    "objectID": "issue_reprex.html#structure-de-lissue",
    "href": "issue_reprex.html#structure-de-lissue",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Structure de l’issue",
    "text": "Structure de l’issue\n\nPrésenter en premier le problème (I’m having trouble with …)\nDonner un exemple reproductible dans un format\n\nUn bon exemple de report de bug #46."
  },
  {
    "objectID": "issue_reprex.html#exemple-reproductible-avec-le-package-reprex",
    "href": "issue_reprex.html#exemple-reproductible-avec-le-package-reprex",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Exemple reproductible avec le package {reprex}",
    "text": "Exemple reproductible avec le package {reprex}\nIl est possible de créer un exemple reproductible avec le package {reprex} qui produit une sortie bien formatée pour GitHub.\nSi le code est un peu long, faire un script, par exemple mon_probleme.R\nIl suffit ensuite d’utiliser la fonction reprex du package du même nom avec les options de son choix. Par exemple reprex(input = 'mon_probleme.R', session_info = TRUE).\nL’option session_info = TRUE permet de récuperer les informations sur notre session R.\nLa fonction génère un fichier markdown (mon_probleme.md) dans le cas de l’utilisation d’un script directement intégrable dans l’issue et ouvre également par défaut le rendu dans le viewer de RStudio ou un navigateur (peut se modifier avec l’argument html_preview = FALSE.\nPetit exemple plus court (sans utilisation de script extérieur) issu du package {reprex}\n\nlibrary(reprex)\nreprex(rbinom(3, size = 10, prob = 0.5), session_info = TRUE)\n\n✖ Install the styler package in order to use `style = TRUE`.\n\n\nℹ Non-interactive session, setting `html_preview = FALSE`.\n\n\nℹ Rendering reprex...\n\n\nCLIPR_ALLOW has not been set, so clipr will not run interactively"
  },
  {
    "objectID": "Intel_MKL.html",
    "href": "Intel_MKL.html",
    "title": "Intel MKL & Open Blas",
    "section": "",
    "text": "Nous allons d’abord installer les librairies Intel MKL (processeur Intel nécéssaire) & Open Blas. Ces deux librairies d’algèbre linéaire permettent de d’optimiser et/ou de paralléliser un certains nombre d’opérations algébriques, notamment le calcul matriciel.\n\nlibrary(tictoc)\n\nNous les testons avec un produit matriciel de 10000 x 10000\n\nsize &lt;- 10000\nmat &lt;- matrix(rnorm(size**2), size, size)\n\ntic()\nget_res &lt;- mat %*% mat\ntoc()\n\nAvant l’installation les librairies utilisées pour du calcul matriciel en R sont libblas.so.3.10.0 et liblapack.so.3.10.0 (on peut les voir avec la ligne)\n\nsessionInfo()\n\n\nInstallation sur Windows (seulement Intel MKL)\nLe plus simple est de recycler les librairies de microsoft R Open (ex version de R distribuée par microsoft qui utilisait la librairie MKL par défaut). Une fois microsoft R open installé, il suffit d’aller récupérer dans le répertoire :\nC:\\Program Files\\Microsoft\\R Open\\R-4.0.2\\bin\\x64\nles trois fichiers nommés\n\nRblas.dll\nRlapack.dll\nlibiomp5md.dll\n\net de les copier dans le répertoire\nC:\\Program Files\\R\\R-4.1.2\\bin\\x64\nConcrètement on remplace les deux fichiers faisant appel au librairies blas et lapack par des fichiers du même nom mais qui en pratique font implicitement appel à mkl.\n\n\nInstallation sur Ubuntu 22.04 (Intel MKL et Open Blas)\n\nIntel MKL\nsudo apt install intel-mkl\n\n\nOpen Blas\nsudo apt install libopenblas-base\n\n\nChangement de librairie\nPour changer la librairie Blas\nsudo update-alternatives --config libblas.so.3-x86_64-linux-gnu\nPour changer la librairie Lapack\nsudo update-alternatives --config liblapack.so.3-x86_64-linux-gnu\nDans les deux cas cela ouvre un menu montrant les différentes librairies disponibles.\n\n\n\nTest de la librairie\nUne fois instalée vérifier si les librairies sont bien référencées pour le calcul matriciel avec\n\nsessionInfo()\n\n\ntic()\nget_res &lt;- mat %*% mat\ntoc()\n\n\n\n\n\n\n\n\n\n\n\nSystème d’exploitation\nLibrary\nCPU\nBase R\nIntel MKL\n\n\n\n\nWindows 10\nIntel MKL\nIntel Xeon - 16 processeur logiques\n15 min\n7 secondes\n\n\nUbuntu 22.04\nIntel MKL\nIntel i7 - 8 processeur logiques\n5 min\nMoins de 1 min\n\n\nUbuntu 22.04\nOpen Blas\nIntel i7 - 8 processeur logiques\n5 min\n9-14 secondes"
  },
  {
    "objectID": "R_INLA.html",
    "href": "R_INLA.html",
    "title": "R INLA",
    "section": "",
    "text": "Présentation de la méthodologie INLA (integrated nested Laplace approximation) en utilisant les packages {INLA} et sa surcouche {inlabru}.\nL’approximation de Laplace intégrée et imbriquée (INLA) est une approche de l’inférence statistique pour les modèles de champs aléatoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et déterministe au MCMC qui était l’outil standard pour l’inférence de tels modèles. Le principal avantage de l’approche INLA par rapport à la MCMC est qu’elle est beaucoup plus rapide à calculer.\n{inlabru} est une surcouche du package INLA, qui facilite l’utilisation du package R {INLA} en simplifiant la syntaxe. Ce package intègre deux extensions :\n\nModèles de type GAM (pour intégrer des prédicteurs non linéaires)\nProcessus de Cox log-Gaussien pour modéliser des processus univariés et spatiaux basés sur des données de comptages.\n\nSources :\n\nhttps://www.r-inla.org/home\nhttps://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf\nhttps://sites.google.com/inlabru.org/inlabru/home\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "R_INLA.html#introduction",
    "href": "R_INLA.html#introduction",
    "title": "R INLA",
    "section": "",
    "text": "Présentation de la méthodologie INLA (integrated nested Laplace approximation) en utilisant les packages {INLA} et sa surcouche {inlabru}.\nL’approximation de Laplace intégrée et imbriquée (INLA) est une approche de l’inférence statistique pour les modèles de champs aléatoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et déterministe au MCMC qui était l’outil standard pour l’inférence de tels modèles. Le principal avantage de l’approche INLA par rapport à la MCMC est qu’elle est beaucoup plus rapide à calculer.\n{inlabru} est une surcouche du package INLA, qui facilite l’utilisation du package R {INLA} en simplifiant la syntaxe. Ce package intègre deux extensions :\n\nModèles de type GAM (pour intégrer des prédicteurs non linéaires)\nProcessus de Cox log-Gaussien pour modéliser des processus univariés et spatiaux basés sur des données de comptages.\n\nSources :\n\nhttps://www.r-inla.org/home\nhttps://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf\nhttps://sites.google.com/inlabru.org/inlabru/home\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "R_INLA.html#installation-de-inla",
    "href": "R_INLA.html#installation-de-inla",
    "title": "R INLA",
    "section": "Installation de INLA",
    "text": "Installation de INLA\n\n# Base de R INLA\ninstall.packages(\"INLA\",repos=c(getOption(\"repos\"),INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE)\n# inlabru wrapper\ninstall.packages(\"inlabru\")"
  },
  {
    "objectID": "R_INLA.html#utilisation",
    "href": "R_INLA.html#utilisation",
    "title": "R INLA",
    "section": "Utilisation",
    "text": "Utilisation\n\nExemple 1\n\nSetup\n\n# Chargement des packages\nlibrary(INLA)\nlibrary(inlabru)\nlibrary(lme4) # pour comparer avec l'approche frequentiste \nlibrary(ggplot2)\nlibrary(ggpolypath)\nlibrary(RColorBrewer)\nlibrary(geoR)\nlibrary(tidyverse)\n\nLe dataset awards contient le nombre de réussites (num_awards) en math (math) pour une classe de 200 élèves. La réponse mesurée étant un comptage, nous devons spécifier un modèle généralisé avec fonction de lien Poisson.\n\n# Chargement des donnees\nload(\"data/awards.RData\")\nhead(awards)\n\n  num_awards       prog math id\n1          0 Vocational   41  1\n2          0    General   41  2\n3          0 Vocational   44  3\n4          0 Vocational   42  4\n5          0 Vocational   40  5\n6          0    General   42  6\n\n\nLa fonction bru_options_set permet de fixer des options sur des paramètres spécifiques à INLA.\n\nbru_options_set(bru_verbose = TRUE,\n                control.compute = list(dic = TRUE, waic = TRUE))\n\nOn peut récupérer ces paramètres avec :\n\nbru_options_get()\n\n\n\nApplication\nNous expliquons le nombre de récompenses obtenues en fonction de la note en math suivant le modèle \\[Y_i\\overset{ind}{\\sim}\\mathcal{P}(\\exp(\\mu+\\alpha\\cdot x_i))\\,.\\]\n\n# Formulation du modele\ncmp1 &lt;- num_awards ~ math + 1\n# Application de la formule avec un modèle de Poisson\nfit.glm.bru &lt;- bru(cmp1, family = \"poisson\", data = awards)\n\niinla: Iteration 1 [max:1]\n\nsummary(fit.glm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.656, Running = 0.267, Post = 0.0318, Total = 0.955 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.086 0.010      0.067    0.086      0.105  0.086   0\nIntercept -5.349 0.591     -6.508   -5.349     -4.191 -5.349   0\n\nDeviance Information Criterion (DIC) ...............: 384.07\nDeviance Information Criterion (DIC, saturated) ....: 208.02\nEffective number of parameters .....................: 1.99\n\nWatanabe-Akaike information criterion (WAIC) ...: 384.48\nEffective number of parameters .................: 2.35\n\nMarginal log-Likelihood:  -204.02 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nComparaison avec un GLM\n\ncmp2 &lt;- num_awards ~ math\nfit2.glm &lt;- glm(cmp2, family=\"poisson\", data = awards)\nsummary(fit2.glm)\n\n\nCall:\nglm(formula = cmp2, family = \"poisson\", data = awards)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.333532   0.591261  -9.021   &lt;2e-16 ***\nmath         0.086166   0.009679   8.902   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 204.02  on 198  degrees of freedom\nAIC: 384.08\n\nNumber of Fisher Scoring iterations: 6\n\n\nLes réponses sont proches.\n\n\nIntégration d’un effet aléatoire\nPour prendre en compte le problème classique de surdispersion dans les données de comptages, il peut être intéressant de rajouter un effet aléatoire de la manière suivante.\n\\[Y_i\\overset{ind}{\\sim}\\mathcal{P}(\\exp(\\mu+\\alpha\\cdot x_i+E_i)) \\quad \\text{avec}\\quad E_i\\overset{ind}{\\sim}\\mathcal{N}(0,\\sigma^2).\\]\n\ncmp3 &lt;- num_awards ~ math + 1 + rand.eff(map = 1:200, model = \"iid\", n = 200)\n\nfit3.glmm.bru &lt;- bru(cmp3, family = \"poisson\", data = awards)\n\nWarning in inlabru:::component.character(\"rand.eff\", map = 1:200, model =\n\"iid\", : Use of 'map' is deprecated and may be disabled; use 'main' instead.\n\n\niinla: Iteration 1 [max:1]\n\nsummary(fit3.glmm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nrand.eff: main = iid(1:200), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.42, Running = 0.246, Post = 0.0584, Total = 0.725 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.086 0.010      0.067    0.086      0.105  0.086   0\nIntercept -5.349 0.591     -6.509   -5.349     -4.190 -5.349   0\n\nRandom effects:\n  Name    Model\n    rand.eff IID model\n\nModel hyperparameters:\n                           mean       sd 0.025quant 0.5quant 0.975quant   mode\nPrecision for rand.eff 19903.65 19900.90     564.00 13861.13   74196.26 187.83\n\nDeviance Information Criterion (DIC) ...............: 384.03\nDeviance Information Criterion (DIC, saturated) ....: 207.97\nEffective number of parameters .....................: 2.00\n\nWatanabe-Akaike information criterion (WAIC) ...: 384.47\nEffective number of parameters .................: 2.38\n\nMarginal log-Likelihood:  -204.09 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nComparaison avec l’approche fréquentiste\n\ncmp4&lt;- num_awards ~ math + (1|id)\nfit4.glmm&lt;-glmer(cmp4, family = poisson, data = awards)\nsummary(fit4.glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: num_awards ~ math + (1 | id)\n   Data: awards\n\n     AIC      BIC   logLik deviance df.resid \n   381.2    391.1   -187.6    375.2      197 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.1653 -0.5518 -0.3760  0.3900  2.9242 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.3257   0.5707  \nNumber of obs: 200, groups:  id, 200\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.63163    0.70476  -7.991 1.34e-15 ***\nmath         0.08861    0.01161   7.634 2.28e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nmath -0.982\n\n\nOn remarque que les résultats sont un peu moins comparables. Pour se rapprocher de glmer(), on peut modifier la loi a priori sur l’effet aléatoire.\n\ncmp5 &lt;- num_awards ~ math + 1 + rand.eff(map = 1:200, model = \"iid\", n = 200,\n                                                 hyper=list(prec=list(param=c(10,0.1),\n                                                                      prior=\"pc.prec\")))\nfit5.glmm.bru &lt;- bru(cmp5, family = \"poisson\", data = awards )\n\nWarning in inlabru:::component.character(\"rand.eff\", map = 1:200, model =\n\"iid\", : Use of 'map' is deprecated and may be disabled; use 'main' instead.\n\n\niinla: Iteration 1 [max:1]\n\nsummary(fit5.glmm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nrand.eff: main = iid(1:200), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.382, Running = 0.228, Post = 0.0511, Total = 0.661 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.090 0.012      0.067    0.089      0.113  0.089   0\nIntercept -5.651 0.692     -7.039   -5.641     -4.321 -5.621   0\n\nRandom effects:\n  Name    Model\n    rand.eff IID model\n\nModel hyperparameters:\n                       mean   sd 0.025quant 0.5quant 0.975quant mode\nPrecision for rand.eff 6.97 8.93       1.58     4.10      27.94 2.69\n\nDeviance Information Criterion (DIC) ...............: 380.37\nDeviance Information Criterion (DIC, saturated) ....: 204.31\nEffective number of parameters .....................: 29.47\n\nWatanabe-Akaike information criterion (WAIC) ...: 381.65\nEffective number of parameters .................: 26.02\n\nMarginal log-Likelihood:  -204.62 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\n\nExemple 2\nDans le jeu de données gorillas on cherche à comprendre la répartition de communautés de gorilles dans une région donnée en fonction de facteurs (végétations) ou de variable continue (altitude).\n\ndata(gorillas, package = \"inlabru\")\n\nOn importe l’objet liste gorillas qui contient 4 sous-listes contenant les localisations d’habitats de gorilles (nests), le maillage de la zone d’intérêt (mesh), la frontière du domaine (boundary) et les variables explicatives (gcov).\n\nnests &lt;- gorillas$nests\nmesh &lt;- gorillas$mesh\nboundary &lt;- gorillas$boundary\ngcov &lt;- gorillas$gcov\n\nsummary(gcov$vegetation)\n\nObject of class SpatialPixelsDataFrame\nCoordinates:\n       min      max\nx 580.1599 586.2320\ny 673.8742 679.0378\nIs projected: TRUE \nproj4string :\n[+proj=utm +zone=32 +datum=WGS84 +units=km +no_defs]\nNumber of points: 39600\nGrid attributes:\n  cellcentre.offset   cellsize cells.dim\nx          580.1737 0.02760054       220\ny          673.8885 0.02868664       180\nData attributes:\n      vegetation   \n Colonising:   48  \n Disturbed :23606  \n Grassland : 7001  \n Primary   : 7725  \n Secondary :  788  \n Transition:  432  \n\n\nLa construction du maillage peut se faire avec les fonctions de {INLA}:\n\ninla.mesh.2d(),\ninla.mesh.create(),\ninla.mesh.1d(),\ninla.mesh.basis(),\ninla.spde2.pcmatern().\n\nvoir la vignette suivante pour quelques exemples: https://inlabru-org.github.io/inlabru/articles/random_fields_2d.html.\n\nVisualisation des données gorilles\n\nggplot() +\n  gg(gcov$vegetation) +\n  gg(boundary) +\n  gg(nests, color = \"white\", cex = 0.5) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\n\nggplot() +\n  gg(gcov$vegetation) +\n  gg(mesh) +\n  gg(boundary) +\n  gg(nests, color = \"white\", cex = 0.5) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\nLes graphiques ci-dessus permettent de visualiser les différentes types de végétaions ainsi que les localisations d’habitats de gorilles dans la zone d’étude. Il est également possible de rajouter le maillage construit sur la zone. {inlabru} propose la fonction gg() permettant avac la grammaire ggplot2 de rajouter les différentes couches d’informations.\n\n\nModèle 1\nOn peut supposer un processus ponctuel spatial d’intensité \\[\\lambda(x,y)=\\exp(\\alpha_i(x,y))\\] où \\(\\alpha\\) est un paramètre correspondant à un type de végétation (modélisation factor full sans intercept donc).\n\ncomp1 &lt;- coordinates ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1\ncomp1alt &lt;- coordinates ~ vegetation(gcov$vegetation, model = \"factor_contrast\") + 1\n\nPour construire un modèle expliquant les comptages de gorilles avec leurs répartitions dans la zone d’étude et prenant en compte les types de végétations, nous définissons la formule avec:\n\ncoordinates() la fonction de {sp} de récupération des coordonnées des habitats dans l’objet nests\nvegetation sera le mot utilisé dans les sorties du modèle faisant référence à la variable explicative gcov$vegetation (possible d’écrire le mot que l’on veut…)\nmodel = \"factor_full\" est pour indiquer que la variable explicative est un facteur. Il est possible d’utiliser “factor_full”, “factor_contrast” etc… suivant les types de contraintes que l’on souhaite appliquer au modèle. “factor_full” indique estimations de toutes les modalités mais il faut alors supprimer l’intercept afin d’être dans un cas identifiable.\n\nAprès avoir défini la formule du modèle, on estime les paramètres en utilisant la fonction lgcp() qui permet de modéliser un processus log-normalisé de Cox. Cette fonction est une surcouche de la fonction de base bru().\nLe LGCP est un modèle probabiliste de processus ponctuel observé dans un tissu spatial ou temporel.\n\nfit1 &lt;- lgcp(components = comp1, # formule du modèle\n             data = nests,       # data set\n             samplers = boundary,  # frontière de la zone d'étude\n             domain = list(coordinates = mesh) # maillage de la zone\n             )\n\niinla: Iteration 1 [max:1]\n\n\nfit1 estime l’intensité des présences de gorilles dans la zone d’étude. Il est alors possible de représenter l’intensité moyenne de ces habitats:\n\npred.df &lt;- fm_pixels(mesh, mask = boundary, format = \"sp\")\nint1 &lt;- predict(fit1, pred.df, ~ exp(vegetation))\n\nggplot() +\n  gg(int1) +\n  gg(boundary, alpha = 0, lwd = 2) +\n  gg(nests, color = \"DarkGreen\") +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\nPour visualiser les résultats du modèle, nous utilisons la fonction predict() (sans oublier de passer à l’exponentielle) et fm_pixels() qui en prenant la zone d’étude (mesh + frontière) crée l’objet spatial adéquat.\nNous remarquons que les intensités sont les plus fortes dans la végétation Primaire, ce qui est logique. Ici, l’intensité représente le nombre d’habitats de gorilles par unité de surface. Attention donc à comment vous définissez les coordonnées de vos zones d’études.\nEn utilisant les fonctions fm_int()et predict() nous allons tenter d’estimer les abondances moyennes sachant que nous savons qu’il y a 647 habitats en réalité:\n\nips &lt;- fm_int(mesh, boundary)\nLambda1 &lt;- predict(fit1, ips, ~ sum(weight * exp(vegetation)))\nLambda1\n\n      mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err\n1 644.2837 23.93294 597.2709 642.6015 691.0567 642.6015        2.393294\n  sd.mc_std_err\n1       1.56008\n\n\n\n# Calcul de la surface de la zone\nsum(ips$weight) # some des surfaces de chaque triangle du mesh\n\n[1] 19.87366\n\nsf::st_area(sf::st_as_sf(boundary)) # surface totale \n\n19.87366 [km^2]\n\n\n\n\nModèle avec utilisation SPDE\nDans cette section, nous allons essayre d’expliquer la répartition des habitats en rajoutant au facteur vegetation une modélisation SPDE (Stochastic partial differential equations). Il faut pour cela compléter la définition du maillage par l’ajout d’une structure de Matern en utilisant la fonction {INLA} inla.spde2.pcmatern() puis réécrire la définition de la forule du modèle INLA. Le modèle intègre alors un champ gaussien avec covariance de Matérn. \\[\\lambda(x,y)=\\exp(\\alpha_i(x,y)+\\xi(x,y))\\] avec \\(\\xi\\) suivant un champ gaussien.\n\npcmatern &lt;- inla.spde2.pcmatern(mesh,\n  prior.sigma = c(0.1, 0.01),\n  prior.range = c(0.1, 0.01)\n)\n\ncomp2 &lt;- coordinates ~\n            -1 +\n            vegetation(gcov$vegetation, model = \"factor_full\") +\n            elevation(gcov$elevation) +\n            mySmooth(coordinates, model = pcmatern)\n\nfit2 &lt;- lgcp(components = comp2, \n             data = nests, \n             samplers = boundary, \n             domain = list(coordinates = mesh))\n\niinla: Iteration 1 [max:1]\n\n\nOn représente l’intensité médiane de la surface:\n\nint2 &lt;- predict(fit2, pred.df, ~ exp(mySmooth + vegetation), n.samples = 1000)\n\nggplot() +\n  gg(int2, aes(fill = q0.025)) +\n  gg(boundary, alpha = 0, lwd = 2) +\n  gg(nests) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\net l’intensité intégrée attendue (moyenne des abondances):\n\nLambda2 &lt;- predict(fit2,\n                   fm_int(mesh, boundary),\n                   ~ sum(weight * exp(mySmooth + vegetation)))\n\nLambda2\n\n       mean     sd     q0.025      q0.5   q0.975    median mean.mc_std_err\n1 0.7062216 2.0737 0.01279027 0.1349317 4.466578 0.1349317         0.20737\n  sd.mc_std_err\n1     0.7864979\n\n\nLook at the contributions to the linear predictor from the SPDE and from vegetation.\nExaminons les contributions au prédicteur linéaire de la partie SPDE et de celle due à la végatation.\nLa fonction scale_fill_gradientn() définit l’échelle pour la légende du graphique. Dans cet exemple, on le définit tel que cela prenne en compte toute la gamme de valeurs des 3 prédicteurs linéaires. Par défaut, ce sont les médianes qui sont représentées.\n\nlp2 &lt;- predict(fit2, \n               pred.df, ~ list(\n                        smooth_veg = (mySmooth + vegetation + elevation),\n                        not_smooth = (vegetation + elevation),\n                        smooth = (mySmooth),\n                        veg = (vegetation),\n                        ele = (elevation)\n              ))\n\nlprange &lt;- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median, lp2$ele$median, lp2$not_smooth$median)\n\nplot.lp2 &lt;- ggplot() +\n  gg(lp2$not_smooth) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"vegetation + elevation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.spde &lt;- ggplot() +\n  gg(lp2$smooth) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"mySmooth\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.veg &lt;- ggplot() +\n  gg(lp2$veg) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"vegetation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.ele &lt;- ggplot() +\n  gg(lp2$ele) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"elevation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nmultiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, plot.lp2.ele, cols = 2)\n\n\n\n\n\n\n\nExemple 3\nNous nous intéressons à un jeu de données concernant la prévalence de la malaria en Gambie (disponible dans le package {geoR}). Cet exemple est repris du livre “Spatial and Spatio-temporal Bayesian Models with R-INLA.\n\ndata(gambia, package = \"geoR\")\n# les coordonnées correspondent au village où se trouve les enfants\n# create one index for each of the 65 villages\nvillage_index &lt;- unite(gambia, col = \"lon_lat\", sep = \"_\", \"x\", \"y\") %&gt;% \n  pull(\"lon_lat\") %&gt;% \n  factor(labels = 1:65)\ngambia &lt;- gambia %&gt;%\n  add_column(village_index) \n\nOn transforme les données et on transforme le jeu de données en type {SpatialPointsDataFrame}.\n\ngambia &lt;- gambia %&gt;%\n  mutate(x = x * 0.001, # to km\n         y = y * 0.001, # to km\n         age = age / 365) \ncoordinates(gambia) &lt;- c(\"x\", \"y\") \nclass(gambia)\n\n[1] \"SpatialPointsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nOn définit ensuite un maillage pour le champ spatial avec un maillage plus fin dans la zone où il y a des observations et qui “déborde” avec un maillage plus grossier.\n\nhull = inla.nonconvex.hull(gambia,convex = -0.1)\ngambia_mesh &lt;- inla.mesh.2d(boundary = hull,\n                            offset = c(30, 60), max.edge = c(20,40))\n\nplot(gambia_mesh,main=\"\",asp=1)\npoints(gambia,pch=21,bg=\"white\",cex=1.5,lwd=1.5)\n\n\n\n\nOn définit à partir du maillage le champ spatial spde qui correspond à un champ spatial gaussien avec une covariance Matérn. Nous considérons les lois a priori par défaut sur les paramètres de variance et de portée du champ spatial.\n\ngambia_spde &lt;- inla.spde2.matern(mesh = gambia_mesh, alpha=2)\n\nTout est prêt pour définir le modèle à ajuster et son estimation : Pour l’enfant \\(j\\) du village \\(i\\), nous supposons \\[Y_{ij}|V_i\\overset{ind}{\\sim}b(p_{ij})\\] avec \\[S_i\\sim GRF, \\quad V_i\\overset{ind}{\\sim}\\mathcal{N}(0,\\sigma^2_V)\\] et \\[p_{ij}=\\mu+\\beta_1 \\cdot treated_{ij}+\\beta_2 \\cdot netuse_{ij}+\\beta_3 \\cdot age_{ij}+\\beta_4 \\cdot green_{ij}+\\beta_5\\cdot phc_{ij}+S_i+V_i.\\]\n\nformula = pos ~ -1 +\n  Intercept(1) +\n  treated +\n  netuse +\n  age +\n  green +\n  phc +\n   spatial_field(coordinates, model=gambia_spde) +\n  village(village_index, model=\"iid\")\n\nfit &lt;- bru(components = formula,\n           data = gambia,\n           family= \"binomial\"\n)\n\niinla: Iteration 1 [max:1]\n\nsummary(fit)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\ntreated: main = linear(treated), group = exchangeable(1L), replicate = iid(1L)\nnetuse: main = linear(netuse), group = exchangeable(1L), replicate = iid(1L)\nage: main = linear(age), group = exchangeable(1L), replicate = iid(1L)\ngreen: main = linear(green), group = exchangeable(1L), replicate = iid(1L)\nphc: main = linear(phc), group = exchangeable(1L), replicate = iid(1L)\nspatial_field: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L)\nvillage: main = iid(village_index), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'binomial'\n    Data class: 'SpatialPointsDataFrame'\n    Predictor: pos ~ .\nTime used:\n    Pre = 0.83, Running = 1.55, Post = 0.106, Total = 2.49 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nIntercept -1.295 1.282     -3.733   -1.327      1.312 -1.398   0\ntreated   -0.387 0.201     -0.782   -0.387      0.006 -0.387   0\nnetuse    -0.347 0.157     -0.655   -0.347     -0.039 -0.347   0\nage        0.246 0.044      0.159    0.246      0.332  0.246   0\ngreen      0.012 0.025     -0.038    0.012      0.060  0.014   0\nphc       -0.323 0.227     -0.772   -0.322      0.122 -0.321   0\n\nRandom effects:\n  Name    Model\n    spatial_field SPDE2 model\n   village IID model\n\nModel hyperparameters:\n                          mean    sd 0.025quant 0.5quant 0.975quant  mode\nTheta1 for spatial_field  1.32 0.836     -0.172     1.26       3.10  1.04\nTheta2 for spatial_field -2.50 0.708     -4.006    -2.45      -1.24 -2.27\nPrecision for village     4.83 2.423      1.684     4.32      10.97  3.45\n\nDeviance Information Criterion (DIC) ...............: 2326.24\nDeviance Information Criterion (DIC, saturated) ....: 2326.24\nEffective number of parameters .....................: 48.46\n\nWatanabe-Akaike information criterion (WAIC) ...: 2325.39\nEffective number of parameters .................: 46.41\n\nMarginal log-Likelihood:  -1227.34 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\nOn peut accéder aux distributions marginales des effets aléatoires et des hyperparamètres :\n\nfit$summary.random \nfit$summary.hyperpar\n\nNous pouvons tracer les distributions a posteriori marginales des effets, par exemple :\n\nage &lt;- fit$marginals.fixed[[4]]\nggplot(data.frame(inla.smarginal(age)), aes(x, y)) +\n  geom_line() +\n  theme_bw()\n\n\n\nrfprecision &lt;- fit$marginals.hyperpar$`Precision for village`\nggplot(data.frame(inla.smarginal(rfprecision)), aes(x, y)) +\n  geom_line() +\n  theme_bw()\n\n\n\n\nNous essayons de représenter le champ gaussien latent\n\ndomain_lims &lt;- apply(hull$loc, 2, range)\ngrd_dims &lt;- round(c(x = diff(domain_lims[, 1]), \n                    y = diff(domain_lims[, 2])) / 1)\nmesh_proj &lt;- fm_evaluator(\n  gambia_mesh,\n  xlim = domain_lims[, 1], ylim = domain_lims[, 2], dims = grd_dims\n)\n\nspatial_field &lt;- data.frame(\n  median = inla.link.invlogit(fit$summary.random$spatial_field$\"0.5quant\"),\n  range95 = (inla.link.invlogit(fit$summary.random$spatial_field$\"0.975quant\") -\n               inla.link.invlogit(fit$summary.random$spatial_field$\"0.025quant\"))\n)\n\npredicted_field &lt;- fm_evaluate(mesh_proj, spatial_field) %&gt;%\n  as.matrix() %&gt;%\n  as.data.frame() %&gt;%\n  bind_cols(expand.grid(x = mesh_proj$x, y = mesh_proj$y), .) %&gt;%\n  pivot_longer(cols = -c(\"x\", \"y\"),\n               names_to = \"metric\",\n               values_to = \"value\")\n# Median\nggplot(filter(predicted_field, metric == \"median\")) +\n  aes(x = x, y = y, fill = value) +\n  geom_raster() +\n  scale_fill_viridis_c()\n\n\n\n# 95% range\nggplot(filter(predicted_field, metric == \"range95\")) +\n  aes(x = x, y = y, fill = value) +\n  geom_raster() +\n  scale_fill_viridis_c()"
  },
  {
    "objectID": "R_INLA.html#references",
    "href": "R_INLA.html#references",
    "title": "R INLA",
    "section": "References",
    "text": "References\n\nhttps://www.pymc.io/projects/examples/en/latest/gaussian_processes/log-gaussian-cox-process.html\nFabian E. Bachl, Finn Lindgren, David L. Borchers, and Janine B. Illian (2019), inlabru: an R package for Bayesian spatial modelling from ecological survey data, Methods in Ecology and Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168\nFunwi-Gabga, N. and Mateu, J. (2012) Understanding the nesting spatial behaviour of gorillas in the Kagwene Sanctuary, Cameroon. Stochastic Environmental Research and Risk Assessment 26 (6), 793-811.\nhttps://www.muscardinus.be/2018/07/inlabru-bru/\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2023 – ou bootcamp R du groupe State Of The R s’est déroulé à la station biologique de Roscoff du 21 au 25 août 2023.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agissait de la septième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#où-quand",
    "href": "index.html#où-quand",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2023 – ou bootcamp R du groupe State Of The R s’est déroulé à la station biologique de Roscoff du 21 au 25 août 2023.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agissait de la septième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#participants",
    "href": "index.html#participants",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Participants",
    "text": "Participants\nEmré Anakok, Julie Aubert, Pierre Barbillon, Barbara Bricout, Caroline Cognot, Félix Cheysson, Julien Chiquet, Annaïg De Walsche, Marie-Pierre Etienne, Armand Favrot, Hugo Gangloff, Pierre Gloaguen, Jérémy Lamouroux, Corentin Lothodé, Mahendra Mariadassou, Tristan Mary-Huard, Isabelle Sanchez, Florian Teste, Théodore Vanrentherghem, Emily Walker."
  },
  {
    "objectID": "index.html#idées-explorées",
    "href": "index.html#idées-explorées",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Idées explorées",
    "text": "Idées explorées"
  },
  {
    "objectID": "index.html#soutien",
    "href": "index.html#soutien",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Soutien",
    "text": "Soutien"
  },
  {
    "objectID": "tidymodels_build_new_model.html",
    "href": "tidymodels_build_new_model.html",
    "title": "Construire un modèle parsnip",
    "section": "",
    "text": "Notre objectif ici est de construire un nouveau modèle {parsnip} à partir d’une implémentation existente dans un package R.\nIntérêts : éliminer des dépendances, du code dupliqué, pouvoir profiter du cadre {tidymodels}.\n\n\n\nhttps://www.tidymodels.org/learn/develop/models/\nTuto tidymodels - Rencontres R 2023\n\n\n\n\nIl se définit par\n\nun mode (régression linéaire, logistique, …),\nun type (régression, classification),\nun moteur de calcul engine (lm, stan, …).\n\nQunad on ajoute un modèle, on doit donc spécifier son mode et son engine. On peut aussi ajouter un nouveau modèle différent d’un pré-existant seulement par son type (ie même combinaison engine et mode).\nIl est possible de voir l’ensemble des modèles déjà disponibles ici."
  },
  {
    "objectID": "tidymodels_build_new_model.html#introduction",
    "href": "tidymodels_build_new_model.html#introduction",
    "title": "Construire un modèle parsnip",
    "section": "",
    "text": "Notre objectif ici est de construire un nouveau modèle {parsnip} à partir d’une implémentation existente dans un package R.\nIntérêts : éliminer des dépendances, du code dupliqué, pouvoir profiter du cadre {tidymodels}.\n\n\n\nhttps://www.tidymodels.org/learn/develop/models/\nTuto tidymodels - Rencontres R 2023\n\n\n\n\nIl se définit par\n\nun mode (régression linéaire, logistique, …),\nun type (régression, classification),\nun moteur de calcul engine (lm, stan, …).\n\nQunad on ajoute un modèle, on doit donc spécifier son mode et son engine. On peut aussi ajouter un nouveau modèle différent d’un pré-existant seulement par son type (ie même combinaison engine et mode).\nIl est possible de voir l’ensemble des modèles déjà disponibles ici."
  },
  {
    "objectID": "tidymodels_build_new_model.html#intégration-de-la-régression-pln",
    "href": "tidymodels_build_new_model.html#intégration-de-la-régression-pln",
    "title": "Construire un modèle parsnip",
    "section": "Intégration de la régression PLN",
    "text": "Intégration de la régression PLN\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.7\n✔ dials        1.2.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.2     ✔ tibble       3.2.1\n✔ ggplot2      3.4.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.1\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()        masks scales::discard()\n✖ dplyr::filter()         masks stats::filter()\n✖ dplyr::lag()            masks stats::lag()\n✖ parsnip::prepare_data() masks PLNmodels::prepare_data()\n✖ recipes::step()         masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(poissonreg)\n\n\nDonnées\nNous utiliserons le jeu de données de la vignette de PLN\n\ndata(trichoptera)\n\n\n\n\n\n\n\nRemarque\n\n\n\nIl existe une fonction prepare_data dans {parsnip} également.\n\n\n\n\nDifférentes étapes pour intégrer PLNmodels::PLN dans parsnip\n\nEtape 1 : Spécification du modèle et de ses arguments\nOn va ajouter la fonction PLNmodels::PLN à la liste des fonctions utilisables pour faire de la régression de Poisson.\n\nshow_model_info(\"poisson_reg\")\n\nInformation for `poisson_reg`\n modes: unknown, regression \n\n engines: \n   regression: glm¹, glmnet¹, hurdle¹, stan¹, zeroinfl¹\n\n¹The model can use case weights.\n\n arguments: \n   glmnet: \n      penalty --&gt; lambda\n      mixture --&gt; alpha\n\n fit modules:\n     engine       mode\n        glm regression\n     hurdle regression\n   zeroinfl regression\n     glmnet regression\n       stan regression\n\n prediction modules:\n         mode   engine                          methods\n   regression      glm                     numeric, raw\n   regression   glmnet                     numeric, raw\n   regression   hurdle                     numeric, raw\n   regression     stan conf_int, numeric, pred_int, raw\n   regression zeroinfl                     numeric, raw\n\n\n\nset_model_mode(model = \"poisson_reg\", mode = \"regression\")\nset_model_engine(\n  \"poisson_reg\", \n  mode = \"regression\", \n  eng = \"PLN\"\n)\nset_dependency(\"poisson_reg\", eng = \"PLN\", pkg = \"PLNmodels\")\n\nOn peut vérifier ce qu’on a ajouté.\n\nshow_model_info(\"poisson_reg\")\n\nInformation for `poisson_reg`\n modes: unknown, regression \n\n engines: \n   regression: glm¹, glmnet¹, hurdle¹, PLNNA, stan¹, zeroinfl¹\n\n¹The model can use case weights.\n\n arguments: \n   glmnet: \n      penalty --&gt; lambda\n      mixture --&gt; alpha\n\n fit modules:\n     engine       mode\n        glm regression\n     hurdle regression\n   zeroinfl regression\n     glmnet regression\n       stan regression\n\n prediction modules:\n         mode   engine                          methods\n   regression      glm                     numeric, raw\n   regression   glmnet                     numeric, raw\n   regression   hurdle                     numeric, raw\n   regression     stan conf_int, numeric, pred_int, raw\n   regression zeroinfl                     numeric, raw\n\n\nSi notre modèle a des arguments supplémentaires que ceux existants, on peut les ajouter.\n\n\nEtape 2 : Créer la fonction principale associée au modèle le cas échéant\nIci comme nous avons seulement ajouté un moteur à un modèle préexistant ce n’est pas nécessaire.\ntodo: regarder comment ajouter l’information possible d’utilisation de poids\n\n\nEtape 3 : Préciser le module d’ajustement (fit)\n\nL’argument interface, peut prendre les valeurs formula, data ou matrices.\nprotect est une liste optionnelle d’arguments qui ne devraient pas être modifié par l’utilisateur.\nfunc est un vecteur précisant le package et la fonction qui sera appelé pour l’ajustement.\ndefaults est une liste optionnelle d’arguments que l’utilisateur peut modifier mais pour laquelle on peut spécifier des valeurs par défaut.\n\n\nset_fit(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  value = list(\n    interface = \"formula\",\n    protect = c(\"formula\", \"data\"),\n    func = c(pkg = \"PLNmodels\", fun = \"PLN\"),\n    defaults = list(control = PLN_param(), weights = NULL, subset = NULL)\n  )\n)\n\nOn peut ajouter des traitements par défaut pour les variables explicatives, tels que calculs de variables indicatrices, calcul d’une constante etc…\n\nset_encoding(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  options = list(\n    predictor_indicators = \"traditional\",\n    compute_intercept = TRUE,\n    remove_intercept = TRUE,\n    allow_sparse_x = FALSE\n  )\n)\n\n\n\nEtape 4 : Ajouter un module pour la prédiction (predict)\n\nset_pred(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  type = \"numeric\",\n  value = list(\n    pre = NULL,\n    post = NULL,\n    func = c(fun = \"predict\"),\n    args =\n      list(\n        object = expr(object$fit),\n        newdata = expr(new_data),\n        type = \"response\"\n      )\n  )\n)\n\n\n\n\nApplication sur les données trichoptera\n\nPLN dans PLNmodelsPLN dans parsnip\n\n\n\nprep_trichoptera &lt;- PLNmodels::prepare_data(trichoptera$Abundance, trichoptera$Covariate)\nmyPLN &lt;- PLN(Abundance ~ 1 , data = prep_trichoptera)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nmyPLN\n\nA multivariate Poisson Lognormal fit with full covariance model.\n==================================================================\n nb_param    loglik       BIC       ICL\n      170 -1129.909 -1460.714 -2230.658\n==================================================================\n* Useful fields\n    $model_par, $latent, $latent_pos, $var_par, $optim_par\n    $loglik, $BIC, $ICL, $loglik_vec, $nb_param, $criteria\n* Useful S3 methods\n    print(), coef(), sigma(), vcov(), fitted()\n    predict(), predict_cond(), standard_error()\n\n\n\n\n\nresPLN &lt;- poisson_reg() %&gt;% \n  set_engine(\"PLN\") %&gt;% \n  fit(Abundance ~ 1 , data = prep_trichoptera)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nresPLN\n\nparsnip model object\n\nA multivariate Poisson Lognormal fit with full covariance model.\n==================================================================\n nb_param    loglik       BIC       ICL\n      170 -1129.909 -1460.714 -2230.658\n==================================================================\n* Useful fields\n    $model_par, $latent, $latent_pos, $var_par, $optim_par\n    $loglik, $BIC, $ICL, $loglik_vec, $nb_param, $criteria\n* Useful S3 methods\n    print(), coef(), sigma(), vcov(), fitted()\n    predict(), predict_cond(), standard_error()\n\n\n\n\n\n\nsummary(resPLN)\n\n             Length Class       Mode       \nlvl           0     -none-      NULL       \nspec          8     poisson_reg list       \nfit          32     PLNfit      environment\npreproc       1     -none-      list       \nelapsed       1     -none-      list       \ncensor_probs  0     -none-      list       \n\nresPLN$spec\n\nPoisson Regression Model Specification (regression)\n\nComputational engine: PLN \n\nModel fit template:\nPLNmodels::PLN(formula = missing_arg(), data = missing_arg(), \n    control = list(backend = \"nlopt\", trace = 1, covariance = \"full\", \n        Omega = NULL, config_post = list(jackknife = FALSE, bootstrap = 0L, \n            rsquared = TRUE, variational_var = FALSE, sandwich_var = FALSE, \n            trace = 1), config_optim = list(algorithm = \"CCSAQ\", \n            maxeval = 10000, ftol_rel = 1e-08, xtol_rel = 1e-06, \n            ftol_abs = 0, xtol_abs = 0, maxtime = -1, trace = 1), \n        inception = NULL), weights = NULL, subset = NULL)\n\n# Pour recuperer les coefficients\ncoef(resPLN$fit)\n\n                  Che       Hyc      Hym      Hys      Psy        Aga       Glo\n(Intercept) -2.833822 -4.049306 1.051399 -2.17906 3.291263 -0.3560404 -2.217591\n                  Ath      Cea       Ced        Set        All       Han\n(Intercept) -1.661659 -3.36122 0.3593471 -0.6285713 -0.8500234 -1.351443\n                  Hfo        Hsp       Hve       Sta\n(Intercept) -2.190792 -0.3070371 -2.758038 0.9621415\n\nall.equal(coef(myPLN), coef(resPLN$fit))\n\n[1] TRUE\n\n# Pour faire de la prediction\npred_pln &lt;- predict(myPLN, newdata  = prep_trichoptera, type = \"response\")\n# On peut appliquer les methodes \n#pred_parsnipfit &lt;- predict(resPLN$fit, newdata  = prep_trichoptera)\npred_parsnip &lt;- predict(resPLN, new_data  = trichoptera$Abundance)\nall.equal(pred_pln, pred_parsnip)\n\n [1] \"Modes: numeric, list\"                                                             \n [2] \"Lengths: 833, 17\"                                                                 \n [3] \"names for current but not for target\"                                             \n [4] \"Attributes: &lt; Names: 2 string mismatches &gt;\"                                       \n [5] \"Attributes: &lt; Length mismatch: comparison on first 2 components &gt;\"                \n [6] \"Attributes: &lt; Component 1: Modes: numeric, character &gt;\"                           \n [7] \"Attributes: &lt; Component 1: Lengths: 2, 3 &gt;\"                                       \n [8] \"Attributes: &lt; Component 1: target is numeric, current is character &gt;\"             \n [9] \"Attributes: &lt; Component 2: Modes: list, numeric &gt;\"                                \n[10] \"Attributes: &lt; Component 2: Length mismatch: comparison on first 2 components &gt;\"   \n[11] \"Attributes: &lt; Component 2: Component 1: Modes: character, numeric &gt;\"              \n[12] \"Attributes: &lt; Component 2: Component 1: Lengths: 49, 1 &gt;\"                         \n[13] \"Attributes: &lt; Component 2: Component 1: target is character, current is numeric &gt;\"\n[14] \"Attributes: &lt; Component 2: Component 2: Modes: character, numeric &gt;\"              \n[15] \"Attributes: &lt; Component 2: Component 2: Lengths: 17, 1 &gt;\"                         \n[16] \"Attributes: &lt; Component 2: Component 2: target is character, current is numeric &gt;\"\n[17] \"target is matrix, current is tbl_df\"                                              \n\n\n\n\nTest d’un workflow\n\n# separation du jeu de donnees en test et apprentissage\nset.seed(123)\ntri_split &lt;- initial_split(data = prep_trichoptera, prop = 0.9)\n#tri_train &lt;- training(tri_split)\n#tri_test &lt;- testing(tri_split)\np_recipe &lt;- \n  recipe(Abundance ~ 1 + Temperature, data = training(tri_split))\n\npln_model &lt;- \n  poisson_reg()%&gt;%\n  set_engine(\"PLN\") %&gt;%\n  set_mode(\"regression\")\n\npln_workflow &lt;- workflow() %&gt;%\n  add_recipe(p_recipe) %&gt;%\n  add_model(pln_model)\n\nfitted_workflow &lt;-  pln_workflow %&gt;%\n  fit(training(tri_split)) \n\n# Predicition sur le jeu d'entrainement\ntest_pred &lt;- fitted_workflow %&gt;% predict(new_data = testing(tri_split))\n\nPour la suite du workflow, calcul de performance sur des rééchantillonnage etc., ce serait possible mais nécessite un peu de code. Il faudrait ici que la sortie de prédiction soit en format plus ‘tidy’ ou réécrire le calcul de métrique sur des matrices.\n\n\nAutre jeu de données, exemple en régression univariée\n\np &lt;- read.csv(\"https://stats.idre.ucla.edu/stat/data/poisson_sim.csv\")\np &lt;- within(p, {\n  prog &lt;- factor(prog, levels=1:3, labels=c(\"General\", \"Academic\", \n                                            \"Vocational\"))\n  id &lt;- factor(id)\n})\n\nOn essaie maintenant en utilisant {parsnip}.\n\nglm de baseglm dans parsnipplnPLN dans parsnip\n\n\n\nsummary(m1 &lt;- glm(num_awards ~ prog + math, family=\"poisson\", data=p))\n\n\nCall:\nglm(formula = num_awards ~ prog + math, family = \"poisson\", data = p)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -5.24712    0.65845  -7.969 1.60e-15 ***\nprogAcademic    1.08386    0.35825   3.025  0.00248 ** \nprogVocational  0.36981    0.44107   0.838  0.40179    \nmath            0.07015    0.01060   6.619 3.63e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 189.45  on 196  degrees of freedom\nAIC: 373.5\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\npoisson_reg() %&gt;% \n     set_engine(\"glm\") %&gt;%\n     set_mode(\"regression\") %&gt;%\n     fit(num_awards ~ prog + math, data = p)  %&gt;%\n     predict(p)\n\n# A tibble: 200 × 1\n    .pred\n    &lt;dbl&gt;\n 1 0.135 \n 2 0.0934\n 3 0.167 \n 4 0.145 \n 5 0.126 \n 6 0.100 \n 7 0.192 \n 8 0.126 \n 9 0.0771\n10 0.192 \n# ℹ 190 more rows\n\n\n\n\n\nmod_pln &lt;- PLN(as.matrix(num_awards) ~ prog + math, data = p)  \n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nmod_pln %&gt;%\n     predict(p, type = \"response\") %&gt;%\n     head(n = 10)\n\n            Y\n1  0.13408541\n2  0.09317098\n3  0.16585222\n4  0.14393335\n5  0.12491126\n6  0.10001395\n7  0.19110900\n8  0.12491126\n9  0.07605752\n10 0.19110900\n\n\n\n\n\npoisson_reg() %&gt;% \n     set_engine(\"PLN\") %&gt;%\n     set_mode(\"regression\") %&gt;%\n     fit(as.matrix(num_awards) ~ prog + math, data = p) %&gt;% \n     predict(p)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n# A tibble: 200 × 1\n   .pred_Y\n     &lt;dbl&gt;\n 1  0.134 \n 2  0.0932\n 3  0.166 \n 4  0.144 \n 5  0.125 \n 6  0.100 \n 7  0.191 \n 8  0.125 \n 9  0.0761\n10  0.191 \n# ℹ 190 more rows\n\n\n\n\n\nOn peut vérifier la commande associée au modèle programmé.\n\npoisson_reg() %&gt;% translate(engine = \"PLN\")\n\nPoisson Regression Model Specification (regression)\n\nComputational engine: PLN \n\nModel fit template:\nPLNmodels::PLN(formula = missing_arg(), data = missing_arg(), \n    control = list(backend = \"nlopt\", trace = 1, covariance = \"full\", \n        Omega = NULL, config_post = list(jackknife = FALSE, bootstrap = 0L, \n            rsquared = TRUE, variational_var = FALSE, sandwich_var = FALSE, \n            trace = 1), config_optim = list(algorithm = \"CCSAQ\", \n            maxeval = 10000, ftol_rel = 1e-08, xtol_rel = 1e-06, \n            ftol_abs = 0, xtol_abs = 0, maxtime = -1, trace = 1), \n        inception = NULL), weights = NULL, subset = NULL)"
  },
  {
    "objectID": "tidymodels_build_new_model.html#pour-aller-plus-loin",
    "href": "tidymodels_build_new_model.html#pour-aller-plus-loin",
    "title": "Construire un modèle parsnip",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nDans le cadre tidymodels tout est assez modulaire et personnalisable : on peut ajouter de nouvelles recettes de pré-traitement, personnaliser son rééchantillonnage, le calcul de métrique etc.\nUn peu de documentation sur le site de {tidymodels] dans la section Develop custom modeling tools."
  },
  {
    "objectID": "jax-getting-started.html",
    "href": "jax-getting-started.html",
    "title": "Premiers pas avec jax",
    "section": "",
    "text": "Le but de cette vignette est d’implémenter une régression logistique et/ou une régression multivariée avec JAX."
  },
  {
    "objectID": "jax-getting-started.html#préliminaires",
    "href": "jax-getting-started.html#préliminaires",
    "title": "Premiers pas avec jax",
    "section": "Préliminaires",
    "text": "Préliminaires\n\nInstallation\n\nConda\nJax est disponible dans le channel conda-forge et peut donc s’installer dans un environnement conda\n#| eval: true\nconda create -n jax\nconda activate jax\n## Install the CPU version\nconda install jax -c conda-forge\n## Install packages necessary for the render\nconda install nbclient nbformat ipykernel\nPour des instruction détaillées pour l’installation en mode GPU ou TPU, se référer à la documentation officielle.\nIl suffit alors d’activer l’environnement jax pour produire le html à partir du qmd\n#| eval: false\nconda activate jax\nquarto render my_document.qmd --to html\n\n\nPip\nSi vous préférez une installation via pip (pour une version cpu),\n#| eval: false\npip3 install jax jaxlib\nPour une installation GPU (avec cuda 12 par exemple, on vous laisse gérer la compatibilité de vos driver Nvidia and Cie),\n#| eval: false\npip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\nL’utilisation de venv est recommandable (mais non obligatoire).\nOn installe également optax pour avoir accès à des optimiseurs.\n#| eval: false\npip3 install optax\nImportant Pour utiliser optax, il vaut mieux utiliser pip pour installer jax et jaxlib, les versions disponibles dans les dépôts conda sont en effet trop anciennes pour optax."
  },
  {
    "objectID": "jax-getting-started.html#premiers-pas",
    "href": "jax-getting-started.html#premiers-pas",
    "title": "Premiers pas avec jax",
    "section": "Premiers pas",
    "text": "Premiers pas\n\nPhilosophie\nEn quelques mots, JAX est une bibliothèque Python développé par Google et itinitalement utilisé dans TensorFLow. Elle permet de faire de l’algèbre linéaire à la numpy, avec 2 propriétés clés le rendant extrêment performant:\n\nun autograd permettant la différention automatique de calcul Python/Numpy\nun compileur pour GPU et autres (XLA), dédié à l’algèbre linéaire qui permet d’optimiser les temps d’exécution grace à une approche JIT (Just-in Time, c’est-à-dire une optimisation du code à l’exécution et non pas avant l’appel comme avec un compileur classique).\n\nL’objectif de la bibliothèque est de proposer une expérience utilisateur aussi proche que possible de calculs à la Numpy, notamment à l’aide de décorateurs Python. Néanmoins, pour accéder pleinement aux capacités de JAX, un certains nombres de contraintes d’écriture des programmes s’appliquent, que nous allons essayer de présenter pas à pas.\n\n\nImport de la bibliothèque\nL’import complet/standard est le suivant:\n\nimport jax.numpy as jnp\nfrom jax import grad, jit, vmap\nfrom jax import random\nimport optax\nimport matplotlib.pyplot as plt\n\nOn peut détailler les fonctionnalité des modules comme suit:\n\nle module jax.numpy, aka jnp, porte les opérations matricielles usuelles de manière quasi transparente\nle module random définit les outils de génération de nombres aléatoires, propres à JAX et très différents de Numpy\nle module grad gère l’autodifférentiation\nle module jit gère la “just-in time” compilation (accélartion du code)\nle module vmap permet de vectoriser automatiquement certaines opérations\n\n\n\nJax.numpy: interface Algèbre linéaire haut-niveau\nOn commence par simuler des données aléatoires via les outils de jax. Attention la gestion de la clé aléatoire est explicite. Après avoir créé une clé et avant chaque appel à une fonction aléatoire, il faut faire évoluer la graine à la main\n\nkey,subkey = random.split(key, 2)\n\net utiliser subkey (les sous-clés) dans l’appel à la fonction aléatoire (ou aux fonctions aléatoire) comme écrit ci-dessous.\n\nn = 10000\np = 100\nkey = random.PRNGKey(0)\nkey,sub1,sub2 = random.split(key, 3)\nones = jnp.ones((n, 1))\nx = random.normal(sub1, (n, p-1))\nx = jnp.concatenate([ones, x], axis = 1)\nkey,subkey = random.split(key, 2)\nbeta_true = random.normal(sub2, (p,1))\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\nAvant de les multiplier. On utilise ici la fonction block_until_ready() uniquement pour mesurer le temps effectif de calcul. En effet, JAX fait de l’évaluation asynchrone (comme {{future}} en R) pour rendre la main à l’utilisateur après l’envoi de la commande.\n\n%timeit odds = jnp.dot(x, beta_true).block_until_ready()  # runs on the CPU\n\n194 µs ± 1.76 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n\n\nOn échantillonne ensuite des variables suivant une loi de Bernoulli.\n\nodds = jnp.dot(x, beta_true)\nkey,subkey = random.split(key, 2)\ny = random.bernoulli(subkey, odds)\n\net une perte logistique\n\\[\\ell(y, x, \\theta) = -\\log p(y; \\sigma(x^{\\top}\\theta)) = -y (x^\\top \\theta) - \\log(1 + e^{x^\\top \\theta})\\]\n\ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n\nQu’on peut tester sur un example simple\n\nlogistic_loss(True, 1.0, 0)\n\nArray(0.6931472, dtype=float32)\n\n\n\n\nJust-in-time compilation\nLa version normale de notre fonction logistique est déjà rapide.\n\n%timeit logistic_loss(y, x, beta_true).block_until_ready()\n\n292 µs ± 4.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\nmais on peut l’accélerer en compilant la fonction via le décorateur @jit ou la fonction jit() de façon complètement transparente pour l’utilisateur.\n\n## Utilisation du décorateur @jit\n@jit \ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n\n\n## Utilisation de jit()\nlogistic_loss_jit = jit(logistic_loss)\n%timeit logistic_loss_jit(y, x, beta_true).block_until_ready()\n\n236 µs ± 21.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\nLa différence est assez importante dans cet exemple mais il n’est pas toujours intéressant ni même possible de jitter une fonction.\nEn particulier, si une fonction implique un branchement conditionnel:\n\ndef f(x):\n  if x &gt; 5:\n    return x\n  else:\n    return 2*x\n\non ne peut la jitter facilement.\n\nf_jit = jit(f)\n## Renvoie une erreur\nf_jit(1)\n\nTracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function f at /tmp/ipykernel_6122/2514275982.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError\n\n\n\n\ngrad: auto-différentiation\nJAX permet de calculer le gradient d’une fonction via grad(). La syntaxe est différente de torch et plus proche de ce qu’on ferait dans une fonction mathématique.\n\ndef loss(theta):\n  return logistic_loss(y, x, theta)\n\n\n## random start for theta\nkey,subkey = random.split(key, 2)\ntheta = random.normal(key, (p, 1))\ngrad_loss = grad(loss)\n\ngrad() peut-être combiné à jit() dans tous les sens à condition que les fonctions s’y prêtent.\n\ngrad_loss = grad(loss)\n%timeit grad_loss(theta)\n\n7.39 ms ± 491 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\ngrad_loss = jit(grad(loss))\n## Warmup to cache grad loss\ngrad_loss(theta).shape\n## Actual time recording\n%timeit grad_loss(theta)\n\n368 µs ± 5.33 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\nMais ce n’est pas toujours intéressant.\n\ngrad_loss = jit(grad(jit(loss)))\n## Warmup to cache grad loss\ngrad_loss(theta).shape\n## Actual time recording\n%timeit grad_loss(theta)\n\n375 µs ± 3.49 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\n\n\nVectorisation\nJAX permet enfin de vectoriser automatiquement des opérations de façon efficace (en faisant descendre la boucle à l’intérieur de la fonction, au niveau des primitives utilisées pour le calcul).\nConsidérons un example simple où on veut calculer des logs-odds sur mesures répétées.\n\n## Matrice de covariables, répétées en temps \n## [temps, individu, variable]\nkey,subkey = random.split(key, 2)\nX = random.normal(key, (10, n, p))\ndef compute_odds(x, theta):\n  return jnp.dot(x, theta)\ndef compute_odds_batched(X,  theta):\n  return jnp.stack([compute_odds(x, theta) for x in X]) \n\nEt testons ce qui se passe. On appelle la fonction sur une tranche de X\n\ncompute_odds(X[:1,:, :], beta_true).shape\n%timeit compute_odds(X[:1,:, :], beta_true)\n\n2.85 ms ± 79.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nPuis sur toutes les tranches de X avec notre fonction vectorisée manuellement.\n\ncompute_odds_batched(X, beta_true).shape\n%timeit compute_odds_batched(X, beta_true)\n\n13.5 ms ± 182 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nPuis sur toutes les tranches de X avec notre fonction vectorisée via vmap().\n\ndef compute_odds_batched_vmap(X,  theta):\n  def f(x):\n    return compute_odds(x, theta)\n  return vmap(f)(X)\n\n\ncompute_odds_batched_vmap(X, beta_true).shape\n\n(10, 10000, 1)\n\n\n\n%timeit compute_odds_batched_vmap(X, beta_true)\n\n11.9 ms ± 279 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nA comparer à la version native jax qui est déjà nativement vectorisée pour cette opération\n\n%timeit compute_odds(X, beta_true)\n\n11.1 ms ± 210 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
  },
  {
    "objectID": "jax-getting-started.html#optimisation-de-la-fonction-objective",
    "href": "jax-getting-started.html#optimisation-de-la-fonction-objective",
    "title": "Premiers pas avec jax",
    "section": "Optimisation de la fonction objective",
    "text": "Optimisation de la fonction objective\n\nÀ la main\nContrairement à torch, on n’a pas d’optimiseur défini clé en main dans JAX. La dérivée est néanmoins une fonction comme les autres et on peut donc écrire très simplement un algorithme simple de descente de gradient.\n\n%%time\nnum_iterations = 50\nloss_vector = []\n## Learning rate\nlr = 0.001\n## Initialisation de theta\ntheta = jnp.zeros(p)\n## Fonction de perte, en mode jit\n@jit\ndef loss(theta):\n  return logistic_loss(y, x, theta)\n## Gradient de la fonction de perte, en mode jit\ngrad_loss = jit(grad(loss))\n\n## Descente de gradient\nfor i in range(num_iterations):\n    # Suivi de la fonction de perte\n    loss_vector.append(loss(theta))\n    # Mise à jour du paramètre\n    theta = theta - lr * grad_loss(theta) \n\nCPU times: user 318 ms, sys: 24.2 ms, total: 342 ms\nWall time: 341 ms\n\n\nEt on peut vérifier que la fonction de perte décroit au cours du temps.\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\nEt que les paramètres de régression estimés se rapprochent des vraies valeurs\n\nplt.plot(beta_true, theta, marker='o', linestyle=\"none\")\nplt.plot([-3, 3], [-3, 3], color='r', linestyle='-', linewidth=2)\nplt.xlabel('True parameter')\nplt.ylabel('Estimated parameter')\nplt.title('Estimated versus true parameter')\nplt.show()\n\n\n\n\n\n\nAvec Optax\nOn peut néanmoins utiliser la librairie optax pour définir des optimiseurs comme en torch. On va utiliser ici Adam.\n\nFonction objective\nOn commence par définir la fonction objective avec un ordre précis pour les arguments:\n\nparamètres à optimiser (typiquement \\(\\theta\\), les coefficients de régression)\nparamètres additionels (pénalités, etc)\ndonnées (avec le mot clé data)\n\n\n@jit \ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n@jit  \ndef objective_and_grad(params, penalty, data):\n  x = data[:, :-1]\n  y = data[:, -1]\n  def loss(params):\n    return logistic_loss(y, x, params)\n  loss_value = loss(params)\n  loss_grad = grad(loss)(params)\n  return [loss_value, loss_grad]\n\n\n\nItérateur de données\nAdam est un algorithme d’optimisation stochastique. On définit donc un itérateur qui va échantillonner les données.\n\nbatch_size = 100\nn_iter = 1000\n# key, subkey = random.split(key, 2)\ndef data_iterator(key):    \n    return random.choice(key, data, (batch_size, ), replace = False)\n\n\n\nOptimisation\nOn définit enfin une fonction de fit qui travaille sur des batchs.\n\ndef fit(params, optimizer, key):\n  opt_state = optimizer.init(params)\n  loss_vector = []\n\n  @jit\n  def step(params, opt_state, batch):\n    loss_value, grads = objective_and_grad(params, 0, batch)\n    updates, opt_state = optimizer.update(grads, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, opt_state, loss_value\n\n  for i in range(n_iter):\n    key, subkey = random.split(key, 2)\n    batch = data_iterator(subkey)\n    params, opt_state, loss_value = step(params, opt_state, batch)\n    loss_vector.append(loss_value.item())\n    if i % 100 == 0:\n      print(f'step {i}, loss: {loss_value}')\n\n  return [params, loss_vector]\n\nFinally, we can fit our parametrized function using the Adam optimizer provided by optax.\n\n%%time \ninitial_params = jnp.zeros((x.shape[1], ))\noptimizer = optax.adam(learning_rate=1e-2)\ndata = jnp.concatenate([x, y], axis = 1)\nparams,loss_vector = fit(initial_params, optimizer, key)\n\nstep 0, loss: 69.3147201538086\nstep 100, loss: 18.997222900390625\nstep 200, loss: 13.532913208007812\nstep 300, loss: 14.558242797851562\nstep 400, loss: 11.654617309570312\nstep 500, loss: 9.333587646484375\nstep 600, loss: 11.057373046875\nstep 700, loss: 7.914306640625\nstep 800, loss: 10.06451416015625\nstep 900, loss: 8.030914306640625\nCPU times: user 8.33 s, sys: 210 ms, total: 8.54 s\nWall time: 8.27 s\n\n\nOn peut vérifier que la fonction objective converge sans décroître systématiquement\n\nplt.plot(range(1, n_iter+1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\net que les paramètres sont proches des bonnes valeurs\n\nplt.plot(beta_true, params, marker='o', linestyle=\"none\")\nplt.plot([-3, 3], [-3, 3], color='r', linestyle='-', linewidth=2)\nplt.xlabel('True parameter')\nplt.ylabel('Estimated parameter')\nplt.title('Estimated versus true parameter')\nplt.show()"
  },
  {
    "objectID": "torch_Python-PLN.html",
    "href": "torch_Python-PLN.html",
    "title": "PLN version Python",
    "section": "",
    "text": "Comme vous pourrez le constater, les syntaxtes {torch} et Pytorch sont très proches.\n\n\nOn charge le jeu de données oaks contenu dans le package python pyPLNmodels\n\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\noaks = load_oaks()\nY = oaks['counts']\nO = np.log(oaks['offsets'])\nX = np.ones([Y.shape[0],1])\n\nPour référence, on optimise avec le package dédié (qui utilise pytorch et l’optimiseur Rprop.\n\npln = Pln.from_formula(\"counts ~ 1 \", data = oaks, take_log_offsets = True)\n%timeit pln.fit()\n\nFitting a Pln model with full covariance model.\nInitialization ...\nInitialization finished\nTolerance 0.001 reached in 264 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 265 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 299 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 300 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 332 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 347 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 362 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 371 iterations\nThe slowest run took 40.24 times longer than the fastest. This could mean that an intermediate result is being cached.\n40.1 ms ± 32.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n\nimport torch\nimport numpy as np\nimport math\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN() :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    ELBO_list : list\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array) : \n        self.Y = torch.tensor(Y)\n        self.O = torch.tensor(O)\n        self.X = torch.tensor(X)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad = True)\n        self.S = torch.full(Y.shape, 1.0, requires_grad = True)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad = True)\n        self.Sigma = torch.eye(self.p)\n        self.Omega = torch.eye(self.p)\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega) +  torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2)) - .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega) + .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n      self.ELBO = np.zeros(N_iter)\n      optimizer = torch.optim.Rprop([self.B, self.M, self.S], lr = lr)\n      objective0 = np.infty\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n        \n        if (abs(objective0 - objective)/abs(objective) &lt; tol):\n          self.ELBO = self.ELBO[0:i]\n          break\n        else:\n          objective0 = objective\n\n\n\n\nTestons notre implémentation simple de PLN utilisant:\n\nmyPLN = PLN(Y, O, X)\n%timeit myPLN.fit(50, lr = 0.1, tol = 1e-8)\nplt.plot(np.log(-myPLN.ELBO))\n\n190 ms ± 7.84 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n```"
  },
  {
    "objectID": "torch_Python-PLN.html#pln-with-pytorch",
    "href": "torch_Python-PLN.html#pln-with-pytorch",
    "title": "PLN version Python",
    "section": "",
    "text": "Comme vous pourrez le constater, les syntaxtes {torch} et Pytorch sont très proches.\n\n\nOn charge le jeu de données oaks contenu dans le package python pyPLNmodels\n\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\noaks = load_oaks()\nY = oaks['counts']\nO = np.log(oaks['offsets'])\nX = np.ones([Y.shape[0],1])\n\nPour référence, on optimise avec le package dédié (qui utilise pytorch et l’optimiseur Rprop.\n\npln = Pln.from_formula(\"counts ~ 1 \", data = oaks, take_log_offsets = True)\n%timeit pln.fit()\n\nFitting a Pln model with full covariance model.\nInitialization ...\nInitialization finished\nTolerance 0.001 reached in 264 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 265 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 299 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 300 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 332 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 347 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 362 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 371 iterations\nThe slowest run took 40.24 times longer than the fastest. This could mean that an intermediate result is being cached.\n40.1 ms ± 32.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n\nimport torch\nimport numpy as np\nimport math\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN() :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    ELBO_list : list\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array) : \n        self.Y = torch.tensor(Y)\n        self.O = torch.tensor(O)\n        self.X = torch.tensor(X)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad = True)\n        self.S = torch.full(Y.shape, 1.0, requires_grad = True)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad = True)\n        self.Sigma = torch.eye(self.p)\n        self.Omega = torch.eye(self.p)\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega) +  torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2)) - .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega) + .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n      self.ELBO = np.zeros(N_iter)\n      optimizer = torch.optim.Rprop([self.B, self.M, self.S], lr = lr)\n      objective0 = np.infty\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n        \n        if (abs(objective0 - objective)/abs(objective) &lt; tol):\n          self.ELBO = self.ELBO[0:i]\n          break\n        else:\n          objective0 = objective\n\n\n\n\nTestons notre implémentation simple de PLN utilisant:\n\nmyPLN = PLN(Y, O, X)\n%timeit myPLN.fit(50, lr = 0.1, tol = 1e-8)\nplt.plot(np.log(-myPLN.ELBO))\n\n190 ms ± 7.84 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n```"
  },
  {
    "objectID": "torch_and_rcpp.html",
    "href": "torch_and_rcpp.html",
    "title": "Torch & Rcpp",
    "section": "",
    "text": "library(Rcpp)\nlibrary(RcppArmadillo)\nlibrary(torch)\nlibrary(tictoc)\nlibrary(bench) # comparaison des vitesses\nlibrary(ggplot2)\nlibrary(ggbeeswarm)"
  },
  {
    "objectID": "torch_and_rcpp.html#torch-on-r",
    "href": "torch_and_rcpp.html#torch-on-r",
    "title": "Torch & Rcpp",
    "section": "Torch on R",
    "text": "Torch on R\nLa librairie torch de R permet la manipulation de tenseur en R. Elle permet notament de faire la différenciation automatique, c-a-d d’évaluer numériquement le gradient d’une fonction et d’effectuer des descente de gradient.\nPrésentation finistR2022\nTorch and Automatic differentiation"
  },
  {
    "objectID": "torch_and_rcpp.html#rcpp",
    "href": "torch_and_rcpp.html#rcpp",
    "title": "Torch & Rcpp",
    "section": "Rcpp",
    "text": "Rcpp\nL’utilisation de {Rcpp} permet d’exporter des fonction C++ en R. Les fonctions seront alors directement utilisable dans un script et avec des arguments R. Ainsi on peu tirer parti de la compilation d’un code C++, et accélérer de nombreux calculs algébriques.\nPrésentation finistR2018\n\nExemple 1\nDans cet exemple nous allons calculer la loss d’une fonction logistique en R et en C++. Puis comparer les résultats avec le package {bench} de R.\n```{cpp, eval = FALSE, echo = TRUE} // [[Rcpp::depends(RcppArmadillo)]] #include &lt;RcppArmadillo.h&gt;\n// Logistic loss // [[Rcpp::export]] // const : pas de changement de valeur dans la fonction // arma:: : se sont les classes de Armadillo // using namespace arma to erase all arma:: // & : appel sans copie donc plus rapide double loss_cpp( const arma::vec theta, const arma::vec& y, const arma::mat& x ) { arma::vec odds(x.n_rows); odds = x * theta; double log_lik; log_lik = arma::dot(y, odds) - arma::sum(arma::log(1 + arma::exp(odds))); return(-log_lik); }\n\n\n\n::: {.cell}\n\n```{.cpp .cell-code}\n// [[Rcpp::depends(RcppArmadillo)]]\n#include &lt;RcppArmadillo.h&gt;\n\n// Logistic loss\n// [[Rcpp::export]]\n// const : pas de changement de valeur dans la fonction\n// arma:: : se sont les classes de Armadillo\n// using namespace arma to erase all arma::\n// & :  appel sans copie donc plus rapide\ndouble loss_cpp( const arma::vec theta, const arma::vec& y, const arma::mat& x ) {\n  arma::vec odds(x.n_rows);\n  odds = x * theta;\n  double log_lik;\n  log_lik = arma::dot(y, odds) - arma::sum(arma::log(1 + arma::exp(odds)));\n  return(-log_lik);\n}\n:::\n\nsourceCpp(file = \"logisticloss.cpp\")\n\n\nloss_R &lt;- function(theta, y, x) {\n  odds &lt;- x %*% theta\n  log_lik &lt;- sum(y * odds - log(1 + exp(odds)))\n  return(-as.numeric(log_lik))\n}\n\n\nloss_cpp(\n  theta = c(0.5, 0.1),\n  y = 1.0,\n  x = matrix(c(0.1, 0.2), 1, 2)\n)\n\n[1] 0.6587596\n\n\n\nloss_R(\n  theta = c(0.5, 0.1),\n  y = 1.0,\n  x = matrix(c(0.1, 0.2), 1, 2)\n)\n\n[1] 0.6587596\n\n\n\n# n_covar &lt;- 30\n# size &lt;- 1000\n# \n# theta &lt;- rnorm(n_covar)\n# y &lt;- as.numeric(rbinom(size, 1, 0.3))\n# x &lt;- matrix(rnorm(size * n_covar), size, n_covar)\n# \n# comp_tbl &lt;- bench::mark(\n#   loss_cpp(theta, y, x),\n#    loss_R(theta, y, x),\n#   iterations = 1000\n# )\n# \n# autoplot(comp_tbl, type = \"boxplot\")"
  },
  {
    "objectID": "torch_and_rcpp.html#references",
    "href": "torch_and_rcpp.html#references",
    "title": "Torch & Rcpp",
    "section": "References",
    "text": "References\n\nCours state of the R (2023)\nfinistR2022 - Torch Auto Diff"
  },
  {
    "objectID": "Readme.html",
    "href": "Readme.html",
    "title": "Ateliers Finist’R 2023",
    "section": "",
    "text": "Ateliers Finist’R 2023\n\n\n\nwebsite\n\n\nL’atelier Finist’R 2023 – ou bootcamp R s’est déroulé à la station biologique de Roscoff du 21 au 25 août 2023.\nIl s’agit de la septième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et dévelopeurs de paquets pour explorer les dernières fonctionalités du logiciel et les nouvelles pratiques de développement. A l’issu de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLa restitution se fait sous forme de site web. Le site de l’édition 2023 sera disponible ici"
  },
  {
    "objectID": "exams.html",
    "href": "exams.html",
    "title": "Nouveautés {learnr} et {exams}",
    "section": "",
    "text": "Introduction\nNous allons ici discuter du package {exams} qui permet de créer des feuilles d’examens (papier ou en ligne).\n\n\nexams\n{exams} est un package R disponible sur le CRAN. Il permet de construire des examens de manière automatique au format markdown ou LaTeX et incluant des chunks de code R dynamique. Comme pour learnr les exercices peuvent être à choix multiples ou simples, des problèmes arithmétiques, du code…\nhttps://www.r-exams.org/\nUn examen exams a plusieurs sorties possibles:\n\nfichiers autonomes : PDF, HTML, Docx, ODT, …\nfichiers dynamiques: Moodle XML, QTI 1.2, QTI 2.1, Blackboard, Canvas, OpenOLAT, ARSnova, and TCExam\n\nIl est possible de scanner les feuilles d’examens imprimés et de les évaluer automatiquement avec l’outil NOPS.\nUne autre option intéressante, pour réduire le risque de triche, exams propose un mécanisme de variations aléatoires des exercices:\n\nmélange de l’ordre des questions\nmélange des réponses possibles pour les QCMs\nmélange des données des exercices\n\nIl est également possible de combiner {exams} avec un tutoriel {learnr}: https://www.r-exams.org/tutorials/exams2learnr/.\n\n\nRéférences\n\nhttps://www.r-exams.org/\nhttps://www.r-exams.org/tutorials/\nhttps://www.r-exams.org/intro/dynamic/"
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Créer une branche propre à l’atelier nommée explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCréer un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs éventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir à mettre à jour l’image docker"
  },
  {
    "objectID": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "href": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Créer une branche propre à l’atelier nommée explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCréer un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs éventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir à mettre à jour l’image docker"
  },
  {
    "objectID": "instructions.html#détails-du-fonctionnement",
    "href": "instructions.html#détails-du-fonctionnement",
    "title": "Instructions pour le dépot sur le site web",
    "section": "Détails du fonctionnement",
    "text": "Détails du fonctionnement\n\nLe docker\nLien vers la fiche pense-bête : [https://www.docker.com/sites/default/files/d8/2019-09/docker-cheat-sheet.pdf]\nPour créer des images Docker en local sur sa machine, voici une liste de commandes utiles\n\nPour construire une image docker, il faut créer un fichier Dockerfile qui contient la recette du Docker. Pour ce site le ficher Dockerfile a la forme suivante\n\n\n\n\nFROM rocker/geospatial:4\nRUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\\n && apt-get install -y pandoc \\\n    pandoc-citeproc\nRUN R -e \"install.packages('remotes')\"\nRUN R -e \"install.packages('microbenchmark')\"\nRUN R -e \"install.packages('purrr')\" # map function\nRUN R -e \"install.packages('BiocManager')\" # map function\nRUN R -e \"BiocManager::install('BiocPkgTools')\" \nRUN R -e \"install.packages('httr')\" # GET function\nENV R_CRAN_WEB=\"https://cran.rstudio.com/\" \nRUN R -e \"install.packages('cowplot')\" # GET function\nRUN R -e \"install.packages('torch')\"\nRUN R -e \"torch::install_torch(type = 'cpu')\"\nRUN R -e \"install.packages('PLNmodels')\"\nRUN R -e \"install.packages('torchvision')\"\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n  jags \\\n  mercurial gdal-bin libgdal-dev gsl-bin libgsl-dev \\ \n  libc6-i386\n  \n  \nRUN R -e \"install.packages('INLA',repos=c(getOption('repos'),INLA='https://inla.r-inla-download.org/R/stable'), dep=TRUE)\"\nRUN R -e \"install.packages('reticulate')\"\nRUN R -e \"install.packages(c('inlabru', 'lme4', 'ggpolypath', 'RColorBrewer', 'geoR'))\"\nRUN R -e \"install.packages(c('tidymodels', 'brulee', 'reprex'))\"\nRUN R -e \"install.packages(c('poissonreg'))\"\nRUN apt-get install -y --no-install-recommends unzip python3-pip dvipng pandoc wget git make python3-venv && \\\n    pip3 install jupyter jupyter-cache flatlatex matplotlib && \\\n    apt-get --purge -y remove texlive.\\*-doc$ && \\\n    apt-get clean\n\nRUN pip3 install jax jaxlib torch numpy matplotlib pandas scikit-learn torchvision torchaudio \nRUN pip3 install pyplnmodels\nRUN pip3 install optax\n\n\npuis demander la construction de l’image à l’aide de la commande\n\n docker build -t nom_depot_dockerhub/nom_du_repo:version  . ## avec un nom\n\net enfin pousser sur Dockerhub\n\n docker push nom_depot_dockerhub/nom_du_repo:version\n\n\n\nLes actions\nDans les action de Github, on peut spécifier un container docker à utiliser, c’est ce que fait la ligne container du fichier d’action suivant, utiliser pour créer ce site web\n\n\nname: website\non:\n  push:\n    branches:\n      - main\n\njobs:   \n  build:\n    name: Build website with rmarkdown\n    runs-on: ubuntu-latest\n    container: stateofther/r-finistr2023:0.5\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Additional Packages\n        run: Rscript -e \"install.packages(c('ggbeeswarm', 'tictoc', 'bench'))\"\n      - name: Generate slides\n        run: \"quarto render\"\n      - name: GitHub Pages action\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./_site"
  },
  {
    "objectID": "torch_Python_R_ResNet.html",
    "href": "torch_Python_R_ResNet.html",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "",
    "text": "Le but est de comparer la syntaxe utilisée par les deux langages, seuls les exemples en R sont exécutés (difficultés de faire un quarto avec deux langages, voir issue ici ou de faire tourner pytorch avec {reticulate}). L’exemple d’application est un ResNet.\nPour charger installer la bibliothèque, en python, plusieurs possibilités sont données sur le site web officiel. Vous pouvez utiliser pip ou conda, avec ou sans cuda. Pour R, cela a déjà été fait à la session précédente de finistR.\n\ninstall.packages(torch)\ntorch::install_torch() ## si vous avez un GPU compatible avec CUDA\n## torch::install_torch(type = \"cpu\") ## sinon\n\nUn bon ouvrage pour démarrer : Deep Learning and Scientific Computing with R torch."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#intro",
    "href": "torch_Python_R_ResNet.html#intro",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "",
    "text": "Le but est de comparer la syntaxe utilisée par les deux langages, seuls les exemples en R sont exécutés (difficultés de faire un quarto avec deux langages, voir issue ici ou de faire tourner pytorch avec {reticulate}). L’exemple d’application est un ResNet.\nPour charger installer la bibliothèque, en python, plusieurs possibilités sont données sur le site web officiel. Vous pouvez utiliser pip ou conda, avec ou sans cuda. Pour R, cela a déjà été fait à la session précédente de finistR.\n\ninstall.packages(torch)\ntorch::install_torch() ## si vous avez un GPU compatible avec CUDA\n## torch::install_torch(type = \"cpu\") ## sinon\n\nUn bon ouvrage pour démarrer : Deep Learning and Scientific Computing with R torch."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#appel-des-fonctions",
    "href": "torch_Python_R_ResNet.html#appel-des-fonctions",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "Appel des fonctions",
    "text": "Appel des fonctions\nEn python, un premier exemple serait déjà d’importer la bibliothèque et de créer un tensor :\nimport torch\nt1 = torch.tensor(1)\nt1\nDonnera en R :\n\nlibrary(torch)\nt1 &lt;- torch_tensor(1)\nt1\n\ntorch_tensor\n 1\n[ CPUFloatType{1} ]\n\n\nOn comprend que la convention de nommage garde torch_ en préfix de toutes les fonctions implémentées."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#construction-dun-réseau-de-neurone-exemple-dun-resnet",
    "href": "torch_Python_R_ResNet.html#construction-dun-réseau-de-neurone-exemple-dun-resnet",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "Construction d’un réseau de neurone, exemple d’un ResNet",
    "text": "Construction d’un réseau de neurone, exemple d’un ResNet\n\nChargement des données\nOn va utiliser torchvision pour importer un jeu de donné connu (des images annotées). On veut appliquer des transformations sur le jeu de test, mais hélas tout n’est pas encore implémenté. On commente les transformations pas encore implementées.\ntransform = transforms.Compose([\n    #transforms.Pad(4),\n    #transforms.RandomHorizontalFlip(),\n    #transforms.RandomCrop(32),\n    transforms.ToTensor()])\n\ntransform &lt;- function(img) {\n  # img &lt;- torchvision::transform_pad(img, 4) # pas implémenté\n  # img &lt;- torchvision::transform_random_horizontal_flip(img) # pas implémenté\n  # img &lt;- torchvision::transform_random_crop(img, 32) # bug sur la taille des images\n  img &lt;- torchvision::transform_to_tensor(img)\n  return(img)\n}\n\nVoici le code pour chager les données en python et R :\nnum_samples = 1000\n\ntrainData = torchvision.datasets.CIFAR10(root=\"./data\",\n                                         train=True,\n                                         transform=transform,\n                                         download=True)\n\ntestData = torchvision.datasets.CIFAR10(root=\"./data\",\n                                        train=False,\n                                        transform=transforms.ToTensor())\n\ntrainLoader = torch.utils.data.DataLoader(\n    dataset=Subset(trainData, range(num_samples)),\n    batch_size=256,\n    shuffle=True)\n\ntestLoader = torch.utils.data.DataLoader(\n    dataset=Subset(testData, range(num_samples)),\n    batch_size=256,\n    shuffle=False)\n\nnum_samples = 1000\n\ntrain_data &lt;- torchvision::cifar10_dataset(\n  root = \"./data\",\n  train = TRUE,\n  transform = transform,\n  download = TRUE\n)\n\ntest_data &lt;- torchvision::cifar10_dataset(\n  root = \"./data\",\n  train = FALSE,\n  transform = torchvision::transform_to_tensor\n)\n\ntrain_loader &lt;- dataloader(\n  dataset = dataset_subset(train_data, 1:num_samples),\n  batch_size = 256,\n  shuffle = TRUE\n)\n\ntest_loader &lt;- dataloader(\n  dataset = dataset_subset(test_data, 1:num_samples),\n  batch_size = 256,\n  shuffle = FALSE\n)\n\n\n\nConstruction d’un block residual\nPour définir notre block residual, on crée une classe torch.nn.Module et on y définit deux méthodes : __init__ et forward : qui hérite de torch.nn.Module.\ndef align(num_in, num_out, stride):\n    if num_in != num_out or stride &gt; 1:\n        return nn.Sequential(\n            nn.Conv2d(\n                num_in, num_out, kernel_size=3, stride=stride, padding=1, bias=False\n                ),\n            nn.BatchNorm2d(num_out)\n            )\n    else:\n        return lambda x: x\n\nclass ResBlock(nn.Module):\n    def __init__(self, num_in, num_out, stride):\n        super(ResBlock, self).__init__()\n        self.align = align(num_in, num_out, stride)\n        self.conv1 = nn.Conv2d(num_in, num_out, kernel_size=3,\n                            stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(num_out)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(num_out, num_out, kernel_size=3,\n                            stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(num_out)\n\n    def forward(self, x):\n        o = self.conv1(x)\n        o = self.bn1(o)\n        o = self.relu(o)\n        o = self.conv2(o)\n        o = self.bn2(o)\n        o = o + self.align(x)\n        o = self.relu(o)\n        return o\nDe la même manière, on peut créer un objet nn_module en R et y spécifier init et forward :\n\nalign &lt;- function(num_in, num_out, stride) {\n  if (num_in != num_out || stride &gt; 1) {\n    return(nn_sequential(\n      nn_conv2d(\n        num_in, num_out,\n        kernel_size = 3, stride = stride, padding = 1,\n        bias = FALSE\n      ),\n      nn_batch_norm2d(num_out)\n    ))\n  } else {\n    return(function(x) x)\n  }\n}\n\nres_block &lt;- nn_module(\n  initialize = function(num_in, num_out, stride) {\n    self$align &lt;- align(num_in, num_out, stride)\n    self$conv1 &lt;- nn_conv2d(num_in, num_out,\n      kernel_size = 3,\n      stride = stride, padding = 1, bias = FALSE\n    )\n    self$bn1 &lt;- nn_batch_norm2d(num_out)\n    self$relu &lt;- nn_relu(inplace = TRUE)\n    self$conv2 &lt;- nn_conv2d(num_out, num_out,\n      kernel_size = 3,\n      stride = 1, padding = 1, bias = FALSE\n    )\n    self$bn2 &lt;- nn_batch_norm2d(num_out)\n  },\n  forward = function(x) {\n    o &lt;- self$conv1(x)\n    o &lt;- self$bn1(o)\n    o &lt;- self$relu(o)\n    o &lt;- self$conv2(o)\n    o &lt;- self$bn2(o)\n    o &lt;- o + self$align(x)\n    o &lt;- self$relu(o)\n    return(o)\n  }\n)\n\n\n\nConstructeur ResNet\nPour construire notre ResNet, on veut créer des block residuals en chaîne. En python, on le fait de la manière suivante (toujours en utilisant torch.nn.Module) :\ndef buildResBlocks(num_in, num_out, stride, num_blocks):\n    blocks = [ResBlock(num_in, num_out, stride)]\n    for _ in range(1, num_blocks):\n        blocks.append(ResBlock(num_out, num_out, 1))\n    return nn.Sequential(*blocks)\n\nclass ResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet, self).__init__()\n        self.blocks0 = nn.Sequential(\n            nn.Conv2d(\n                3, 16, kernel_size=3,\n                stride=1, padding=1, bias=False\n                ),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True)\n            )\n        self.blocks1 = buildResBlocks(16, 16, 1, 2)\n        self.blocks2 = buildResBlocks(16, 32, 2, 2)\n        self.blocks3 = buildResBlocks(32, 64, 2, 2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        n = x.shape[0]\n        o = self.blocks0(x)\n        o = self.blocks1(o)\n        o = self.blocks2(o)\n        o = self.blocks3(o)\n        o = self.avgpool(o)\n        o = self.fc(o.reshape(n, -1))\n        return o\nEn R, cela donne :\n\nbuild_res_blocks &lt;- function(num_in, num_out, stride, num_blocks) {\n  blocks &lt;- list(res_block(num_in, num_out, stride))\n  for (i in 2:num_blocks) {\n    blocks[[i]] &lt;- res_block(num_out, num_out, 1)\n  }\n  return(do.call(nn_sequential, blocks))\n}\n\nres_net &lt;- nn_module(\n  initialize = function(num_classes) {\n    self$blocks0 &lt;- nn_sequential(\n      nn_conv2d(\n        3,\n        16,\n        kernel_size = 3,\n        stride = 1,\n        padding = 1,\n        bias = FALSE\n      ),\n      nn_batch_norm2d(16),\n      nn_relu(inplace = TRUE)\n    )\n    self$blocks1 &lt;- build_res_blocks(16, 16, 1, 2)\n    self$blocks2 &lt;- build_res_blocks(16, 32, 2, 2)\n    self$blocks3 &lt;- build_res_blocks(32, 64, 2, 2)\n    self$avgpool &lt;- nn_avg_pool2d(kernel_size = 8)\n    self$fc &lt;- nn_linear(64, num_classes)\n  },\n  forward = function(x) {\n    n &lt;- dim(x)[1]\n    o &lt;- self$blocks0(x)\n    o &lt;- self$blocks1(o)\n    o &lt;- self$blocks2(o)\n    o &lt;- self$blocks3(o)\n    o &lt;- self$avgpool(o)\n    o &lt;- torch_flatten(o, start_dim = 2)\n    o &lt;- self$fc(o)\n    return(o)\n  }\n)\n\n\n\nInstantiation model et optimiseurs\nPartie un peu plus rapide et simple, quasi identique dans les deux cas :\ndevice = \"cpu\"\nmodel = ResNet(10).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ndevice = \"cpu\"\nmodel &lt;- res_net$new(10)$to(device = device)\nmodel\n\nAn `nn_module` containing 195,738 parameters.\n\n── Modules ─────────────────────────────────────────────────────────────────────\n• blocks0: &lt;nn_sequential&gt; #464 parameters\n• blocks1: &lt;nn_sequential&gt; #9,344 parameters\n• blocks2: &lt;nn_sequential&gt; #37,184 parameters\n• blocks3: &lt;nn_sequential&gt; #148,096 parameters\n• avgpool: &lt;nn_avg_pool2d&gt; #0 parameters\n• fc: &lt;nn_linear&gt; #650 parameters\n\n\n\noptimizer &lt;- optim_adam(model$parameters, lr = 0.001)\noptimizer\n\n&lt;optim_adam&gt;\n  Inherits from: &lt;torch_optimizer&gt;\n  Public:\n    add_param_group: function (param_group) \n    clone: function (deep = FALSE) \n    defaults: list\n    initialize: function (params, lr = 0.001, betas = c(0.9, 0.999), eps = 1e-08, \n    load_state_dict: function (state_dict, ..., .refer_to_state_dict = FALSE) \n    param_groups: list\n    state: State, R6\n    state_dict: function () \n    step: function (closure = NULL) \n    zero_grad: function () \n  Private:\n    step_helper: function (closure, loop_fun) \n\n\n\n\nApprentissage\ndef train():\n    for epoch in range(1, 11):\n        for i, (x, y) in enumerate(trainLoader):\n            (x, y) = x.to(device), y.to(device)\n            o = model(x)\n            loss = F.cross_entropy(o, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if i % 100 == 0:\n                 print(\"Epoch: {}\\tLoss: {}\".format(epoch, loss.item()))\n\ntrain &lt;- function() {\n  for (epoch in 1:10) {\n    i &lt;- 0\n    coro::loop(for (batch in train_loader) {\n      x &lt;- batch[[1]]\n      y &lt;- batch[[2]]\n      o &lt;- model(x)\n      loss &lt;- nnf_cross_entropy(o, y)\n\n      optimizer$zero_grad()\n      loss$backward()\n      optimizer$step()\n      if (i %% 100 == 0) {\n        cat(sprintf(\"Epoch: %d\\tLoss: %.4f\\n\", epoch, loss$item()))\n      }\n      i &lt;- i + 1\n    })\n  }\n}\n\n\n\nComparaison temps de calcul\ntic = time.time()\ntrain()\nprint(time.time()-tic, \"s\")\n\ntic &lt;- system.time(\n  train()\n)\n\nEpoch: 1    Loss: 2.6272\nEpoch: 2    Loss: 2.0250\nEpoch: 3    Loss: 1.9189\nEpoch: 4    Loss: 1.7768\nEpoch: 5    Loss: 1.6845\nEpoch: 6    Loss: 1.5591\nEpoch: 7    Loss: 1.4958\nEpoch: 8    Loss: 1.2789\nEpoch: 9    Loss: 1.2640\nEpoch: 10   Loss: 1.1744\n\ntic\n\n   user  system elapsed \n 42.978   3.890  31.170 \n\n\nSur mon ordinateurs : - python : 27.6s (elapsed) - R : 33.1s\nDes temps de calcul très comparables !\n\n\nPrécision\nPour tester la précision :\nn, N = 0, 0\nwith torch.no_grad():\n    for (x, y) in testLoader:\n        (x, y) = x.to(device), y.to(device)\n        o = model(x)\n        _, ŷ = torch.max(o, 1)\n        N += y.size(0)\n        n += torch.sum(ŷ == y).item()\n    print(\"Accuracy: {}\".format(n/N))\n\nwith_no_grad({\n  n_tests_ok &lt;- 0\n  n_tests &lt;- 0\n  coro::loop(for (batch in test_loader) {\n    x &lt;- batch[[1]]\n    y &lt;- batch[[2]]\n    o &lt;- model(x)\n    yest &lt;- torch_max(o, dim = 2)[[2]]\n    n_tests &lt;- n_tests + y$shape\n    n_tests_ok &lt;- n_tests_ok + torch_sum(y == yest)$item()\n  })\n  cat(\"Accuracy\", n_tests_ok / n_tests, \"\\n\")\n})\n\nAccuracy 0.408 \n\n\nLes deux codes donnent des résultats semblables !"
  },
  {
    "objectID": "jit-example-pln.html",
    "href": "jit-example-pln.html",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "Hugo Gangloff"
  },
  {
    "objectID": "jit-example-pln.html#jit-with-pytorch",
    "href": "jit-example-pln.html#jit-with-pytorch",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "Hugo Gangloff"
  },
  {
    "objectID": "jit-example-pln.html#set-up",
    "href": "jit-example-pln.html#set-up",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Set-up",
    "text": "Set-up\nReferences to pytorch jit, by order of difficulty:\n\npytorch jit official documentation\npytorch jit trace documentation\nTorchScript official tutorial\npytorch jit intermediate guide\npytorch jit intermediate / advanced guide\npytorch jit advanced guide\n\nMake necessary imports\n\nimport torch\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\n\nUsing a GPU.\n\n\nNOTE: We use pytorch GPU ! JIT compilation is particularly efficient on GPU. On this particular example, we were not able to see any speed up on CPU between jitted code and non-jitted code. We suppose it might be possible to get a CPU speed up on other case study, considering neural networks for example..\n\ndevice =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\ntorch.set_default_dtype(torch.float32)\nmyfloat = np.float32\n\ncuda\n\n\n\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 5000\nlr = 1e-2"
  },
  {
    "objectID": "jit-example-pln.html#original-non-jitted-version",
    "href": "jit-example-pln.html#original-non-jitted-version",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Original non-jitted version",
    "text": "Original non-jitted version\nWe reuse the code from torch for R versus pytorch.\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device:\n    torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol=1e-8) :\n      self.ELBO = np.zeros(N_iter, dtype=myfloat)\n      optimizer = torch.optim.Adam([self.B, self.M, self.S], lr=lr)\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n\nLet’s create the PLN object:\n\n%%time\nmyPLN = PLN(Y, O, X, device)\n\nCPU times: user 281 ms, sys: 48.8 ms, total: 330 ms\nWall time: 85.5 ms\n\n\nand run the learning process:\n\n%%time\nmyPLN.fit(N_iter, lr = lr, tol=1e-8)\n\nCPU times: user 34.3 s, sys: 168 ms, total: 34.5 s\nWall time: 34.8 s"
  },
  {
    "objectID": "jit-example-pln.html#eager-graph-mode",
    "href": "jit-example-pln.html#eager-graph-mode",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Eager graph mode",
    "text": "Eager graph mode\nThere are two ways to create the computational graph: eager execution and graph execution. The default mode in Pytorch is eager, this means the computational graph is created at each forward pass in the graph. On the other hand, the graph mode adds an additional compilation step which builds the graph only once and lets the computations be done at a lower level.\nJIT (Just In Time) compilation is the process that builds an Intermediate Representation (IR) of the graph. This is the additional compilation step mentioned above.\nUsing graph mode, we gain:\n\nefficiency since the graph is precomputed and can be optimized to factorize redundant operations or delete useless operations.\nportability since this IR can be reused in another language.\n\nHowever, we lose:\n\nflexibility since we are tied to fixed array sizes, we cannot easily use control flows, …\n\nThere are two ways in Pytorch to JIT our code, hence, there are two ways to use require the graph mode. We study these two ways in the next sections."
  },
  {
    "objectID": "jit-example-pln.html#jit-with-torch.jit.script",
    "href": "jit-example-pln.html#jit-with-torch.jit.script",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "JIT with torch.jit.script",
    "text": "JIT with torch.jit.script\nBy reading the above mentioned references, we get that we cannot jit the fit function. Some reasons are:\n\nN_iter is variable at compilation time (shape might change depending on input).\nthe torch optimizer’s operations cannot be jitted.\nthe jit script cannot handle control flow or loops.\n\n\nclass jitPLN(torch.jit.ScriptModule) :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        super().__init__()\n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    @torch.jit.script_method\n    def _log_stirling(self, integer):\n        integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n        return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\n    @torch.jit.script_method\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    @torch.jit.script_method\n    def get_inv(self, S):\n      return torch.inverse(S)\n\n    @torch.jit.script_method\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(self._log_stirling(self.Y))\n      return elbo\n\ndef fit(pln, N_iter, lr, tol = 1e-8) :\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - pln.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = pln.get_Sigma()\n        pln.Omega = pln.get_inv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\n\nLet’s create the jitted PLN object:\n\n%%time\nmyjitPLN = jitPLN(Y, O, X, device)\n\nCPU times: user 206 ms, sys: 0 ns, total: 206 ms\nWall time: 16.4 ms\n\n\nand run the learning process:\n\n%%time\nscriptELBO = fit(myjitPLN, N_iter, lr = lr, tol = 1e-8)\n\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: operator() profile_node %760 : int[] = prim::profile_ivalue(%dims.24)\n does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\n\nCPU times: user 26.1 s, sys: 177 ms, total: 26.2 s\nWall time: 26.8 s"
  },
  {
    "objectID": "jit-example-pln.html#jit-with-torch.jit.trace",
    "href": "jit-example-pln.html#jit-with-torch.jit.trace",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "JIT with torch.jit.trace",
    "text": "JIT with torch.jit.trace\nHere we jit trace each of the computational functions, the PLN class is just a container for the objects. The previous limitations from jit script are still present, notably, we cannot jit the main for loop.\n\nclass tracejitPLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : torch.Tensor\n    p : torch.Tensor\n    d : torch.Tensor\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.n = torch.tensor(self.n)\n        self.p = torch.tensor(self.p)\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n        self.device = device\n\nLet’s create the PLN object and the jitted functions:\n\n%%time\nmytracePLN = tracejitPLN(Y, O, X, device)\n\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\ntraced_logstirling = torch.jit.trace(_log_stirling, (mytracePLN.Y))\n\ndef get_ELBO(S, X, B, O, M, n, Omega, Y, p): \n    S2 = torch.square(S)\n    XB = X @ B\n    A = torch.exp(O + M + XB + S2/2)\n\n    elbo = n/2 * torch.logdet(Omega)\n    elbo += torch.sum(- A + Y * (O + M + XB) + .5 * torch.log(S2))\n    elbo -= .5 * torch.trace(M.T @ M + torch.diag(torch.sum(S2, dim = 0)) @ Omega)\n    elbo += .5 * n * p  - torch.sum(traced_logstirling(Y))\n    return elbo\n\ntraced_getELBO = torch.jit.trace(get_ELBO, (mytracePLN.S, mytracePLN.X, mytracePLN.B, mytracePLN.O, mytracePLN.M,\n    mytracePLN.n, mytracePLN.Omega, mytracePLN.Y, mytracePLN.p))\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + torch.diag(torch.sum(S**2, dim = 0)))\n\ntraced_getSigma = torch.jit.trace(get_Sigma, (mytracePLN.n, mytracePLN.M, mytracePLN.S))\n\ndef get_inv(S):\n    return torch.inverse(S)\n\ntraced_getInv = torch.jit.trace(get_inv, get_Sigma(mytracePLN.n, mytracePLN.M, mytracePLN.S))\n\nCPU times: user 233 ms, sys: 9.87 ms, total: 242 ms\nWall time: 43.5 ms\n\n\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n  if a.grad is not None:\n\n\n\ndef tracefit(pln, N_iter, lr, tol = 1e-8) :\n\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -traced_getELBO(pln.S, pln.X, pln.B, pln.O, pln.M,\n            pln.n, pln.Omega, pln.Y, pln.p)\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = traced_getSigma(pln.n, pln.M, pln.S)\n        pln.Omega = traced_getInv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\n\nand run the learning process:\n\n%%time\ntraceELBO = tracefit(mytracePLN, N_iter, lr = lr, tol = 1e-8)\n\nCPU times: user 25.5 s, sys: 142 ms, total: 25.6 s\nWall time: 26.4 s"
  },
  {
    "objectID": "jit-example-pln.html#conclusion",
    "href": "jit-example-pln.html#conclusion",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Conclusion",
    "text": "Conclusion\nWe check that we get the same results with each method:\n\nplt.plot(np.log(-myPLN.ELBO), label='NO jit')\nplt.plot(np.log(-scriptELBO), label='jit script')\nplt.plot(np.log(-traceELBO), label='jit trace')\nplt.legend()\nplt.show()\n\n\n\n\nWe see that jit script and jit trace reduce computation time by a few second over the non jitted code. Hence, jit compilation in pytorch can be interesting but induces strict limitations that the user must be aware of.\nAlso, we should try to consider a more involved problem computationally speaking (bigger input data, computations involving neural networks, …)"
  },
  {
    "objectID": "torch_Python_regression.html",
    "href": "torch_Python_regression.html",
    "title": "Introduction à Pytorch",
    "section": "",
    "text": "Cette page constitue une traduction en Python avec pytorch de la page équivalente produite avec {torch} lors de FinistR 2022"
  },
  {
    "objectID": "torch_Python_regression.html#installation",
    "href": "torch_Python_regression.html#installation",
    "title": "Introduction à Pytorch",
    "section": "Installation",
    "text": "Installation\nUne façon (parmi d’autres) d’avoir une installation fonctionnelle de torch consiste à l’installer via conda. La page officielle est très bien documentée et fournit toutes les instructions nécessaires. La solution adoptée ici consiste à créer un environnement conda (nommé torch) pour y installer torch (en version CPU).\n#| eval: false\nconda create -n torch\nconda install pytorch torchvision torchaudio cpuonly -c pytorch\nconda install pandas matplotlib scikit-learn jupyter\nIl suffit alors d’activer l’environnement torch pour produire le html à partir du qmd\n#| eval: false\nconda activate torch\nquarto render my_document.qmd --to html"
  },
  {
    "objectID": "torch_Python_regression.html#exploration-de-torch-pour-la-différentiation-automatique",
    "href": "torch_Python_regression.html#exploration-de-torch-pour-la-différentiation-automatique",
    "title": "Introduction à Pytorch",
    "section": "Exploration de {torch} pour la différentiation automatique",
    "text": "Exploration de {torch} pour la différentiation automatique\n\nimport torch\nimport torch.distributions as dist\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression"
  },
  {
    "objectID": "torch_Python_regression.html#principe-du-calcul-de-gradient",
    "href": "torch_Python_regression.html#principe-du-calcul-de-gradient",
    "title": "Introduction à Pytorch",
    "section": "Principe du calcul de gradient",
    "text": "Principe du calcul de gradient\n{torch} fonctionne avec ses propres types numériques, qu’il faut créer avec la fonction torch.tensor() et ses propres fonctions torch.*(). Considérons un exemple très simple: \\(x \\mapsto x^2\\)\n\nx = torch.tensor(3)\ny = torch.square(x)\n\n\ny\n\ntensor(9)\n\n\nOn va pouvoir calculer \\(\\frac{dy}{dx}\\) en définissant x avec l’argument require_grad = True. Cet argument va spécifier que ‘x’ est entrainable et va démarrer l’enregistrement par autograd des opérations sur ce tenseur.\nAutograd est un module de torch qui permet de collecter les gradients. Il le fait en enregistrant des données (tenseurs) et toutes les opérations exécutées dans un graphe acyclique dirigé dont les feuilles sont les tenseurs d’entrée et les racines les tenseurs de sorties. Ces opérations sont stockées comme des fonctions et au moment du calcul des gradients, sont appliquées depuis le noeud de sortie en ‘backpropagation’ le long du réseau.\nAttention, torch ne peut stocker un gradient que pour des valeurs numériques (float), pas pour des entiers.\n\nx = torch.tensor(2.0, requires_grad = True)\nx\n\ntensor(2., requires_grad=True)\n\n\nOn remarque que x possède désormais un champ grad (même si ce dernier n’est pas encore défini).\n\nx.grad\n\nLorsqu’on calcule \\(y = x^2\\), ce dernier va également hériter d’un nouveau champ $grad_fn:\n\ny = torch.log(torch.square(x))\ny\ny.grad_fn\n\n&lt;LogBackward0 at 0x7f111c4eb9d0&gt;\n\n\nqui indique comment calculer le gradient en utilisant la dérivée des fonctions composées:\n\\[\n(g\\circ f)'(x) = f'(x) \\times g'(f(x))\n\\]\net les fonctions\n\\[\n\\frac{dx^2}{dx} = 2x \\quad \\frac{d \\log(x)}{dx} = \\frac{1}{x}\n\\]\nLe calcul effectif du gradient est déclenché lors de l’appel à la méthode .backward() de y et est stocké dans le champ .grad de x.\n\nx.grad ## gradient non défini\ny.backward() \nx.grad ## gradient défini = 1\n\ntensor(1.)\n\n\nOn a bien:\n\\[\n\\frac{dy}{dx} = \\underbrace{\\frac{dy}{dz}}_{\\log}(z) \\times \\underbrace{\\frac{dz}{dx}}_{\\text{power}}(x) = \\frac{1}{4} \\times 2*2 = 1\n\\]\nIntuitivement au moment du calcul de y, torch construit un graphe computationnel qui lui permet d’évaluer numériquement \\(y\\) et qui va également servir pour calculer \\(\\frac{dy}{dz}\\) au moment de l’appel à la fonction .backward() issue du module autograd.\nEssayons de reproduire le calcul dans notre exemple. Le calcul forward donne\n\\[\nx = 2 \\xrightarrow{x \\mapsto x^2} z = 4 \\mapsto \\xrightarrow{x \\mapsto \\log(x)} y = \\log(4)\n\\]\nPour le calcul backward, il faut donc construire le graphe formel suivant. La première étape du graphe est accessible via $grad_fn\n\ny.grad_fn\n\n&lt;LogBackward0 at 0x7f111c4eb9d0&gt;\n\n\net les fonctions suivantes via $next_functions\n\ny.grad_fn.next_functions\n\n((&lt;PowBackward0 at 0x7f111c4e97b0&gt;, 0),)\n\n\nDans notre exemple, on a donc:\n\\[\n\\frac{dy}{dy} = 1 \\xrightarrow{x \\mapsto \\text{logBackward}(x)} \\frac{dy}{dz} = \\frac{dy}{dy} \\times \\text{logBackward}(z) \\xrightarrow{x \\mapsto \\text{powerBackward}(x)} \\frac{dy}{dx} = \\frac{dy}{dz} \\times \\text{logBackward}(x)\n\\]\nDans cet exemple:\n\n\\(\\text{logBackward}(x) = \\frac{1}{x}\\)\n\\(\\text{powBackward}(x) = 2x\\)\n\nEt la propagation des dérivées donne donc\n\\[\n\\frac{dy}{dy} = 1 \\to \\frac{dy}{dz} = 1 \\times \\frac{1}{4} = \\frac{1}{4} \\to \\frac{dy}{dx} = \\frac{1}{4} \\times 4 = 1\n\\]\nCe graphe est illustré ci-dessous pour la fonction \\((x_1, x_2) \\mapsto z = sin(x_2) log(x_1 x_2)\\)\n\nPour (beaucoup) plus de détails sur le graphe computationnel, on peut consulter la documentation officielle de PyTorch.\nIl faut juste noter que dans torch, le graphe computationnel est construit de façon dynamique, au moment du calcul de y."
  },
  {
    "objectID": "torch_Python_regression.html#régression-logistique-avec-torch",
    "href": "torch_Python_regression.html#régression-logistique-avec-torch",
    "title": "Introduction à Pytorch",
    "section": "Régression logistique avec torch",
    "text": "Régression logistique avec torch\nOn va adopter un simple modèle de régression logistique:\n\\[\nY_i \\sim \\mathcal{B}(\\sigma(\\theta^T x_i)) \\quad \\text{avec} \\quad \\sigma(x) = \\frac{1}{1 + e^{x}}\n\\]\nLe but est d’estimer \\(\\theta\\) et éventuellement les erreurs associées. On commence par générer des données.\n\n# Générer les paramètres\ntorch.manual_seed(45)\nn = 100\np = 3\n# Générer la matrice X\nX = torch.randn(n, p)\n# Générer le vecteur theta\ntheta = torch.randn(3)\n# Calculer les probabilités\nprobs = 1 / (1 + torch.exp(torch.mv(X, theta)))\n# Générer les observations Y en utilisant une distribution Bernoulli\nbernoulli_dist = dist.Bernoulli(probs=probs)\nY = bernoulli_dist.sample()\n\ntorch fonctionne avec ses propres types numériques, qu’il faut créer avec la fonction torch.tensor(). C’est ce qu’on a fait avec les fonctions torch.randn() et bernoulli_dist.sample() mais on pourrait forcer la conversion avec torch.tensor().\n\nx = X.clone()\ny = Y.clone()\n\nOn écrit ensuite la fonction de vraisemblance\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta) = \\sum_{i=1}^n y_i (\\theta^Tx_i) - \\sum_{i=1}^n log(1 + e^{\\theta^T x_i})\n\\]\n\ndef logistic_loss(theta, x, y):\n    odds = torch.mv(x, theta)\n    log_lik = torch.dot(y, odds) - torch.sum(torch.log(1 + torch.exp(odds)))\n    return -log_lik\n\navant de vérifier qu’elle fonctionne:\n\nlogistic_loss(theta = theta, x = x, y = y)\n\ntensor(80.1576)\n\n\nOn veut ensuite définir une fonction objective à maximiser (qui ne dépend que de theta):\n\ndef eval_loss(theta, verbose=True):\n    loss = logistic_loss(theta, x, y)\n    if verbose:\n        print(\"Theta:\", theta, \": Loss:\", float(loss))\n    return loss\n\net vérifier qu’elle fonctionne\n\neval_loss(theta, verbose = True)\n\nTheta: tensor([-0.2633, -0.2123,  0.5694]) : Loss: 80.15764617919922\n\n\ntensor(80.1576)\n\n\navant de procéder à l’optimisation à proprement parler. Pour cette dernière, on commence par définir notre paramètre sous forme d’un tenseur qui va être mis à jour\n\ntheta_current = torch.zeros(len(theta), requires_grad=True)\n\net d’un optimiseur:\n\noptimizer = optim.Rprop([theta_current])\n\nOn considère ici l’optimiseur Rprop (resilient backpropagation) qui ne prend pas en compte l’amplitude du gradient mais uniquement le signe de ses coordonnées (voir ici pour une introduction pédagogique à Rprop).\nIntuitivement, l’optimiseur a juste besoin de la valeur de \\(\\theta\\) et de son gradient pour le mettre à jour. Mais à ce stade on ne connaît pas encore le gradient \\(\\nabla_\\theta \\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta)\\)\n\ntheta_current.grad\n\net il faut donc le calculer:\n\nloss = eval_loss(theta_current, verbose = False)\nloss.backward()\n\nOn peut vérifier que le gradient est stocké dans theta\n\ntheta_current.grad\n\ntensor([-5.4452, -9.6232,  5.0331])\n\n\net effectuer la mise à jour avec une étape d’optimisation\n\noptimizer.step()\n\nOn peut vérifier que le paramètre courant a été mis à jour.\n\ntheta_current\n\ntensor([ 0.0100,  0.0100, -0.0100], requires_grad=True)\n\n\nIl ne reste plus qu’à recommencer pour un nombre d’itérations donné. Attention, il faut réinitialiser le gradient avant de le mettre à jour, le comportement par défaut de mise à jour étant l’accumulation plutôt que le remplacement.\n\nnum_iterations = 100\nloss_vector = []\n\nfor i in range(num_iterations):\n    optimizer.zero_grad()\n    loss = eval_loss(theta_current, verbose=False)\n    loss.backward()\n    optimizer.step()\n    loss_vector.append(loss.item())\n\nOn vérifie que la perte diminue au cours du temps.\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\nOn constate que notre optimiseur aboutit à peu près au même résultat que glm()\n\n# Ajustement du modèle GLM\nmodel = LogisticRegression(fit_intercept=False, penalty = None)\nmodel.fit(X, Y)\nsklearn_coeffs = model.coef_.tolist()[0]\n\n# Comparer les valeurs obtenues avec torch et glm\ndf = pd.DataFrame({\n    'torch': theta_current.detach().numpy().tolist(),\n    'sklearn': sklearn_coeffs\n})\nprint(df)\n\n      torch   sklearn\n0  0.125890  0.125891\n1  0.423915  0.423912\n2 -0.341099 -0.341100\n\n\nAttention la mécanique présentée ci-dessus avec .step() ne fonctionne pas pour certaines routines d’optimisation (BFGS, gradient conjugué) qui nécessite de calculer plusieurs fois la fonction objective. Dans ce cas, il faut définir une closure, qui renvoie la fonction objective, et la passer en argument à .step().\n\n%%time\n# Remise à zéro du paramètre courant\ntheta_current = torch.zeros(len(theta), requires_grad=True)\noptimizer = optim.Rprop([theta_current], lr=0.01)\n\n# Définition de la closure\ndef calc_loss():\n    optimizer.zero_grad()\n    loss = eval_loss(theta_current, verbose=False)\n    loss.backward()\n    return loss\n\n# Optimisation avec la closure\nnum_iterations = 100\nloss_vector = []\n\nfor i in range(num_iterations):\n    loss = optimizer.step(calc_loss).item()\n    loss_vector.append(loss)\n\nCPU times: user 38.7 ms, sys: 0 ns, total: 38.7 ms\nWall time: 38.6 ms\n\n\nOn peut vérifier qu’on obtient des résultats identiques dans les deux cas d’utilisation:\n\ntheta_current\n\ntensor([ 0.1259,  0.4239, -0.3411], requires_grad=True)\n\n\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()"
  },
  {
    "objectID": "torch_Python_regression.html#exemple-de-régression-multivariée",
    "href": "torch_Python_regression.html#exemple-de-régression-multivariée",
    "title": "Introduction à Pytorch",
    "section": "Exemple de régression multivariée",
    "text": "Exemple de régression multivariée\nOn considère un exemple de régression multiple, réalisé à partir du blog torch for optimization, où l’on cherche à estimer les paramètres de moyenne ainsi que la variance par maximisation de la vraisemblance.\nOn génère les données\n\n# Définir la graine aléatoire pour la reproductibilité\ntorch.manual_seed(45)\n# Générer la matrice X\nn = 100\nX = torch.cat((torch.ones(n, 1), torch.randn(n, 10)), dim=1)\n# Générer le vecteur Beta.true\nBeta_true = torch.randn(11)\n# Générer la variable dépendante Y\nY = torch.matmul(X, Beta_true) + torch.randn(n)\n\nLa fonction de perte à optimiser (ici la log-vraisemblance) va dépendre d’inputs définis comme des “tenseurs torch”:\n\n## Declare the parameter for the loss function\n## 11 parameters for Beta, 1 for sigma\nTheta = torch.ones(12, requires_grad = True)\n\nQuelques remarques :\n\nle paramètre \\(\\theta\\) à optimiser est ici défini comme un tenseur, i.e. un objet qui va notamment stocker la valeur courante de \\(\\theta\\). Avec l’option requires_grad=True la valeur courante du gradient de la dernière fonction appelée dépendant de \\(\\theta\\) va aussi être stockée.\nla matrice \\(X\\) est aussi définie comme un tenseur, mais l’option “requires_grad=TRUE” n’a pas été spécifiée, le gradient ne sera donc pas stocké pour cet objet. Cette distinction est explicitée lorsque l’on affiche les deux objets:\n\n\nTheta[:3]\nX[:3, :3]\n\ntensor([[ 1.0000,  0.1371,  1.5252],\n        [ 1.0000,  0.3665,  1.2984],\n        [ 1.0000, -0.1322,  0.0068]])\n\n\nLa fonction de perte est ici la log-vraisemblance, elle-même définie à partir d’opérateurs torch élémentaires :\n\ndef LogLik():\n    n = X.shape[0]  \n    # Last term of Theta is the std\n    sigma = Theta[11]\n    log_sigma = torch.log(sigma)\n    squared_residuals = torch.norm(Y - torch.matmul(X, Theta[:11])) ** 2\n    term1 = n * log_sigma\n    term2 = squared_residuals / (2 * (sigma ** 2))\n    return term1 + term2\n\nLa fonction LogLik peut être appliquée comme une fonction R qui prendra directement en argument les valeurs courantes de X.tensor et \\(\\theta\\), et produira en sortie un tenseur\n\nLogLik()\n\ntensor(736.3355, grad_fn=&lt;AddBackward0&gt;)\n\n\nOutre la valeur courante de la fonction, ce tenseur contient la “recette” du graphe computationnel utilisé dans calcul backward du gradient de la fonction LogLik par rapport à \\(\\theta\\). On peut ainsi afficher la dernière opération de ce graphe\n\ntoto = LogLik()\ntoto.grad_fn\n\n&lt;AddBackward0 at 0x7f111c4a1420&gt;\n\n\ncorrespondant à l’addition (AddBackward) des deux termes \\[  n\\times \\log(\\theta[11]) \\quad \\text{et} \\quad ||Y-X\\theta[0:10]||^2/(2*\\theta[11]^2)\\] dans le calcul de la perte. On peut afficher les opérations suivantes dans le graphe comme suit:\n\ntoto.grad_fn.next_functions\n\n((&lt;MulBackward0 at 0x7f1043d70550&gt;, 0), (&lt;DivBackward0 at 0x7f1043d73af0&gt;, 0))\n\n\nL’étape suivante consiste à choisir la méthode d’optimisation à appliquer. L’intérêt d’utiliser le package {torch} est d’avoir accès à une large gamme de méthodes d’optimisation, on considère ici la méthode rprop qui réalise une descente de gradient à pas adaptatif et spécifique à chaque coordonnée:\n\n## Specify the optimization parameters\nlr = 0.01\noptimizer = optim.Rprop([Theta],lr)\n\nOn décrit maintenant un pas de calcul du gradient, contenant les étapes suivantes : - réinitialisation du gradient de \\(\\theta\\),\n- évaluation de la fonction de perte (avec la valeur courante de \\(\\theta\\)),\n- calcul backward du gradient. On inclut tout cela dans une fonction:\n\n## Optimization step description\ndef calc_loss():\n    optimizer.zero_grad()\n    value = LogLik()\n    value.backward()\n    return value\n\nCommençons par regarder ce que fait concrètement cette fonction. L’état courant du paramètre est le suivant:\n\nTheta\nTheta.grad\n\nOn applique une première fois la fonction, et on obtient la mise à jour suivante :\n\ncalc_loss()\nTheta\nTheta.grad\n\ntensor([  -73.6607,   133.4165,  -100.1567,   134.5971,    38.0697,   123.4896,\n           49.8657,    82.5681,   -27.1204,   185.5123,   176.2979, -1372.6710])\n\n\nComme on le voit la valeur courante du paramètre n’a pas changée, en revanche Theta.grad contient maintenant le gradient de la fonction de perte calculé en \\(\\theta\\). Dans le cas où la méthode d’optimisation considérée n’a besoin que de la valeur courante du gradient et du paramètre, on peut directement faire la mise à jour de \\(\\theta\\) :\n\noptimizer.step()\nTheta\nTheta.grad\n\ntensor([  -73.6607,   133.4165,  -100.1567,   134.5971,    38.0697,   123.4896,\n           49.8657,    82.5681,   -27.1204,   185.5123,   176.2979, -1372.6710])\n\n\nIl n’y a plus qu’à itérer !\n\n%%time\n## Run the optimization\nnum_iterations = 100\nloss_vector = torch.empty(num_iterations)\n\nfor i in range(num_iterations):\n    loss_vector[i] = calc_loss().item()\n    optimizer.step()\n\nCPU times: user 54.3 ms, sys: 484 µs, total: 54.8 ms\nWall time: 54.6 ms\n\n\nOn vérifie que l’optimisation s’est bien passée (ie que l’on a minimisé la fonction de perte)\n\n## How does the loss function behave ?\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n## Are the gradients at 0 ?\nTheta.grad\n\n\n\n\ntensor([-7.5638e-05, -8.4504e-05,  3.2596e-05, -4.3469e-05, -8.8593e-05,\n         9.8785e-05,  3.1149e-05, -7.0865e-05, -1.0586e-04,  8.9571e-05,\n         4.5321e-05,  5.3406e-05])\n\n\net que le résultat est comparable à la solution classique obtenue par OLS :\n\n# Ajuster un modèle de régression linéaire avec scikit-learn\nregressor = LinearRegression(fit_intercept=False)\nregressor.fit(X, Y)\n\n# Obtenir les coefficients du modèle\nbeta_hat = regressor.coef_\n\n# Afficher les coefficients et tracer une ligne y = x\nprint(\"Coefficients du modèle de régression linéaire :\\n\", beta_hat)\nprint(\"Coefficients de Theta :\\n\", Theta[:11].detach().numpy().tolist())\n\n# Tracer la ligne y = x pour la comparaison\nplt.scatter(beta_hat, Theta[:11].detach().numpy().tolist())\nplt.plot([beta_hat.min(), beta_hat.max()], [beta_hat.min(), beta_hat.max()], color='red', linestyle='--')\nplt.xlabel('Coefficients du modèle de régression linéaire')\nplt.ylabel('Coefficients de Theta')\nplt.title('Comparaison des coefficients')\nplt.show()\n\n# Calculer la variance des résidus\nresiduals = Y - torch.matmul(X, torch.tensor(beta_hat).t())\nsigma_squared_lm = np.var(residuals.detach().numpy())\nsigma_squared_theta = Theta[11]\n\nprint(\"Variance du modèle de régression linéaire :\", sigma_squared_lm)\nprint(\"Variance de Theta[12] :\", sigma_squared_theta.item())\n\nCoefficients du modèle de régression linéaire :\n [ 1.7637295  -0.32114246  1.4978632  -0.11171225  0.40113908 -0.06434418\n  0.2032495  -0.25903088  0.9809813  -0.7663111  -0.6479076 ]\nCoefficients de Theta :\n [1.763728141784668, -0.3211430013179779, 1.4978625774383545, -0.11171171814203262, 0.40113818645477295, -0.06434360891580582, 0.20324911177158356, -0.2590320408344269, 0.9809804558753967, -0.7663102149963379, -0.6479072570800781]\nVariance du modèle de régression linéaire : 1.2505516\nVariance de Theta[12] : 1.1182799339294434"
  }
]