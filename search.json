[
  {
    "objectID": "torch_test-brulee.html",
    "href": "torch_test-brulee.html",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "",
    "text": "L’idée ici est d’explorer la régression logistique en utilisant {torch} à l’aide du package {brulee}.\n\nlibrary(torch)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.7\n✔ dials        1.2.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.2     ✔ tibble       3.2.1\n✔ ggplot2      3.4.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.1\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(brulee)"
  },
  {
    "objectID": "torch_test-brulee.html#introduction",
    "href": "torch_test-brulee.html#introduction",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "",
    "text": "L’idée ici est d’explorer la régression logistique en utilisant {torch} à l’aide du package {brulee}.\n\nlibrary(torch)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.7\n✔ dials        1.2.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.2     ✔ tibble       3.2.1\n✔ ggplot2      3.4.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.1\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(brulee)"
  },
  {
    "objectID": "torch_test-brulee.html#exemple",
    "href": "torch_test-brulee.html#exemple",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "Exemple",
    "text": "Exemple\nOn reprend l’exemple détaillé l’an dernier pour la régression logistique, disponible à la page https://stateofther.github.io/finistR2022/autodiff.html.\n\nset.seed(45)\nn &lt;- 100\np &lt;- 3\nX &lt;- matrix(rnorm(n = n*p), ncol = p, nrow = n)\ntheta &lt;- rnorm(3) %&gt;% round(digits = 2)\nprobs &lt;- (X %*% theta) %&gt;% as.vector()\nY &lt;- purrr::rbernoulli(n = n, p = probs) + 0.\n\nWarning: `rbernoulli()` was deprecated in purrr 1.0.0.\n\nx &lt;- torch_tensor(X)\ny &lt;- torch_tensor(Y)\n\nlogistic_loss &lt;- function(theta, x, y) {\n  if (!is(theta, \"torch_tensor\")) {\n    stop(\"theta must be a torch tensor\")\n  }\n  odds &lt;- torch_matmul(x, theta)\n  log_lik &lt;- torch_dot(y, odds) - torch_sum(torch_log(1 + torch_exp(odds)))\n  return(-log_lik)\n}\nlogistic_loss(theta = torch_tensor(theta), x = x, y = y)\n\ntorch_tensor\n50.4573\n[ CPUFloatType{} ]\n\neval_loss &lt;- function(theta, verbose = TRUE) {\n  loss &lt;- logistic_loss(theta, x, y)\n  if (verbose) {\n    cat(paste(theta |&gt; as.numeric(), collapse=\", \"), \": \", as.numeric(loss), \"\\n\")\n  }\n  return(loss)\n}\neval_loss(torch_tensor(theta), verbose = FALSE)\n\ntorch_tensor\n50.4573\n[ CPUFloatType{} ]\n\ntheta_current &lt;- torch_tensor(rep(0, length(theta)), requires_grad = TRUE)\ntheta_optimizer &lt;- optim_rprop(theta_current)\nloss &lt;- eval_loss(theta_current, verbose = FALSE)\nloss$backward()\ntheta_optimizer$step()\n\nNULL\n\nnum_iterations &lt;- 100\nloss_vector &lt;- vector(\"numeric\", length = num_iterations)\nfor (i in 1:num_iterations) {\n  theta_optimizer$zero_grad()\n  loss &lt;- eval_loss(theta_current, verbose = FALSE)\n  loss$backward()\n  theta_optimizer$step()\n  loss_vector[i] &lt;- loss %&gt;% as.numeric()\n}\ndplyr::tibble(\n  torch = theta_current |&gt; as.numeric(),\n  glm   = glm(Y ~ 0 + X, family = \"binomial\") |&gt; coefficients()\n)\n\n# A tibble: 3 × 2\n   torch    glm\n   &lt;dbl&gt;  &lt;dbl&gt;\n1  1.79   1.79 \n2 -1.04  -1.04 \n3 -0.973 -0.973"
  },
  {
    "objectID": "torch_test-brulee.html#tidymodels",
    "href": "torch_test-brulee.html#tidymodels",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "Tidymodels",
    "text": "Tidymodels\nIl est possible d’effectuer une régression logistique à l’aide de plusieurs engine dans {tidymodels} :\n\nshow_engines(\"logistic_reg\")\n\n# A tibble: 7 × 2\n  engine    mode          \n  &lt;chr&gt;     &lt;chr&gt;         \n1 glm       classification\n2 glmnet    classification\n3 LiblineaR classification\n4 spark     classification\n5 keras     classification\n6 stan      classification\n7 brulee    classification\n\n\nOn vérifie qu’on retrouve bien les mêmes coefficient en utilisant le package {glm} dans {tidymodels} pour effectuer notre régression logistique :\n\nset.seed(20)\ndata_df &lt;- data.frame(Y = as.factor(Y), X = X)\nlogistic_reg(engine = \"glm\") %&gt;% \n  fit(Y ~ 0 + X.1 + X.2 + X.3, family = \"binomial\", data = data_df) %&gt;% \n  extract_fit_engine() %&gt;% # besoin d'extraire l'objet lm\n  coef()\n\n       X.1        X.2        X.3 \n 1.7914697 -1.0379660 -0.9728552 \n\n\nLe package {brulee} de l’univers tidymodels propose différents modèles classiques (réseau de neurones, régression logistique, régression linéaire, régression multinomiale) via l’infrastructure torch. La liste des loss disponibles dans le package :\n\nls(pattern = \"loss$\", envir = asNamespace(\"torch\"))\n\n [1] \"nn_adaptive_log_softmax_with_loss\"    \n [2] \"nn_bce_loss\"                          \n [3] \"nn_bce_with_logits_loss\"              \n [4] \"nn_cosine_embedding_loss\"             \n [5] \"nn_cross_entropy_loss\"                \n [6] \"nn_ctc_loss\"                          \n [7] \"nn_hinge_embedding_loss\"              \n [8] \"nn_kl_div_loss\"                       \n [9] \"nn_l1_loss\"                           \n[10] \"nn_loss\"                              \n[11] \"nn_margin_ranking_loss\"               \n[12] \"nn_mse_loss\"                          \n[13] \"nn_multi_margin_loss\"                 \n[14] \"nn_multilabel_margin_loss\"            \n[15] \"nn_multilabel_soft_margin_loss\"       \n[16] \"nn_nll_loss\"                          \n[17] \"nn_poisson_nll_loss\"                  \n[18] \"nn_smooth_l1_loss\"                    \n[19] \"nn_soft_margin_loss\"                  \n[20] \"nn_triplet_margin_loss\"               \n[21] \"nn_triplet_margin_with_distance_loss\" \n[22] \"nn_weighted_loss\"                     \n[23] \"nnf_cosine_embedding_loss\"            \n[24] \"nnf_ctc_loss\"                         \n[25] \"nnf_hinge_embedding_loss\"             \n[26] \"nnf_l1_loss\"                          \n[27] \"nnf_margin_ranking_loss\"              \n[28] \"nnf_mse_loss\"                         \n[29] \"nnf_multi_margin_loss\"                \n[30] \"nnf_multilabel_margin_loss\"           \n[31] \"nnf_multilabel_soft_margin_loss\"      \n[32] \"nnf_nll_loss\"                         \n[33] \"nnf_poisson_nll_loss\"                 \n[34] \"nnf_smooth_l1_loss\"                   \n[35] \"nnf_soft_margin_loss\"                 \n[36] \"nnf_triplet_margin_loss\"              \n[37] \"nnf_triplet_margin_with_distance_loss\"\n[38] \"torch__ctc_loss\"                      \n[39] \"torch__cudnn_ctc_loss\"                \n[40] \"torch__use_cudnn_ctc_loss\"            \n[41] \"torch_cosine_embedding_loss\"          \n[42] \"torch_cross_entropy_loss\"             \n[43] \"torch_ctc_loss\"                       \n[44] \"torch_hinge_embedding_loss\"           \n[45] \"torch_huber_loss\"                     \n[46] \"torch_l1_loss\"                        \n[47] \"torch_margin_ranking_loss\"            \n[48] \"torch_mse_loss\"                       \n[49] \"torch_multi_margin_loss\"              \n[50] \"torch_multilabel_margin_loss\"         \n[51] \"torch_nll_loss\"                       \n[52] \"torch_poisson_nll_loss\"               \n[53] \"torch_smooth_l1_loss\"                 \n[54] \"torch_soft_margin_loss\"               \n[55] \"torch_triplet_margin_loss\"            \n\n\nOn va regarder ici comment faire la même régression logistique que précédemment. Il est possible de spécifier soit avec les données sous forme de data.frame soit en utilisant des matrices. Deux procédures d’optimisation sont disponibles : ‘LBFGS’ et ‘SGD’.\nA noter qu’il n’est pas possible de spécifier un modèle sans intercept, ni avec 0+ ni avec -1.\n\nreg_log_brulee2 &lt;- brulee_logistic_reg(x = as.matrix(X), y = as.factor(Y),\n                         epochs = num_iterations, optimizer = \"SGD\", validation = 0)\n\nreg_log_brulee1 &lt;- brulee_logistic_reg(Y ~ X.1 + X.2 + X.3, data = data_df,\n                         epochs = num_iterations, optimizer = \"SGD\", validation = 0)\n\nEn théorie il est possible récupérer les coefficients du modèle ajusté avec la méthode coef en spécifiant l’epoch désirée. Si epoch = NULL la meilleure epoch est choisie.\n\nreg_log_brulee2 %&gt;% coef()\n\n\nreg_log_brulee2$estimates[[100]]\n\n$fc1.weight\n          [,1]       [,2]      [,3]\n[1,] -1.096883  0.5906312  1.178145\n[2,]  1.788497 -0.9432783 -1.099946\n\n$fc1.bias\n[1]  1.451596 -1.311797"
  },
  {
    "objectID": "torch_R_PLN.html",
    "href": "torch_R_PLN.html",
    "title": "PLN version R",
    "section": "",
    "text": "On charge le jeu de données oaks contenu dans PLNmodels\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\ndata(oaks)\n\nPour référence, on optimise avec le package dédié (qui utilise le backend NLOpt, une bilbiothèque C++ d’optimisation non linéaire. La variance CCSQA, utilisant les gradients explicites, est utilisée).\n\nsystem.time(myPLN_nlopt &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks))\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  6.753   1.872   4.469 \n\n\n\n\n\nOn définit une simple classe avec une routine d’optimisation utilisant Rprop et l’auto-differentiation sur le critère à optimiser (l’ELBO = Expected Lower BOund).\n\nlibrary(torch)\nlibrary(R6)\n\nlog_stirling &lt;- function(n_){\n  n_ &lt;- n_+ (n_==0)\n  torch_log(torch_sqrt(2*pi*n_)) + n_*log(n_/exp(1))\n}\n\nPLN &lt;-\n  R6Class(\"PLN\",\n    public = list(\n      Y = NULL,\n      O = NULL,\n      X = NULL,\n      n = NULL,\n      p = NULL,\n      d = NULL,\n      M = NULL,\n      S = NULL,\n      A = NULL,\n      B = NULL,\n      Sigma = NULL,\n      Omega = NULL,\n      loglik = NULL,\n      ELBO_list = NULL,\n\n      ## Constructor\n      initialize = function(Y, O, X){\n        self$Y &lt;- torch_tensor(Y)\n        self$O &lt;- torch_tensor(O)\n        self$X &lt;- torch_tensor(X)\n        self$n &lt;- nrow(Y)\n        self$p &lt;- ncol(Y)\n        self$d &lt;- ncol(X)\n        ## Variational parameters\n        self$M &lt;- torch_zeros(self$n, self$p, requires_grad = TRUE)\n        self$S &lt;- torch_ones(self$n , self$p, requires_grad = TRUE)\n        ## Model parameters\n        self$B &lt;- torch_full(c(self$d, self$p), -8.0, requires_grad = TRUE)\n        self$Sigma &lt;- torch_eye(self$p)\n        self$Omega &lt;- torch_eye(self$p)\n        ## Monitoring\n        self$ELBO_list &lt;- c()\n      },\n\n      get_Sigma = function(M, S){\n        1/self$n * (torch_mm(torch_t(M),M) + torch_diag(torch_sum(S**2, dim = 1)))\n      },\n\n      get_ELBO = function(B, M, S, Omega){\n        S2 &lt;- torch_square(S)\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        self$n/2 * torch_logdet(Omega) -\n          torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2))\n      },\n    \n      get_loglik = function(B, M, S, Omega) {\n        S2 &lt;- S**2\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        J &lt;- self$n/2 * torch_logdet(Omega) + \n            .5 * self$n * self$p - torch_sum(log_stirling(self$Y)) -\n            torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2)) -\n          .5 * torch_sum(torch_mm(M, Omega) * M + S2 * torch_diag(Omega))\n        J\n      },\n\n      fit = function(N_iter, lr, tol = 1e-8, verbose = FALSE){\n        self$ELBO_list &lt;- double(length = N_iter)\n        optimizer &lt;- optim_rprop(c(self$B, self$M, self$S), lr = lr)\n        objective0 &lt;- Inf\n        for (i in 1:N_iter){\n          ## reinitialize gradients\n          optimizer$zero_grad()\n\n          ## compute current ELBO\n          loss &lt;- - self$get_ELBO(self$B, self$M, self$S, self$Omega)\n\n          ## backward propagation and optimization\n          loss$backward()\n          optimizer$step()\n\n          ## update parameters with close form\n          self$Sigma &lt;- self$get_Sigma(self$M, self$S)\n          self$Omega &lt;- torch_inverse(self$Sigma)\n\n          objective &lt;- -loss$item()\n          if(verbose && (i %% 50 == 0)){\n            pr('i : ', i )\n            pr('ELBO', objective)\n          }\n          self$ELBO_list[i] &lt;- objective\n          if (abs(objective0 - objective)/abs(objective) &lt; tol) {\n            self$ELBO_list &lt;- self$ELBO_list[1:i]\n            break\n          } else {\n            objective0 &lt;- objective\n          }\n        }\n        self$loglik &lt;- self$get_loglik(self$B, self$M, self$S, self$Omega)\n      },\n\n      plotLogNegElbo = function(from = 10){\n        plot(log(-self$ELBO_list[from:length(self$ELBO_list) ]), type = \"l\")\n      }\n    )\n  )\n\n\n\n\nOn crée une instance avec les données appropriées\n\nY &lt;- oaks$Abundance\nX &lt;- cbind(rep(1, nrow(Y)))\nO &lt;- log(oaks$Offset)\nmyPLN &lt;- PLN$new(Y = Y, O = O, X = X)\n\nTestons notre implémentation simple de PLN utilisant R-torch:\n\nsystem.time(myPLN$fit(1000, lr = 0.05, tol = 1e-9))\n\n   user  system elapsed \n  2.361   0.728   1.841 \n\nplot(-myPLN$ELBO_list, type=\"l\")\n\n\n\n\nEn fait, un backend torch est déjà disponible dans le package PLNmodels\n\nsystem.time(myPLN_torch &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks, control = PLN_param(backend = 'torch', config_optim = list(lr = 0.01))))\n\n\n Initialization...\n Adjusting a full covariance PLN model with torch optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  9.144   2.221   6.050 \n\n\nLes vraisemblances finales sont comparables\n\nmyPLN_nlopt$loglik\n\n[1] -32086.86\n\nmyPLN_torch$loglik\n\n[1] -32175.42\n\nmyPLN$loglik\n\ntorch_tensor\n-31816.6250\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward0&gt; ]\n\n\nAinsi que les paramètres\n\nplot(myPLN$B,\n     myPLN_nlopt$model_par$B, \n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Regression coefficients\"); abline(0, 1, col = \"red\")\nplot(myPLN_torch$model_par$Sigma,\n     myPLN$Sigma,\n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Covariance matrix\"); abline(0, 1, col = \"red\")"
  },
  {
    "objectID": "torch_R_PLN.html#pln-with-r-torch",
    "href": "torch_R_PLN.html#pln-with-r-torch",
    "title": "PLN version R",
    "section": "",
    "text": "On charge le jeu de données oaks contenu dans PLNmodels\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\ndata(oaks)\n\nPour référence, on optimise avec le package dédié (qui utilise le backend NLOpt, une bilbiothèque C++ d’optimisation non linéaire. La variance CCSQA, utilisant les gradients explicites, est utilisée).\n\nsystem.time(myPLN_nlopt &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks))\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  6.753   1.872   4.469 \n\n\n\n\n\nOn définit une simple classe avec une routine d’optimisation utilisant Rprop et l’auto-differentiation sur le critère à optimiser (l’ELBO = Expected Lower BOund).\n\nlibrary(torch)\nlibrary(R6)\n\nlog_stirling &lt;- function(n_){\n  n_ &lt;- n_+ (n_==0)\n  torch_log(torch_sqrt(2*pi*n_)) + n_*log(n_/exp(1))\n}\n\nPLN &lt;-\n  R6Class(\"PLN\",\n    public = list(\n      Y = NULL,\n      O = NULL,\n      X = NULL,\n      n = NULL,\n      p = NULL,\n      d = NULL,\n      M = NULL,\n      S = NULL,\n      A = NULL,\n      B = NULL,\n      Sigma = NULL,\n      Omega = NULL,\n      loglik = NULL,\n      ELBO_list = NULL,\n\n      ## Constructor\n      initialize = function(Y, O, X){\n        self$Y &lt;- torch_tensor(Y)\n        self$O &lt;- torch_tensor(O)\n        self$X &lt;- torch_tensor(X)\n        self$n &lt;- nrow(Y)\n        self$p &lt;- ncol(Y)\n        self$d &lt;- ncol(X)\n        ## Variational parameters\n        self$M &lt;- torch_zeros(self$n, self$p, requires_grad = TRUE)\n        self$S &lt;- torch_ones(self$n , self$p, requires_grad = TRUE)\n        ## Model parameters\n        self$B &lt;- torch_full(c(self$d, self$p), -8.0, requires_grad = TRUE)\n        self$Sigma &lt;- torch_eye(self$p)\n        self$Omega &lt;- torch_eye(self$p)\n        ## Monitoring\n        self$ELBO_list &lt;- c()\n      },\n\n      get_Sigma = function(M, S){\n        1/self$n * (torch_mm(torch_t(M),M) + torch_diag(torch_sum(S**2, dim = 1)))\n      },\n\n      get_ELBO = function(B, M, S, Omega){\n        S2 &lt;- torch_square(S)\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        self$n/2 * torch_logdet(Omega) -\n          torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2))\n      },\n    \n      get_loglik = function(B, M, S, Omega) {\n        S2 &lt;- S**2\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        J &lt;- self$n/2 * torch_logdet(Omega) + \n            .5 * self$n * self$p - torch_sum(log_stirling(self$Y)) -\n            torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2)) -\n          .5 * torch_sum(torch_mm(M, Omega) * M + S2 * torch_diag(Omega))\n        J\n      },\n\n      fit = function(N_iter, lr, tol = 1e-8, verbose = FALSE){\n        self$ELBO_list &lt;- double(length = N_iter)\n        optimizer &lt;- optim_rprop(c(self$B, self$M, self$S), lr = lr)\n        objective0 &lt;- Inf\n        for (i in 1:N_iter){\n          ## reinitialize gradients\n          optimizer$zero_grad()\n\n          ## compute current ELBO\n          loss &lt;- - self$get_ELBO(self$B, self$M, self$S, self$Omega)\n\n          ## backward propagation and optimization\n          loss$backward()\n          optimizer$step()\n\n          ## update parameters with close form\n          self$Sigma &lt;- self$get_Sigma(self$M, self$S)\n          self$Omega &lt;- torch_inverse(self$Sigma)\n\n          objective &lt;- -loss$item()\n          if(verbose && (i %% 50 == 0)){\n            pr('i : ', i )\n            pr('ELBO', objective)\n          }\n          self$ELBO_list[i] &lt;- objective\n          if (abs(objective0 - objective)/abs(objective) &lt; tol) {\n            self$ELBO_list &lt;- self$ELBO_list[1:i]\n            break\n          } else {\n            objective0 &lt;- objective\n          }\n        }\n        self$loglik &lt;- self$get_loglik(self$B, self$M, self$S, self$Omega)\n      },\n\n      plotLogNegElbo = function(from = 10){\n        plot(log(-self$ELBO_list[from:length(self$ELBO_list) ]), type = \"l\")\n      }\n    )\n  )\n\n\n\n\nOn crée une instance avec les données appropriées\n\nY &lt;- oaks$Abundance\nX &lt;- cbind(rep(1, nrow(Y)))\nO &lt;- log(oaks$Offset)\nmyPLN &lt;- PLN$new(Y = Y, O = O, X = X)\n\nTestons notre implémentation simple de PLN utilisant R-torch:\n\nsystem.time(myPLN$fit(1000, lr = 0.05, tol = 1e-9))\n\n   user  system elapsed \n  2.361   0.728   1.841 \n\nplot(-myPLN$ELBO_list, type=\"l\")\n\n\n\n\nEn fait, un backend torch est déjà disponible dans le package PLNmodels\n\nsystem.time(myPLN_torch &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks, control = PLN_param(backend = 'torch', config_optim = list(lr = 0.01))))\n\n\n Initialization...\n Adjusting a full covariance PLN model with torch optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  9.144   2.221   6.050 \n\n\nLes vraisemblances finales sont comparables\n\nmyPLN_nlopt$loglik\n\n[1] -32086.86\n\nmyPLN_torch$loglik\n\n[1] -32175.42\n\nmyPLN$loglik\n\ntorch_tensor\n-31816.6250\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward0&gt; ]\n\n\nAinsi que les paramètres\n\nplot(myPLN$B,\n     myPLN_nlopt$model_par$B, \n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Regression coefficients\"); abline(0, 1, col = \"red\")\nplot(myPLN_torch$model_par$Sigma,\n     myPLN$Sigma,\n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Covariance matrix\"); abline(0, 1, col = \"red\")"
  },
  {
    "objectID": "learnr.html",
    "href": "learnr.html",
    "title": "Nouveautés {learnr}",
    "section": "",
    "text": "Introduction\nNous allons ici présenter les nouveautés du package {learnr} qui permet de créer des tutoriaux interactifs. {learnr} avait déjà été discuté durant la semaine Finist’R 2020\n{learnr} repose sur {shiny}. Le tutoriel est construit à partir d’un fichier Rmarkdown et peut être soit executé en local via le bouton run app soit en déployant le fichier sur un serveur Shiny.\nDepuis 2020 environ, il est possible d’intégrer un tutoriel {learnr] dans un package, ce qui rend les classiques vignettes interactives. Les nouvelles versions de RStudio ont de plus inclus un bouton tutorial disponible dans le panel “Environnement, Git etc…”.\nL’idée est de partager un tutoriel facilement à une large audience et pour cela il est maintenant possible de les intégrer dans un package. Cela peut être intéressant pour des tutoriaux à destination d’étudiants mais également pour des tutoriaux à intégrer dans les packages que vous développez pour rendre l’initiation aux méthodes développées plus interactives qu’une vignette.\nL’avantage technique d’intégrer un tutoriel {learnr} dans un package est qu’il est alors possible, après avoir installé le package, d’exécuter le tutoriel en local sans avoir à le déployer sur un serveur Shiny. C’est donc gratuit et simple d’utilisation.\nA noter qu’il n’est pas nécessaire que le package contenant le tutoriel soit déposé sur le CRAN ou autre, qu’il contienne d’autres fichiers que le tutoriel. Tout est donc possible.\nLes étapes pour créer un package contenant un tutoriel:\n\nSi le package n’est pas déjà créé:\n\n\nusethis::create_package(\"&lt;path_to_folder/name_of_package&gt;\")\n\n\nPour créer le fichier du tutoriel:\n\n\nusethis::use_tutorial(\"&lt;name-of-learnr-file&gt;\", \"&lt;Title You'd Like the User to See&gt;\")\n\n\nPuis dans RStudio, cliquer sur “Build &gt; Install and Restart”.\nSi nécessaire, rajouter le package {gradethis} (noter la fonction de {usethis} spécifique pour les install de package en développement),\n\n\nusethis::use_dev_package(\"gradethis\")\n\n\nSi nécessaire, rajouter les packages présent sur le CRAN toujours avec {usethis}\n\n\nusethis::use_package(\"palmerpenguins\")\n\n\nSi nécessaire, éditer le fichier DESCRIPTION\nExécuter usethis::use_readme_rmd() pour rajouter un fichier README. puis compiler le tout.\nDéposer le package sur gitlab ou github puis partager le repository qui peut être installé avec les lignes de code suivantes:\n\n\ndevtools::install_github(\"&lt;your-repo&gt;/&lt;package-name&gt;\")\ndevtools::install_gitlab(\"&lt;your-repo&gt;/&lt;package-name&gt;\")\n\n\nLorsque le package est installé, aller dans le panel Tutorial dans RStudio et c’est parti…\nQuelques outils utiles.\n\nIl est possible de chaîner des chunks en utilisant la fonctionnalité exercise.setup dans les chunks. Par exemple, nous pouvons effectuer\n```{r exo1,exercise=TRUE}\n\n```\n```{r exo1-solution}\nx = 2+1\n```\n```{r exo2,exercise=TRUE,exercise.setup=\"exo1-solution\"}\n\n```\n```{r exo2-solution,exercise.setup=\"exo1-solution\"}\ny = x *3\n```\n```{r exo3,exercise=TRUE,exercise.setup=\"exo2-solution\"}\n\n```\netc.\nLe package {gradethis} permet de vérifier les solutions proposées à un exercice. Par exemple,\nL’exercice consiste à faire 2+3\n```{r exo3}\n\n```\n```{r exo3-solution}\n2+3\n```\non ajoute un chunk pour vérifier que le code est le bon (mais cela demande que la solution proposée contienne le même code que dans la solution)\n```{r exo3-code-check}\ngrade_this_code()\n```\nsinon on peut simplement vérifier la sortie du code proposé par l’utilisateur :\n```{r exo3-check}\ngrade_result(\n  pass_if(~identical(.result, 5))\n)\n```\n\n\nRéférences\n\nhttps://rstudio.github.io/learnr/\nhttps://education.rstudio.com/blog/2020/09/delivering-learnr-tutorials-in-a-package/"
  },
  {
    "objectID": "jit-example-pln-jax.html",
    "href": "jit-example-pln-jax.html",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "JAX is a Python library, basically a wrapper around numpy for efficient scientific programming: automatic differentiation, parallelization, JIT, etc. Many numpy functions are rewritten in a low level API called LAX. It then uses the XLA compiler to opitmization computations, see #numpy-lax-xla-jax-api-layering\nThis tutorial is a non exhaustive but dense introduction to JAX, especially JIT compilation with JAX. We try to point the reader to the main concepts with a lot of redirections to external resources and to JAX documentation."
  },
  {
    "objectID": "jit-example-pln-jax.html#jit-with-jax",
    "href": "jit-example-pln-jax.html#jit-with-jax",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "JIT with JAX",
    "text": "JIT with JAX\nA practical definition of JIT compilation can be found in JAX documentation:\n\nWhen we jit-compile a function, we usually want to compile a version of the function that works for many different argument values, so that we can cache and reuse the compiled code. That way we don’t have to re-compile on each function evaluation.\n\n\nFor example, if we evaluate an @jit function on the array jnp.array([1., 2., 3.], jnp.float32), we might want to compile code that we can reuse to evaluate the function on jnp.array([4., 5., 6.], jnp.float32) to save on compile time.\n\n\nBy default JAX executes operations one at a time, in sequence. Using a just-in-time (JIT) compilation decorator, sequences of operations can be optimized together and run at once.\n\nIn this tutorial we explore JAX JIT compilation on the same algorithm of the PLN model as coded in the PLN in pytorch tutorial. Also, this tutorial is to be compared with JIT compilation in pytorch.\nFirst, we make the necessary imports\nimport os\n#os.environ['CUDA_VISIBLE_DEVICES'] = '' # uncomment to force CPU\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\nimport jax\nimport jax.numpy as jnp\nimport optax\njax.config.update(\"jax_enable_x64\", False)\nprint(jax.devices())\nmyfloat = np.float32\n[gpu(id=0)]\nNote: We use a GPU since JIT compilation is particularly efficient on GPU.\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 1000\nlr = 1e-4\n\nJAX without JIT\nThis section does not use any kind of jitting. This is our baseline.\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return jnp.log(jnp.sqrt(2 * jnp.pi * integer_)) + integer_ * jnp.log(integer_ / jnp.exp(1))\n\nclass PLN:\n    def __init__(self, Y, O, X): \n        self.Y = Y\n        self.O = O\n        self.X = X\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = jnp.full(Y.shape, 0.0)\n        self.S = jnp.full(Y.shape, 1.0)\n        ## Model parameters\n        self.B = jnp.zeros((self.d, self.p))\n        self.Sigma = jnp.eye(self.p)\n        self.Omega = jnp.eye(self.p)\n\n    def get_Sigma(self, n, M, S) :\n        return 1/n * (M.T @ M + jnp.diag(jnp.sum(S**2, axis=0)))\n    \n    def get_ELBO(self, optim_params):\n      B, M, S = optim_params\n      S2 = jnp.square(S)\n      XB = self.X @ B\n      A = jnp.exp(self.O + M + XB + S2/2)\n\n      elbo = self.n/2 * jnp.log(jnp.linalg.det(self.Omega))\n      elbo += jnp.sum(- A + self.Y * (self.O + M + XB) + .5 * jnp.log(S2))\n      elbo -= .5 * jnp.trace(M.T @ M + jnp.diag(jnp.sum(S2, axis=0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - jnp.sum(_log_stirling(self.Y))\n      return -elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n        ELBO = jnp.zeros(N_iter)\n        optimizer = optax.chain(\n            #adam(learning_rate=lr)\n            optax.scale_by_radam(),\n            optax.scale(-1.0),\n            optax.clip(0.1),\n        )\n        opt_state = optimizer.init((self.B, self.M, self.S))\n        \n        for i in range(N_iter):\n            loss_value, grads = jax.value_and_grad(\n                self.get_ELBO, 0\n            )((self.B, self.M, self.S))\n    \n            updates, opt_state = optimizer.update(grads, opt_state, (self.B, self.M, self.S))\n            optim_params = optax.apply_updates((self.B, self.M, self.S), updates)\n            self.B, self.M, self.S = optim_params\n    \n            ## update parameters with close form\n            self.Sigma = self.get_Sigma(self.n, self.M, self.S)\n            self.Omega = jnp.linalg.inv(self.Sigma)\n    \n            objective = loss_value\n            ELBO = ELBO.at[i].set(objective)\n        \n        return ELBO\nHave a look a the way we update the ELBO vector in the previous functions. This is because JAX arrays are immutable #in-place-updates\n%%time\npln = PLN(Y, O, X)\n\nwith jax.default_device(jax.devices('cpu')[0]): # as opposed to the subsequent jitted versions of the code, running this code do\n    jaxELBO_no_jit = jax.block_until_ready(\n        pln.fit(N_iter, lr, tol=1e-8)\n    )\nCPU times: user 10min 53s, sys: 21min 15s, total: 32min 8s\nWall time: 2min\n\n\nJIT with JAX level 1: jax.jit\nIn this section, we will jit the functions used in the optimization process. Since it is not straightforward to JIT compilation class methods (see subsequent section), we will not use a class anymore.\nThus, we first create an independant function to initialize variables.\ndef init_params(Y, O, X): \n    n, p = Y.shape\n    d = X.shape[1]\n    ## Variational parameters\n    M = jnp.full(Y.shape, 0.0)\n    S = jnp.full(Y.shape, 1.0)\n    ## Model parameters\n    B = jnp.zeros((d, p))\n    Sigma = jnp.eye(p)\n    Omega = jnp.eye(p)\n\n    return n, p, d, M, S, B, Sigma, Omega\nLet’s create the jitted functions. Note that _log_stirling will be automatically jitted when called the jitted get_ELBO. The actual Just In Time compilation will actually happen at the first execution of the jitted function. Note that the call jax.jit() is equivalent to using the decorator @jax.jit\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)\n    return jnp.log(jnp.sqrt(2 * jnp.pi * integer_)) + integer_ * jnp.log(integer_ / jnp.exp(1))\n    \ndef get_ELBO(optim_params, other_params): \n    B, M, S = optim_params['B'], optim_params['M'], optim_params['S']\n    X, O, n, Omega, Y, p = (other_params['X'], other_params['O'], \n        other_params['n'], other_params['Omega'], other_params['Y'],\n        other_params['p'])\n    S2 = jnp.square(S)\n    XB = X @ B\n    A = jnp.exp(O + M + XB + S2/2)\n\n    elbo = 0.\n    elbo = n / 2 * jnp.log(jnp.linalg.det(Omega))\n    elbo += jnp.sum(- A + Y * (O + M + XB) + .5 * jnp.log(S2))\n    elbo -= .5 * jnp.trace(M.T @ M + jnp.diag(jnp.sum(S2, axis = 0)) @ Omega)\n    elbo += .5 * n * p  - jnp.sum(_log_stirling(Y))\n    return -elbo\n\njit_loss_and_grad = jax.jit(jax.value_and_grad(get_ELBO, 0)) # JIT !\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + jnp.diag(jnp.sum(S**2, axis = 0)))\n\njit_getSigma = jax.jit(get_Sigma) # JIT !\n\njit_inv = jax.jit(jnp.linalg.inv) # JIT !\nIn the following, each function inside the for loop is jitted but the for loop is not jitted itself; it is inefficient to do so in JAX mostly due to the long compilation time it would induce, see #jit-decorated-function-is-very-slow-to-compile.\ndef jaxfit1(optim_params, other_params, N_iter, lr, tol = 1e-8) :\n    ELBO = jnp.zeros(N_iter)\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init(optim_params)\n    objective0 = jnp.inf\n\n    update = jax.jit(optimizer.update)\n    apply_updates = jax.jit(optax.apply_updates)\n\n    for i in range(N_iter):\n        loss_value, grads = jit_loss_and_grad(\n            optim_params,\n            other_params\n        )\n\n        updates, opt_state = update(grads, opt_state, optim_params)\n        optim_params = apply_updates(optim_params, updates)\n\n        ## update parameters with close form\n        other_params['Sigma'] = jit_getSigma(other_params['n'], optim_params['M'],\n        optim_params['S'])\n        other_params['Omega'] = jit_inv(other_params['Sigma'])\n\n        objective = loss_value\n        ELBO = ELBO.at[i].set(objective)\n\n    return ELBO\nInitialize the data for JAX\nY = jnp.asarray(Y)\nO = jnp.asarray(O)\nX = jnp.array(X)\nn, p, d, M, S, B, Sigma, Omega = init_params(Y, O, X)\noptim_params = {'B':B, 'M':M, 'S':S}\nother_params = {'X':X, 'O':O, 'n':n, 'Omega':Omega, 'Y':Y, 'p':p, 'Sigma':Sigma}\nand run the learning process:\n%%time\njaxELBO1 = jax.block_until_ready(\n    jaxfit1(optim_params, other_params, N_iter, lr=lr, tol=1e-8)\n)\nCPU times: user 3.87 s, sys: 500 ms, total: 4.37 s\nWall time: 4.13 s\nNote: Because of the complex JAX internal mechanics, benchmarking with JAX should be done with caution https://jax.readthedocs.io/en/latest/async_dispatch.html\n\n\nJIT with JAX level 2: jax.lax.scan\nIn this section, we add resort to jax.lax.scan, which is the standard way to write for loops in JAX. jax.lax.scan automatically JIT compiles its content, it’s not necessary to add the calls to jax.jit here.\nFor a complete tutorial on jax.lax.scan see https://ericmjl.github.io/dl-workshop/02-jax-idioms/02-loopy-carry.html\ndef jaxfit2(optim_params, other_params, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init(optim_params)\n    \n    def scan_fun(carry, _):\n        optim_params = carry['optim_params']\n        other_params = carry['other_params']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(optim_params,\n        other_params)\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        optim_params = optax.apply_updates(optim_params, updates)\n    \n        ## update parameters with close form\n        other_params['Sigma'] = get_Sigma(other_params['n'], optim_params['M'],\n        optim_params['S'])\n        other_params['Omega'] = jnp.linalg.inv(other_params['Sigma'])\n    \n        carry['optim_params'] = optim_params\n        carry['other_params'] = other_params\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n\n    \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"optim_params\":optim_params,\n            \"other_params\":other_params,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\nInitialize the data for JAX:\nY = jnp.asarray(Y)\nO = jnp.asarray(O)\nX = jnp.array(X)\nn, p, d, M, S, B, Sigma, Omega = init_params(Y, O, X)\noptim_params = {'B':B, 'M':M, 'S':S}\nother_params = {'X':X, 'O':O, 'n':n, 'Omega':Omega, 'Y':Y, 'p':p, 'Sigma':Sigma}\nNote: Let’s us try the Ahead Of Time (AOT) compilation where the compilation is done beforehand in a particular explicit step and not at the first execution of the function (as in classical JIT compilation). By doing so we can get an estimate of the compilation time, which is, in our case, not a bottleneck.\n%%time\nlowered = jax.jit(jaxfit2, static_argnums=(2,3,4)).lower(optim_params,\nother_params, N_iter, lr=lr, tol=1e-8)\ncompiled = lowered.compile()\nCPU times: user 708 ms, sys: 40.1 ms, total: 748 ms\nWall time: 502 ms\nLet’s run the complete fit (including compilation)\n%%time\njaxELBO2 = jax.block_until_ready(\n    jaxfit2(optim_params, other_params, N_iter, lr, tol=1e-8)\n)\nCPU times: user 1.97 s, sys: 1.08 s, total: 3.05 s\nWall time: 2.83 s\n\n\nJIT with JAX level 3: can we jit everything?\nNow we will dive into some of the sharp bits of JAX. Let’s try to reuse the above jitted functions with a simple PLN class which acts like a container as we did in the tutorial JIT compilation in pytorch.\nclass PLN_container:\n    def __init__(self, Y, O, X): \n        self.Y = Y\n        self.O = O\n        self.X = X\n        self.n, self.p = Y.shape\n        self.n = self.n\n        self.p = self.p\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = jnp.full(Y.shape, 0.0)\n        self.S = jnp.full(Y.shape, 1.0)\n        ## Model parameters\n        self.B = jnp.zeros((self.d, self.p))\n        self.Sigma = jnp.eye(self.p)\n        self.Omega = jnp.eye(self.p)\nThen we would like to adapt the scan_fun as:\ndef jaxfit3(pln, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init({'B':pln.B, 'M':pln.M, 'S':pln.S})\n\n    def scan_fun(carry, _):\n        pln = carry['PLN']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            {'X':pln.X, 'O':pln.O, 'n':pln.n, 'Omega':pln.Omega,\n             'Y':pln.Y, 'p':pln.p, 'Sigma':pln.Sigma}\n        )\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        updated_params = optax.apply_updates(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            updates)\n        pln.B = updated_params['B']\n        pln.M = updated_params['M']\n        pln.S = updated_params['S']\n    \n        ## update parameters with close form\n        pln.Sigma = get_Sigma(pln.N, pln.M, pln.S)\n        pln.Omega = jnp.linalg.inv(pln.Sigma)\n    \n        carry['PLN'] = pln\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n    \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"PLN\":pln,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\nAnd finally, we would like to start the optimization with:\npln_container = PLN_container(Y, O, X)\njaxELBO3 = jax.block_until_ready(\n    jaxfit3(pln_container, N_iter, lr, tol=1e-8)\n)\nIf we run the previous lines, we get an expected error: class PLN is not a valid JAX type. Recall that the scan loop automatically JIT compiles its content and we cannot JIT compile function whose arguments are custom classes without specific treatment that we will discover in the next subsection. But what is a valid JAX type? From the documentation of jax.jit we read:\n\nThe arguments and return value of fun [the jitted function] should be arrays, scalars, or (nested) standard Python containers (tuple/list/dict) [pytrees] thereof [which themselves contain arrays or scalars].\n\nThe variety of containers that JAX can handle are refered to with the term Pytrees.\nWe also read about pure function and static arguments, more on that below !\nFor the moment, as the class PLN acts as a simple container, a common work around can be to use a Python native and jittable namedtuple class, or a NamedTuple from typing library which improves the class creation. See this introduction to NamedTuple: https://www.geeksforgeeks.org/typing-namedtuple-improved-namedtuples/. NamedTuples are immutable class, so if we want to update one of its attributes we need to use the _replace() method which returns a new object! Note that we can use jax.typing to provide JAX related type hints #jax.typing.\nfrom typing import NamedTuple\nfrom jax.typing import ArrayLike\n\nclass PLN(NamedTuple):\n    Y: ArrayLike\n    O: ArrayLike\n    X: ArrayLike\n    n: int\n    p: int\n    d: int\n    M: ArrayLike\n    S: ArrayLike\n    B: ArrayLike\n    Sigma: ArrayLike\n    Omega: ArrayLike\n    \npln_namedtuple = PLN(\n    Y, O, X,\n    Y.shape[0], Y.shape[1], X.shape[1],\n    jnp.full(Y.shape, 0.0), jnp.full(Y.shape, 1.0),\n    jnp.zeros((X.shape[1], Y.shape[1])), jnp.eye(Y.shape[1]),\n    jnp.eye(Y.shape[1]))\nLet’s adapt the scan_fun function\ndef jaxfit3(pln, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init({'B':pln.B, 'M':pln.M, 'S':pln.S})\n\n    def scan_fun(carry, _):\n        pln = carry['PLN']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            {'X':pln.X, 'O':pln.O, 'n':pln.n, 'Omega':pln.Omega,\n             'Y':pln.Y, 'p':pln.p, 'Sigma':pln.Sigma}\n        )\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        updated_params = optax.apply_updates(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            updates)\n        pln = pln._replace(B=updated_params['B'])\n        pln = pln._replace(M=updated_params['M'])\n        pln = pln._replace(S=updated_params['S'])\n    \n    \n        ## update parameters with close form\n        pln = pln._replace(Sigma=get_Sigma(pln.n, pln.M, pln.S))\n        pln = pln._replace(Omega=jnp.linalg.inv(pln.Sigma))\n    \n        carry['PLN'] = pln\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"PLN\":pln,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\n%%time\njaxELBO3 = jax.block_until_ready(\n    jaxfit3(pln_namedtuple, N_iter, lr, tol=1e-8)\n)\nCPU times: user 2.34 s, sys: 831 ms, total: 3.17 s\nWall time: 2.91 s\nOk, our code works but it is getting a little bit messy: we would like more than containers but real classes, with real methods! That’s what we will see in the next section.\nFirst, let’s try to summarize the main points of JIT compiling functions with JAX:\n\nNot all JAX code can be JIT compiled, as it requires array shapes to be static & known at compile time. #to-jit-or-not-to-jit\nJIT and other JAX transforms work by tracing a function to determine its effect on inputs of a specific shape and type. Variables that you don’t want [or that cannot be traced because they are not of valid JAX type] to be traced can be marked as static #jit-mechanics-tracing-and-static-variables\nRecall that JIT compilation in pytorch cannot handle dynamic shapes, control flows, etc. since it is lost when constructing the Intermediate Representation (IR) of the computational graph that is ued for jitting. The same behaviour happens in JAX when constructing the jaxpr which is the name of the IR in JAX, see #why-can-t-we-just-jit-everything. However, in JAX, there exists way to not lose all the control flows, to conserve conditional statements even inside the jaxpr, etc. Let’s mention the static_argnums decorator, the special jax.lax.cond function, etc. To find more about control flows and jit, see #python-control-flow-jit\nIn fact, JAX is asked to JIT compile a function, it will trace its arguments to create the jaxpr, more precisely #jitting.html:\n\n\nWhen tracing, JAX wraps each argument by a tracer object. These tracers then record all JAX operations performed on them during the function call (which happens in regular Python). Then, JAX uses the tracer records to reconstruct the entire function. The output of that reconstruction is the jaxpr\n\n\nThe more specific information about the values we use in the trace, the more we can use standard Python control flow to express ourselves. However, being too specific means we can’t reuse the same traced function for other values. JAX solves this by tracing at different levels of abstraction for different purposes. For jax.jit, the default level is ShapedArray We understand that the arguments of a jitted function should be traceable as ShapedArray class, or be a Pytree with either 1.Pytree nodes or 2.leaf nodes being either traceable as a ShapedArray object or leaf nodes treated as static arguments. We saw above that scalars and arrays were the valid JAX types, it makes sense since scalars or arrays can be traced with ShapedArray objects.\n\n\nNote on static arguments:\n\n\nWe can tell JAX to help itself to a less abstract tracer for a particular input by specifying static_argnums or static_argnames. The cost of this is that the resulting jaxpr is less flexible, so JAX will have to re-compile the function for every new value of the specified static input. It is only a good strategy if the function is guaranteed to get limited different values.\n\n\nLast but not least, JAX requires the jitted functions to be pure, they cannot have any side effect #pure-functions:\n\n\nJAX transformation and compilation are designed to work only on Python functions that are functionally pure: all the input data is passed through the function parameters, all the results are output through the function results. A pure function will always return the same result if invoked with the same inputs.\n\nJIT with JAX level 3.5: dataclasses and pytrees\nPython developpers also love to use dataclasses as simple data structures. However they are not supported by default in JAX. Many libraries offer ways to also add dataclasses to the Pytrees JAX can handle: simple-pytree, tjax, jax_dataclasses, chex dataclasses etc.\n\n\nJIT with JAX level 4: JIT on class methods\nIn this section, we study the canonical way to JIT compile class methods, a introduction to this technique can be found here: #how-to-use-jit-with-methods. Note that the recipe we give here should be seen from the viewpoint of Pytrees, since a class is always somehow a container. We therefore want to #extending-pytrees. The main elements of making custom class jittable are:\n\nDecorate the class with @register_pytree_node_class\nAdd the tree_flatten method\nAdd the tree_unflatten method\n\nWe here can draw a link with the elements we noted in the previous section: we make our custom class a Pytree, so that it can be jitted provided it contains attributes being 1.Pytree nodes or 2.leaf nodes being either inherited ShapedArray object or leaf nodes treated as static arguments!\nfrom jax.tree_util import register_pytree_node_class\nfrom jax.typing import ArrayLike\n\n@register_pytree_node_class\nclass PLN:\n    Y: ArrayLike\n    O: ArrayLike\n    X: ArrayLike\n    n: int\n    p: int\n    d: int\n    M: ArrayLike\n    S: ArrayLike\n    B: ArrayLike\n    Sigma: ArrayLike\n    Omega: ArrayLike\n    \n    def __init__(self, Y, O, X): \n        self.Y = Y\n        self.O = O\n        self.X = X\n        self.n, self.p = Y.shape\n        self.n = self.n\n        self.p = self.p\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = jnp.full(Y.shape, 0.0)\n        self.S = jnp.full(Y.shape, 1.0)\n        ## Model parameters\n        self.B = jnp.zeros((self.d, self.p))\n        self.Sigma = jnp.eye(self.p)\n        self.Omega = jnp.eye(self.p)\n\n    def get_optim_params(self):\n        return {'B':self.B, 'M':self.M, 'S':self.S}\n        \n    def set_optim_params(self, op):\n        for k, v in op.items():\n            vars(self)[k] = v\n\n    def get_other_params(self):\n        return {\n            'X':self.X, 'O':self.O, 'n':self.n, 'Omega':self.Omega,\n            'Y':self.Y, 'p':self.p, 'Sigma':self.Sigma\n        }\n        \n    def set_other_params(self, op):\n        for k, v in op.items():\n            vars(self)[k] = v\n\n    def update_Sigma(self):\n        pln.Sigma = 1 / self.n * (self.M.T @ self.M + jnp.diag(jnp.sum(self.S ** 2, axis = 0)))\n\n    def update_Omega(self):\n        pln.Omega = jnp.linalg.inv(self.Sigma)\n\n    def tree_flatten(self):\n        children = (\n            self.B, self.M, self.S, self.Sigma, self.Omega,\n        )  # arrays / dynamic values\n        aux_data = {\n            'Y':self.Y, 'O':self.O, 'X':self.X,\n            'n':self.n, 'p':self.p, 'd':self.d\n        }  # static values\n        return (children, aux_data)\n\n    @classmethod\n    def tree_unflatten(cls, aux_data, children):\n        (B, M, S, Sigma, Omega) = children\n        obj = cls(\n            aux_data['Y'], aux_data['O'], aux_data['X']\n        )\n        obj.B = B\n        obj.M = M\n        obj.S = S\n        return obj\nLet’s adapt the scan_fun function, we are now free to use our new class methods\ndef jaxfit4(pln, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init(pln.get_optim_params())\n\n    def scan_fun(carry, k):\n        pln = carry['PLN']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(\n            pln.get_optim_params(),\n            pln.get_other_params()\n        )\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        optim_params = optax.apply_updates(\n            pln.get_optim_params(),\n            updates\n        )\n        pln.set_optim_params(optim_params)\n    \n        ## update parameters with close form\n        pln.update_Sigma()\n        pln.update_Omega()\n    \n        carry['PLN'] = pln\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"PLN\":pln,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\n%%time\npln = PLN(Y, O, X)\njaxELBO4 = jax.block_until_ready(\n    jaxfit4(pln, N_iter, lr, tol=1e-8)\n)\nCPU times: user 6.29 s, sys: 901 ms, total: 7.2 s\nWall time: 4.34 s"
  },
  {
    "objectID": "jit-example-pln-jax.html#conclusion",
    "href": "jit-example-pln-jax.html#conclusion",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Conclusion",
    "text": "Conclusion\nWe check the results\nplt.plot(np.log(jaxELBO_no_jit), label='no jit')\nplt.plot(np.log(jaxELBO1), label='jit level 1')\nplt.plot(np.log(jaxELBO2), label='jit level 2')\nplt.plot(np.log(jaxELBO3), label='jit level 3')\nplt.plot(np.log(jaxELBO4), label='jit level 4')\nplt.legend()\nplt.show()\n/tmp/ipykernel_54173/3050985271.py:1: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO_no_jit), label='no jit')\n/tmp/ipykernel_54173/3050985271.py:2: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO1), label='jit level 1')\n/tmp/ipykernel_54173/3050985271.py:3: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO2), label='jit level 2')\n/tmp/ipykernel_54173/3050985271.py:4: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO3), label='jit level 3')\n\n\n\npng\n\n\n\nJitting is more involved in JAX than with pytorch, the best performances require some specific JAX knowledge that we exposed in each subsection of this document.\nWhen jitting with JAX we fall back on quite the same difficulties as when jitting with pytorch trace.\nHowever, JAX offers clear ways to overcome the difficulties that pytorch tracing does not offer (scan, static_argnums, pytrees, …)\nIn this particular example on GPU, jitted JAX can perform twice as fast as jitted pytorch. But in this particular example on CPU, JAX is slower than pytorch; is it link with the points raised in #benchmarking-jax-code ? However, this also recalls what we can often read online: JAX is particularly suited for GPU optimization. We need to test JAX on other examples involving neural networks, mini-batches, etc. in order to understand JAX potential on CPU optimization too."
  },
  {
    "objectID": "issue_reprex.html",
    "href": "issue_reprex.html",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "",
    "text": "L’objectif de ce billet est de présenter des conseils pour écrire une issue pour demander des améliorations ou soumettre des bugs dans un code déposé sur GitHub."
  },
  {
    "objectID": "issue_reprex.html#objectif",
    "href": "issue_reprex.html#objectif",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "",
    "text": "L’objectif de ce billet est de présenter des conseils pour écrire une issue pour demander des améliorations ou soumettre des bugs dans un code déposé sur GitHub."
  },
  {
    "objectID": "issue_reprex.html#recommandations",
    "href": "issue_reprex.html#recommandations",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Recommandations",
    "text": "Recommandations\nLes recommandations proposées sur les dépôts des packages du tidyverse :\n\nInclure un exemple minimal reproductible, dit reprex.\n\nLire What is a reprex pour plus de détails.\n\nSi les données sont confidentielles, utiliser des données disponibles dans modeldata, simuler des données ou anonymiser les données.\nUtiliser des graines set.seed()\nVérifier sur les blogs ou forums que le problème n’a pas déjà été signalé ou réglé.\n\nD’autres recommandations sont proposées dans le cas d’utilisation de calculs parallèles."
  },
  {
    "objectID": "issue_reprex.html#structure-de-lissue",
    "href": "issue_reprex.html#structure-de-lissue",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Structure de l’issue",
    "text": "Structure de l’issue\n\nPrésenter en premier le problème (“I’m having trouble with …”)\nDonner un exemple reproductible dans un format adapté.\n\nUn bon exemple de report de bug #46."
  },
  {
    "objectID": "issue_reprex.html#exemple-reproductible-avec-le-package-reprex",
    "href": "issue_reprex.html#exemple-reproductible-avec-le-package-reprex",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Exemple reproductible avec le package {reprex}",
    "text": "Exemple reproductible avec le package {reprex}\nIl est possible de créer un exemple reproductible avec le package {reprex} qui produit une sortie bien formatée notamment pour GitHub, et que l’on peut ensuite faciler copier/coller.\nSi le code est un peu long, faire un script, par exemple mon_probleme.R\nIl suffit ensuite d’utiliser la fonction reprex du package du même nom avec les options de son choix. Par exemple reprex(input = 'mon_probleme.R', session_info = TRUE).\nL’option session_info = TRUE permet de récuperer les informations sur notre session R.\nLa fonction génère un fichier markdown (mon_probleme.md) dans le cas de l’utilisation d’un script directement intégrable dans l’issue et ouvre également par défaut le rendu dans le viewer de RStudio ou un navigateur (peut se modifier avec l’argument html_preview = FALSE).\nPetit exemple plus court (sans utilisation de script extérieur) issu du package {reprex} :\n\nlibrary(reprex)\nreprex(rbinom(3, size = 10, prob = 0.5), session_info = TRUE, html_preview = FALSE)"
  },
  {
    "objectID": "Intel_MKL.html",
    "href": "Intel_MKL.html",
    "title": "Intel MKL & Open Blas",
    "section": "",
    "text": "Nous allons d’abord installer les librairies Intel MKL (processeur Intel nécessaire) & Open Blas. Ces deux librairies d’algèbre linéaire permettent d’optimiser et/ou de paralléliser un certains nombre d’opérations algébriques, notamment le calcul matriciel.\nNous les testons avec un produit matriciel de 10000 x 10000.\n\nsize &lt;- 10000\nmat &lt;- matrix(rnorm(size**2), size, size)\n\ntic()\nget_res &lt;- mat %*% mat\ntoc()\n\nAvant l’installation les librairies utilisées pour du calcul matriciel en R sont libblas.so.3.10.0 et liblapack.so.3.10.0 (on peut les voir avec la ligne suivante)\n\nsessionInfo()\n\n\nInstallation sur Windows (seulement Intel MKL)\nLe plus simple est de télécharger les librairies Intel - MKL sur le seafile d’Agroparistech.\n\n1 - Faire une copie de la version actuelle de BLAS et LAPACK:\nDans le dossier C:\\Program Files\\R\\Your_R_Version\\bin\\x64, copier Rblas.dll et Rlapack.dll dans un autre dossier à conserver pour pouvoir revenir aux librairies de la base R.\n\n\n2 - Télécharger les librairies Intel-MKL\nEn allant sur https://seafile.agroparistech.fr/d/696def33ceb848508cb0/ et en cliquant sur le boutton vert ZIP en haut à droite, vous pouvez télécharger le dossier. Puis le déziper.\n\n\n\n3 - Copier les bibliothèques\nLorsque le dossier est décompressé, allez dans \\Intel-MKL-Libs\\Intel_MKL et copiez tous les fichiers dans votre C:\\Program Files\\R\\Your_R_Version\\bin\\x64.\n\n\n4 - Réouverture de R\nVous pouvez fermer votre session R et la rouvrir. Maintenant votre session R devrait fonctionner avec Intel-MKL. Vérifiez si vous avez gagné en efficacité sur votre ordinateur. Attention, le code déjà parallélisé pourrait être moins efficace car ces bibliothèques parallélisent déjà l’algèbre linéaire.\nConcrètement on remplace les deux fichiers faisant appel aux librairies BLAS et LAPACK par des fichiers du même nom mais qui en pratique font implicitement appel à mkl. Pensez bien à sauver une copie des fichiers initiaux.\nPour retourner à la base R il suffit d’opérer à l’opération inverse, copie des fichiers Rblas.dll, Rlapack.dll et libiomp5md.dll du dossier C:\\Program Files\\R\\Your_R_Version\\bin\\x64. Les mettre en sécurité puis copier les librairies des Rblas.dll et Rlapack.dll depuis votre sauvegarde ou https://seafile.agroparistech.fr/d/696def33ceb848508cb0/.\n\n\n\nInstallation sur Ubuntu 22.04 (Intel MKL et Open Blas)\n\nIntel MKL\nsudo apt install intel-mkl\n\n\nOpen Blas\nsudo apt install libopenblas-base\n\n\nChangement de librairie\nPour changer la librairie Blas\nsudo update-alternatives --config libblas.so.3-x86_64-linux-gnu\nPour changer la librairie Lapack\nsudo update-alternatives --config liblapack.so.3-x86_64-linux-gnu\nDans les deux cas cela ouvre un menu montrant les différentes librairies disponibles.\n\n\n\nComparaison produit matriciel (BLAS)\nUne fois installées, vérifier si les librairies sont bien référencées pour le calcul matriciel avec\n\nsessionInfo()\n\n\ntic()\nget_res &lt;- mat %*% mat\ntoc()\n\n\n\n\n\n\n\n\n\n\n\nSystème d’exploitation\nLibrary\nCPU\nBase R\nIntel MKL\n\n\n\n\nWindows 10\nIntel MKL\nIntel Xeon - 16 processeur logiques\n15 min\n7 secondes\n\n\nUbuntu 22.04\nIntel MKL\nIntel i7 - 8 processeur logiques\n5 min\nMoins de 1 min\n\n\nUbuntu 22.04\nOpen Blas\nIntel i7 - 8 processeur logiques\n5 min\n9-14 secondes\n\n\n\n\n\nBenchmark approfondi\nNous allons comparer les performances de toutes ces librairies sur Ubuntu avec un ordinateur à 8 cœurs Intel I7. Pour effectuer ce benchmark nous devons réitérer les fermetures de sessions donc le même code à été lancé séquentiellement.\n\nSet-up\n\nPackages\n\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(furrr)\nlibrary(future)\nlibrary(tictoc)\n\n\n\nFonctions de test\n\ntest_type &lt;- function(seed, type = 'type'){\n  res &lt;- data.frame(seed = rep(0,2), \n                    time = rep(0,2), \n                    type = rep(0,2),\n                    matrix_size = rep(0,2))\n  matrix_size &lt;- c(200, 2000)\n  for(j in 1:2){\n      set.seed(seed)\n      mat = matrix(rnorm(matrix_size[[j]] ^ 2), ncol = matrix_size[[j]])\n      T1 = Sys.time()\n      res_tmp = mat %*% mat\n      T2 = Sys.time()\n      res$seed[[j]] &lt;- seed\n      res$time[[j]] &lt;- difftime(T2, T1)\n      res$type[[j]] &lt;- type\n      res$matrix_size[[j]] &lt;- matrix_size[[j]]\n  }\n  return(res)\n}\n\ncompare &lt;- function(seeds,type = 'type'){\n  if(type == \"base\"){\n    plan(multisession, workers = availableCores())\n    future_map_dfr(seeds,~test_type(.x,type = type))\n  }else{\n    map_dfr(seeds,~test_type(.x,type = type))\n  }\n}\n\nmy_multiplot &lt;- function(data){\n  ggplot(data = data,\n       aes(x = time, y = type, fill = type,col = type)) +\n  geom_boxplot(alpha = 0.5,show.legend = F) +  \n  facet_wrap(\"matrix_size\",scales = \"free_x\",labeller = label_both)\n}\n\n\n\nParamètres\n\ntypes &lt;- c(\"base\",\"openblas\",\"lasy_intel_mkl\",\"intel_mkl_high_perf\")\nseeds &lt;- 1:20\n\n\n\nSélection de la librarie active\n\ntype &lt;- types[[1]]\n\n\n\nCalculs et sauvegarde\n\nres &lt;- compare(seeds,type)\n\nsaveRDS(res, file = paste0('res_algebrica_calculations/res_',type,'.RDS'))\n\n\n\nChargement des résultats\n\nlist_of_results &lt;- grep(\"^res_algebrica_calculations/res_.*.RDS$\",\n                        dir(recursive = T),\n                        value=T)\nres_table &lt;- map_dfr(list_of_results,readRDS)\n\n\n\nGraph des résultats complets\nOn peut voir dans ces graphiques que dans l’ensemble OpenBlas et Intel-MKL sont plus efficaces que la base de R. Cependant d’autres remarques sont à faire :\n\nOpenBlas est utilise constamment l’ensemble des cœurs disponibles, ce comportement extrême peu devenir un problème lors des longs calculs où lorsque l’on utilise des librairies plus complexes comme par exemple Rcpp avec laquelle il obtiens des performances largement plus faible que la base.\nNous avons aussi remarqué une certaine variations dans les performances de Intel-MKL sur Ubuntu seulement. Bien que toujours observée plus efficace que la base. Il est fréquent que pour un même calcul le temps soit jusqu’à 4 fois plus long que le minimum. Cette variation semble être fixe pour chaque session R ouverte. Dans ces graph nous appelons “lasy intel mkl” les sessions de faible performances.\n\n\nmy_multiplot(res_table)\n\n\n\n\n\n\nSans la base R\n\nres_table %&gt;% \n  filter(type != \"base\") %&gt;% \n  my_multiplot()\n\n\n\n\n\n\n\n\nRéférences\n\nhttps://www.intel.com/content/www/us/en/docs/onemkl/get-started-guide/2023-0/overview.html\nhttps://www.openblas.net/\nhttps://github.com/xianyi/OpenBLAS/wiki/faq"
  },
  {
    "objectID": "R_INLA.html",
    "href": "R_INLA.html",
    "title": "R INLA",
    "section": "",
    "text": "Présentation de la méthodologie INLA (integrated nested Laplace approximation) en utilisant les packages {INLA} et sa surcouche {inlabru}.\nL’approximation de Laplace intégrée et imbriquée (INLA) est une approche de l’inférence statistique pour les modèles de champs aléatoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et déterministe au MCMC qui était l’outil standard pour l’inférence de tels modèles. Le principal avantage de l’approche INLA par rapport à la MCMC est qu’elle est beaucoup plus rapide à calculer.\n{inlabru} est une surcouche du package INLA, qui facilite l’utilisation du package R {INLA} en simplifiant la syntaxe. Ce package intègre deux extensions :\n\nModèles de type GAM (pour intégrer des prédicteurs non linéaires)\nProcessus de Cox log-Gaussien pour modéliser des processus univariés et spatiaux basés sur des données de comptages.\n\nSources :\n\nhttps://www.r-inla.org/home\nhttps://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf\nhttps://sites.google.com/inlabru.org/inlabru/home\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "R_INLA.html#introduction",
    "href": "R_INLA.html#introduction",
    "title": "R INLA",
    "section": "",
    "text": "Présentation de la méthodologie INLA (integrated nested Laplace approximation) en utilisant les packages {INLA} et sa surcouche {inlabru}.\nL’approximation de Laplace intégrée et imbriquée (INLA) est une approche de l’inférence statistique pour les modèles de champs aléatoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et déterministe au MCMC qui était l’outil standard pour l’inférence de tels modèles. Le principal avantage de l’approche INLA par rapport à la MCMC est qu’elle est beaucoup plus rapide à calculer.\n{inlabru} est une surcouche du package INLA, qui facilite l’utilisation du package R {INLA} en simplifiant la syntaxe. Ce package intègre deux extensions :\n\nModèles de type GAM (pour intégrer des prédicteurs non linéaires)\nProcessus de Cox log-Gaussien pour modéliser des processus univariés et spatiaux basés sur des données de comptages.\n\nSources :\n\nhttps://www.r-inla.org/home\nhttps://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf\nhttps://sites.google.com/inlabru.org/inlabru/home\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "R_INLA.html#installation-de-inla",
    "href": "R_INLA.html#installation-de-inla",
    "title": "R INLA",
    "section": "Installation de INLA",
    "text": "Installation de INLA\n\n# Base de R INLA\ninstall.packages(\"INLA\",repos=c(getOption(\"repos\"),INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE)\n# inlabru wrapper\ninstall.packages(\"inlabru\")"
  },
  {
    "objectID": "R_INLA.html#utilisation",
    "href": "R_INLA.html#utilisation",
    "title": "R INLA",
    "section": "Utilisation",
    "text": "Utilisation\n\nExemple 1\n\nSetup\n\n# Chargement des packages\nlibrary(INLA)\nlibrary(inlabru)\nlibrary(lme4) # pour comparer avec l'approche frequentiste \nlibrary(ggplot2)\nlibrary(ggpolypath)\nlibrary(RColorBrewer)\nlibrary(geoR)\nlibrary(tidyverse)\n\nLe dataset awards contient le nombre de réussites (num_awards) en math (math) pour une classe de 200 élèves. La réponse mesurée étant un comptage, nous devons spécifier un modèle généralisé avec fonction de lien Poisson.\n\n# Chargement des donnees\nload(\"data/awards.RData\")\nhead(awards)\n\n  num_awards       prog math id\n1          0 Vocational   41  1\n2          0    General   41  2\n3          0 Vocational   44  3\n4          0 Vocational   42  4\n5          0 Vocational   40  5\n6          0    General   42  6\n\n\nLa fonction bru_options_set permet de fixer des options sur des paramètres spécifiques à INLA.\n\nbru_options_set(bru_verbose = TRUE,\n                control.compute = list(dic = TRUE, waic = TRUE))\n\nOn peut récupérer ces paramètres avec :\n\nbru_options_get()\n\n\n\nApplication\nNous expliquons le nombre de récompenses obtenues en fonction de la note en math suivant le modèle \\[Y_i\\overset{ind}{\\sim}\\mathcal{P}(\\exp(\\mu+\\alpha\\cdot x_i))\\,.\\]\n\n# Formulation du modele\ncmp1 &lt;- num_awards ~ math + 1\n# Application de la formule avec un modèle de Poisson\nfit.glm.bru &lt;- bru(cmp1, family = \"poisson\", data = awards)\n\niinla: Iteration 1 [max:1]\n\nsummary(fit.glm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.742, Running = 0.276, Post = 0.033, Total = 1.05 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.086 0.010      0.067    0.086      0.105  0.086   0\nIntercept -5.349 0.591     -6.508   -5.349     -4.191 -5.349   0\n\nDeviance Information Criterion (DIC) ...............: 384.07\nDeviance Information Criterion (DIC, saturated) ....: 208.02\nEffective number of parameters .....................: 1.99\n\nWatanabe-Akaike information criterion (WAIC) ...: 384.48\nEffective number of parameters .................: 2.35\n\nMarginal log-Likelihood:  -204.02 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nComparaison avec un GLM\n\ncmp2 &lt;- num_awards ~ math\nfit2.glm &lt;- glm(cmp2, family=\"poisson\", data = awards)\nsummary(fit2.glm)\n\n\nCall:\nglm(formula = cmp2, family = \"poisson\", data = awards)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.333532   0.591261  -9.021   &lt;2e-16 ***\nmath         0.086166   0.009679   8.902   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 204.02  on 198  degrees of freedom\nAIC: 384.08\n\nNumber of Fisher Scoring iterations: 6\n\n\nLes réponses sont proches.\n\n\nIntégration d’un effet aléatoire\nPour prendre en compte le problème classique de surdispersion dans les données de comptages, il peut être intéressant de rajouter un effet aléatoire de la manière suivante.\n\\[Y_i\\overset{ind}{\\sim}\\mathcal{P}(\\exp(\\mu+\\alpha\\cdot x_i+E_i)) \\quad \\text{avec}\\quad E_i\\overset{ind}{\\sim}\\mathcal{N}(0,\\sigma^2).\\]\n\ncmp3 &lt;- num_awards ~ math + 1 + rand.eff(map = 1:200, model = \"iid\", n = 200)\n\nfit3.glmm.bru &lt;- bru(cmp3, family = \"poisson\", data = awards)\n\nWarning in inlabru:::component.character(\"rand.eff\", map = 1:200, model =\n\"iid\", : Use of 'map' is deprecated and may be disabled; use 'main' instead.\n\n\niinla: Iteration 1 [max:1]\n\nsummary(fit3.glmm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nrand.eff: main = iid(1:200), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.462, Running = 0.223, Post = 0.07, Total = 0.754 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.086 0.010      0.067    0.086      0.105  0.086   0\nIntercept -5.349 0.591     -6.509   -5.349     -4.190 -5.349   0\n\nRandom effects:\n  Name    Model\n    rand.eff IID model\n\nModel hyperparameters:\n                           mean       sd 0.025quant 0.5quant 0.975quant   mode\nPrecision for rand.eff 19903.65 19900.90     564.00 13861.13   74196.24 187.83\n\nDeviance Information Criterion (DIC) ...............: 384.03\nDeviance Information Criterion (DIC, saturated) ....: 207.97\nEffective number of parameters .....................: 2.00\n\nWatanabe-Akaike information criterion (WAIC) ...: 384.47\nEffective number of parameters .................: 2.38\n\nMarginal log-Likelihood:  -204.09 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nComparaison avec l’approche fréquentiste\n\ncmp4&lt;- num_awards ~ math + (1|id)\nfit4.glmm&lt;-glmer(cmp4, family = poisson, data = awards)\nsummary(fit4.glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: num_awards ~ math + (1 | id)\n   Data: awards\n\n     AIC      BIC   logLik deviance df.resid \n   381.2    391.1   -187.6    375.2      197 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.1653 -0.5518 -0.3760  0.3900  2.9242 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.3257   0.5707  \nNumber of obs: 200, groups:  id, 200\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.63163    0.70476  -7.991 1.34e-15 ***\nmath         0.08861    0.01161   7.634 2.28e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nmath -0.982\n\n\nOn remarque que les résultats sont un peu moins comparables. Pour se rapprocher de glmer(), on peut modifier la loi a priori sur l’effet aléatoire.\n\ncmp5 &lt;- num_awards ~ math + 1 + rand.eff(map = 1:200, model = \"iid\", n = 200,\n                                                 hyper=list(prec=list(param=c(10,0.1),\n                                                                      prior=\"pc.prec\")))\nfit5.glmm.bru &lt;- bru(cmp5, family = \"poisson\", data = awards )\n\nWarning in inlabru:::component.character(\"rand.eff\", map = 1:200, model =\n\"iid\", : Use of 'map' is deprecated and may be disabled; use 'main' instead.\n\n\niinla: Iteration 1 [max:1]\n\nsummary(fit5.glmm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nrand.eff: main = iid(1:200), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.429, Running = 0.23, Post = 0.0663, Total = 0.725 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.090 0.012      0.067    0.089      0.113  0.089   0\nIntercept -5.651 0.692     -7.039   -5.641     -4.321 -5.621   0\n\nRandom effects:\n  Name    Model\n    rand.eff IID model\n\nModel hyperparameters:\n                       mean   sd 0.025quant 0.5quant 0.975quant mode\nPrecision for rand.eff 6.97 8.93       1.58     4.10      27.94 2.69\n\nDeviance Information Criterion (DIC) ...............: 380.37\nDeviance Information Criterion (DIC, saturated) ....: 204.31\nEffective number of parameters .....................: 29.47\n\nWatanabe-Akaike information criterion (WAIC) ...: 381.65\nEffective number of parameters .................: 26.02\n\nMarginal log-Likelihood:  -204.62 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\n\nExemple 2\nDans le jeu de données gorillas, on cherche à comprendre la répartition de communautés de gorilles dans une région donnée en fonction de facteurs (végétations) ou de variable continue (altitude).\n\ndata(gorillas, package = \"inlabru\")\n\nOn importe l’objet liste gorillas qui contient 4 sous-listes contenant les localisations d’habitats de gorilles (nests), le maillage de la zone d’intérêt (mesh), la frontière du domaine (boundary) et les variables explicatives (gcov).\n\nnests &lt;- gorillas$nests\nmesh &lt;- gorillas$mesh\nboundary &lt;- gorillas$boundary\ngcov &lt;- gorillas$gcov\n\nsummary(gcov$vegetation)\n\nObject of class SpatialPixelsDataFrame\nCoordinates:\n       min      max\nx 580.1599 586.2320\ny 673.8742 679.0378\nIs projected: TRUE \nproj4string :\n[+proj=utm +zone=32 +datum=WGS84 +units=km +no_defs]\nNumber of points: 39600\nGrid attributes:\n  cellcentre.offset   cellsize cells.dim\nx          580.1737 0.02760054       220\ny          673.8885 0.02868664       180\nData attributes:\n      vegetation   \n Colonising:   48  \n Disturbed :23606  \n Grassland : 7001  \n Primary   : 7725  \n Secondary :  788  \n Transition:  432  \n\n\nLa construction du maillage peut se faire avec les fonctions de {INLA}:\n\ninla.mesh.2d(),\ninla.mesh.create(),\ninla.mesh.1d(),\ninla.mesh.basis(),\ninla.spde2.pcmatern().\n\nvoir la vignette suivante pour quelques exemples: https://inlabru-org.github.io/inlabru/articles/random_fields_2d.html.\n\nVisualisation des données gorilles\n\nggplot() +\n  gg(gcov$vegetation) +\n  gg(boundary) +\n  gg(nests, color = \"white\", cex = 0.5) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\n\nggplot() +\n  gg(gcov$vegetation) +\n  gg(mesh) +\n  gg(boundary) +\n  gg(nests, color = \"white\", cex = 0.5) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\nLes graphiques ci-dessus permettent de visualiser les différents types de végétations ainsi que les localisations d’habitat de gorilles dans la zone d’étude. Il est également possible de rajouter le maillage construit sur la zone. {inlabru} propose la fonction gg() permettant avac la grammaire ggplot2 de rajouter les différentes couches d’informations.\n\n\nModèle 1\nOn peut supposer un processus ponctuel spatial d’intensité \\[\\lambda(x,y)=\\exp(\\alpha_i(x,y))\\] où \\(\\alpha\\) est un paramètre correspondant à un type de végétation (modélisation factor full sans intercept donc).\n\ncomp1 &lt;- coordinates ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1\ncomp1alt &lt;- coordinates ~ vegetation(gcov$vegetation, model = \"factor_contrast\") + 1\n\nPour construire un modèle expliquant les comptages de gorilles avec leurs répartitions dans la zone d’étude et prenant en compte les types de végétations, nous définissons la formule avec:\n\ncoordinates() la fonction de {sp} de récupération des coordonnées des habitats dans l’objet nests\nvegetation sera le mot utilisé dans les sorties du modèle faisant référence à la variable explicative gcov$vegetation (possible d’écrire le mot que l’on veut…)\nmodel = \"factor_full\" est pour indiquer que la variable explicative est un facteur. Il est possible d’utiliser “factor_full”, “factor_contrast” etc… suivant les types de contraintes que l’on souhaite appliquer au modèle. “factor_full” indique estimations de toutes les modalités mais il faut alors supprimer l’intercept afin d’être dans un cas identifiable.\n\nAprès avoir défini la formule du modèle, on estime les paramètres en utilisant la fonction lgcp() qui permet de modéliser un processus log-normalisé de Cox. Cette fonction est une surcouche de la fonction de base bru().\nLe LGCP est un modèle probabiliste de processus ponctuel observé dans un tissu spatial ou temporel.\n\nfit1 &lt;- lgcp(components = comp1, # formule du modèle\n             data = nests,       # data set\n             samplers = boundary,  # frontière de la zone d'étude\n             domain = list(coordinates = mesh) # maillage de la zone\n             )\n\niinla: Iteration 1 [max:1]\n\n\nfit1 estime l’intensité des présences de gorilles dans la zone d’étude. Il est alors possible de représenter l’intensité moyenne de ces habitats:\n\npred.df &lt;- fm_pixels(mesh, mask = boundary, format = \"sp\")\nint1 &lt;- predict(fit1, pred.df, ~ exp(vegetation))\n\nggplot() +\n  gg(int1) +\n  gg(boundary, alpha = 0, lwd = 2) +\n  gg(nests, color = \"DarkGreen\") +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\nPour visualiser les résultats du modèle, nous utilisons la fonction predict() (sans oublier de passer à l’exponentielle) et fm_pixels() qui en prenant la zone d’étude (mesh + frontière) crée l’objet spatial adéquat.\nNous remarquons que les intensités sont les plus fortes dans la végétation Primaire, ce qui est logique. Ici, l’intensité représente le nombre d’habitats de gorilles par unité de surface. Attention donc à comment vous définissez les coordonnées de vos zones d’études.\nEn utilisant les fonctions fm_int()et predict() nous allons tenter d’estimer les abondances moyennes sachant que nous savons qu’il y a 647 habitats en réalité:\n\nips &lt;- fm_int(mesh, boundary)\nLambda1 &lt;- predict(fit1, ips, ~ sum(weight * exp(vegetation)))\nLambda1\n\n      mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err\n1 650.2296 25.28652 610.2632 647.8453 697.3896 647.8453        2.528652\n  sd.mc_std_err\n1      1.808314\n\n\n\n# Calcul de la surface de la zone\nsum(ips$weight) # some des surfaces de chaque triangle du mesh\n\n[1] 19.87366\n\nsf::st_area(sf::st_as_sf(boundary)) # surface totale \n\n19.87366 [km^2]\n\n\n\n\nModèle avec utilisation SPDE\nDans cette section, nous allons essayer d’expliquer la répartition des habitats en rajoutant au facteur vegetation une modélisation SPDE (Stochastic partial differential equations). Il faut pour cela compléter la définition du maillage par l’ajout d’une structure de Matérn en utilisant la fonction {INLA} inla.spde2.pcmatern() puis réécrire la définition de la formule du modèle INLA. Le modèle intègre alors un champ gaussien avec covariance de Matérn. \\[\\lambda(x,y)=\\exp(\\alpha_i(x,y)+\\xi(x,y))\\] avec \\(\\xi\\) suivant un champ gaussien.\n\npcmatern &lt;- inla.spde2.pcmatern(mesh,\n  prior.sigma = c(0.1, 0.01),\n  prior.range = c(0.1, 0.01)\n)\n\ncomp2 &lt;- coordinates ~\n            -1 +\n            vegetation(gcov$vegetation, model = \"factor_full\") +\n            elevation(gcov$elevation) +\n            mySmooth(coordinates, model = pcmatern)\n\nfit2 &lt;- lgcp(components = comp2, \n             data = nests, \n             samplers = boundary, \n             domain = list(coordinates = mesh))\n\niinla: Iteration 1 [max:1]\n\n\nOn représente l’intensité médiane de la surface:\n\nint2 &lt;- predict(fit2, pred.df, ~ exp(mySmooth + vegetation), n.samples = 1000)\n\nggplot() +\n  gg(int2, aes(fill = q0.025)) +\n  gg(boundary, alpha = 0, lwd = 2) +\n  gg(nests) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\net l’intensité intégrée attendue (moyenne des abondances):\n\nLambda2 &lt;- predict(fit2,\n                   fm_int(mesh, boundary),\n                   ~ sum(weight * exp(mySmooth + vegetation)))\n\nLambda2\n\n       mean       sd      q0.025      q0.5  q0.975    median mean.mc_std_err\n1 0.8949473 2.460237 0.007384043 0.2472062 4.47594 0.2472062       0.2460237\n  sd.mc_std_err\n1      1.005067\n\n\nExaminons les contributions au prédicteur linéaire de la partie SPDE et de celle due à la végatation.\nLa fonction scale_fill_gradientn() définit l’échelle pour la légende du graphique. Dans cet exemple, on la définit telle que cela prenne en compte toute la gamme de valeurs des 3 prédicteurs linéaires. Par défaut, ce sont les médianes qui sont représentées.\n\nlp2 &lt;- predict(fit2, \n               pred.df, ~ list(\n                        smooth_veg = (mySmooth + vegetation + elevation),\n                        not_smooth = (vegetation + elevation),\n                        smooth = (mySmooth),\n                        veg = (vegetation),\n                        ele = (elevation)\n              ))\n\nlprange &lt;- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median, lp2$ele$median, lp2$not_smooth$median)\n\nplot.lp2 &lt;- ggplot() +\n  gg(lp2$not_smooth) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"vegetation + elevation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.spde &lt;- ggplot() +\n  gg(lp2$smooth) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"mySmooth\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.veg &lt;- ggplot() +\n  gg(lp2$veg) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"vegetation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.ele &lt;- ggplot() +\n  gg(lp2$ele) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"elevation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nmultiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, plot.lp2.ele, cols = 2)\n\n\n\n\n\n\n\nExemple 3\nNous nous intéressons à un jeu de données concernant la prévalence de la malaria en Gambie (disponible dans le package {geoR}). Cet exemple est repris du livre “Spatial and Spatio-temporal Bayesian Models with R-INLA”.\n\ndata(gambia, package = \"geoR\")\n# les coordonnées correspondent au village où se trouve les enfants\n# create one index for each of the 65 villages\nvillage_index &lt;- unite(gambia, col = \"lon_lat\", sep = \"_\", \"x\", \"y\") %&gt;% \n  pull(\"lon_lat\") %&gt;% \n  factor(labels = 1:65)\ngambia &lt;- gambia %&gt;%\n  add_column(village_index) \n\nOn transforme le jeu de données en type {SpatialPointsDataFrame}.\n\ngambia &lt;- gambia %&gt;%\n  mutate(x = x * 0.001, # to km\n         y = y * 0.001, # to km\n         age = age / 365) \ncoordinates(gambia) &lt;- c(\"x\", \"y\") \nclass(gambia)\n\n[1] \"SpatialPointsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nOn définit ensuite un maillage pour le champ spatial avec un maillage plus fin dans la zone où il y a des observations et qui “déborde” avec un maillage plus grossier.\n\nhull = inla.nonconvex.hull(gambia,convex = -0.1)\ngambia_mesh &lt;- inla.mesh.2d(boundary = hull,\n                            offset = c(30, 60), max.edge = c(20,40))\n\nplot(gambia_mesh,main=\"\",asp=1)\npoints(gambia,pch=21,bg=\"white\",cex=1.5,lwd=1.5)\n\n\n\n\nOn définit à partir du maillage le champ spatial spde qui correspond à un champ spatial gaussien avec une covariance Matérn. Nous considérons les lois a priori par défaut sur les paramètres de variance et de portée du champ spatial.\n\ngambia_spde &lt;- inla.spde2.matern(mesh = gambia_mesh, alpha=2)\n\nTout est prêt pour définir le modèle à ajuster et son estimation : Pour l’enfant \\(j\\) du village \\(i\\), nous supposons \\[Y_{ij}|V_i\\overset{ind}{\\sim}b(p_{ij})\\] avec \\[S_i\\sim GRF, \\quad V_i\\overset{ind}{\\sim}\\mathcal{N}(0,\\sigma^2_V)\\] et \\[p_{ij}=\\mu+\\beta_1 \\cdot treated_{ij}+\\beta_2 \\cdot netuse_{ij}+\\beta_3 \\cdot age_{ij}+\\beta_4 \\cdot green_{ij}+\\beta_5\\cdot phc_{ij}+S_i+V_i.\\]\n\nformula = pos ~ -1 +\n  Intercept(1) +\n  treated +\n  netuse +\n  age +\n  green +\n  phc +\n   spatial_field(coordinates, model=gambia_spde) +\n  village(village_index, model=\"iid\")\n\nfit &lt;- bru(components = formula,\n           data = gambia,\n           family= \"binomial\"\n)\n\niinla: Iteration 1 [max:1]\n\nsummary(fit)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\ntreated: main = linear(treated), group = exchangeable(1L), replicate = iid(1L)\nnetuse: main = linear(netuse), group = exchangeable(1L), replicate = iid(1L)\nage: main = linear(age), group = exchangeable(1L), replicate = iid(1L)\ngreen: main = linear(green), group = exchangeable(1L), replicate = iid(1L)\nphc: main = linear(phc), group = exchangeable(1L), replicate = iid(1L)\nspatial_field: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L)\nvillage: main = iid(village_index), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'binomial'\n    Data class: 'SpatialPointsDataFrame'\n    Predictor: pos ~ .\nTime used:\n    Pre = 0.964, Running = 1.67, Post = 0.122, Total = 2.75 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nIntercept -1.295 1.282     -3.733   -1.327      1.312 -1.398   0\ntreated   -0.387 0.201     -0.782   -0.387      0.006 -0.387   0\nnetuse    -0.347 0.157     -0.655   -0.347     -0.039 -0.347   0\nage        0.246 0.044      0.159    0.246      0.332  0.246   0\ngreen      0.012 0.025     -0.038    0.012      0.060  0.014   0\nphc       -0.323 0.227     -0.772   -0.322      0.122 -0.321   0\n\nRandom effects:\n  Name    Model\n    spatial_field SPDE2 model\n   village IID model\n\nModel hyperparameters:\n                          mean    sd 0.025quant 0.5quant 0.975quant  mode\nTheta1 for spatial_field  1.32 0.836     -0.172     1.26       3.10  1.04\nTheta2 for spatial_field -2.50 0.708     -4.006    -2.45      -1.24 -2.27\nPrecision for village     4.83 2.423      1.685     4.32      10.97  3.45\n\nDeviance Information Criterion (DIC) ...............: 2326.24\nDeviance Information Criterion (DIC, saturated) ....: 2326.24\nEffective number of parameters .....................: 48.46\n\nWatanabe-Akaike information criterion (WAIC) ...: 2325.39\nEffective number of parameters .................: 46.41\n\nMarginal log-Likelihood:  -1227.34 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\nOn peut accéder aux distributions marginales des effets aléatoires et des hyperparamètres :\n\nfit$summary.random \nfit$summary.hyperpar\n\nNous pouvons tracer les distributions a posteriori marginales des effets, par exemple :\n\nage &lt;- fit$marginals.fixed[[4]]\nggplot(data.frame(inla.smarginal(age)), aes(x, y)) +\n  geom_line() +\n  theme_bw()\n\n\n\nrfprecision &lt;- fit$marginals.hyperpar$`Precision for village`\nggplot(data.frame(inla.smarginal(rfprecision)), aes(x, y)) +\n  geom_line() +\n  theme_bw()\n\n\n\n\nNous essayons de représenter le champs gaussien latent\n\ndomain_lims &lt;- apply(hull$loc, 2, range)\ngrd_dims &lt;- round(c(x = diff(domain_lims[, 1]), \n                    y = diff(domain_lims[, 2])) / 1)\nmesh_proj &lt;- fm_evaluator(\n  gambia_mesh,\n  xlim = domain_lims[, 1], ylim = domain_lims[, 2], dims = grd_dims\n)\n\nspatial_field &lt;- data.frame(\n  median = inla.link.invlogit(fit$summary.random$spatial_field$\"0.5quant\"),\n  range95 = (inla.link.invlogit(fit$summary.random$spatial_field$\"0.975quant\") -\n               inla.link.invlogit(fit$summary.random$spatial_field$\"0.025quant\"))\n)\n\npredicted_field &lt;- fm_evaluate(mesh_proj, spatial_field) %&gt;%\n  as.matrix() %&gt;%\n  as.data.frame() %&gt;%\n  bind_cols(expand.grid(x = mesh_proj$x, y = mesh_proj$y), .) %&gt;%\n  pivot_longer(cols = -c(\"x\", \"y\"),\n               names_to = \"metric\",\n               values_to = \"value\")\n# Median\nggplot(filter(predicted_field, metric == \"median\")) +\n  aes(x = x, y = y, fill = value) +\n  geom_raster() +\n  scale_fill_viridis_c()\n\n\n\n# 95% range\nggplot(filter(predicted_field, metric == \"range95\")) +\n  aes(x = x, y = y, fill = value) +\n  geom_raster() +\n  scale_fill_viridis_c()"
  },
  {
    "objectID": "R_INLA.html#references",
    "href": "R_INLA.html#references",
    "title": "R INLA",
    "section": "References",
    "text": "References\n\nhttps://www.pymc.io/projects/examples/en/latest/gaussian_processes/log-gaussian-cox-process.html\nFabian E. Bachl, Finn Lindgren, David L. Borchers, and Janine B. Illian (2019), inlabru: an R package for Bayesian spatial modelling from ecological survey data, Methods in Ecology and Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168\nFunwi-Gabga, N. and Mateu, J. (2012) Understanding the nesting spatial behaviour of gorillas in the Kagwene Sanctuary, Cameroon. Stochastic Environmental Research and Risk Assessment 26 (6), 793-811.\nhttps://www.muscardinus.be/2018/07/inlabru-bru/\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2023 – ou bootcamp R du groupe State Of The R s’est déroulé à la station biologique de Roscoff du 21 au 25 août 2023.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agissait de la septième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#où-quand",
    "href": "index.html#où-quand",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2023 – ou bootcamp R du groupe State Of The R s’est déroulé à la station biologique de Roscoff du 21 au 25 août 2023.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agissait de la septième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#participants",
    "href": "index.html#participants",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Participants",
    "text": "Participants\nEmré Anakok, Julie Aubert, Pierre Barbillon, Barbara Bricout, Caroline Cognot, Félix Cheysson, Julien Chiquet, Annaïg De Walsche, Marie-Pierre Etienne, Armand Favrot, Hugo Gangloff, Pierre Gloaguen, Jérémy Lamouroux, Corentin Lothodé, Mahendra Mariadassou, Tristan Mary-Huard, Isabelle Sanchez, Florian Teste, Théodore Vanrentherghem, Emily Walker."
  },
  {
    "objectID": "index.html#soutien",
    "href": "index.html#soutien",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Soutien",
    "text": "Soutien"
  },
  {
    "objectID": "tidymodels_build_new_model.html",
    "href": "tidymodels_build_new_model.html",
    "title": "Construire un modèle parsnip",
    "section": "",
    "text": "Notre objectif ici est de construire un nouveau modèle {parsnip} à partir d’une implémentation existante dans un package R.\nIntérêts : éliminer des dépendances, du code dupliqué, pouvoir profiter du cadre {tidymodels}.\n\n\n\nhttps://www.tidymodels.org/learn/develop/models/\nTuto tidymodels - Rencontres R 2023\n\n\n\n\nIl se définit par\n\nun mode (régression linéaire, logistique, …),\nun type (régression, classification),\nun moteur de calcul engine (lm, stan, …).\n\nQunad on ajoute un modèle, on doit donc spécifier son mode et son engine. On peut aussi ajouter un nouveau modèle différent d’un pré-existant seulement par son type (ie même combinaison engine et mode).\nIl est possible de voir l’ensemble des modèles déjà disponibles ici."
  },
  {
    "objectID": "tidymodels_build_new_model.html#introduction",
    "href": "tidymodels_build_new_model.html#introduction",
    "title": "Construire un modèle parsnip",
    "section": "",
    "text": "Notre objectif ici est de construire un nouveau modèle {parsnip} à partir d’une implémentation existante dans un package R.\nIntérêts : éliminer des dépendances, du code dupliqué, pouvoir profiter du cadre {tidymodels}.\n\n\n\nhttps://www.tidymodels.org/learn/develop/models/\nTuto tidymodels - Rencontres R 2023\n\n\n\n\nIl se définit par\n\nun mode (régression linéaire, logistique, …),\nun type (régression, classification),\nun moteur de calcul engine (lm, stan, …).\n\nQunad on ajoute un modèle, on doit donc spécifier son mode et son engine. On peut aussi ajouter un nouveau modèle différent d’un pré-existant seulement par son type (ie même combinaison engine et mode).\nIl est possible de voir l’ensemble des modèles déjà disponibles ici."
  },
  {
    "objectID": "tidymodels_build_new_model.html#intégration-de-la-régression-pln",
    "href": "tidymodels_build_new_model.html#intégration-de-la-régression-pln",
    "title": "Construire un modèle parsnip",
    "section": "Intégration de la régression PLN",
    "text": "Intégration de la régression PLN\n\nlibrary(PLNmodels)\nlibrary(tidymodels)\nlibrary(poissonreg)\n\n\nDonnées\nNous utiliserons le jeu de données de la vignette de PLN.\n\ndata(trichoptera)\n\n\n\n\n\n\n\nRemarque\n\n\n\nIl existe une fonction prepare_data dans {parsnip} également.\n\n\n\n\nDifférentes étapes pour intégrer PLNmodels::PLN dans parsnip\n\nEtape 1 : Spécification du modèle et de ses arguments\nOn va ajouter la fonction PLNmodels::PLN à la liste des fonctions utilisables pour faire de la régression de Poisson.\n\nshow_model_info(\"poisson_reg\")\n\nInformation for `poisson_reg`\n modes: unknown, regression \n\n engines: \n   regression: glm¹, glmnet¹, hurdle¹, stan¹, zeroinfl¹\n\n¹The model can use case weights.\n\n arguments: \n   glmnet: \n      penalty --&gt; lambda\n      mixture --&gt; alpha\n\n fit modules:\n     engine       mode\n        glm regression\n     hurdle regression\n   zeroinfl regression\n     glmnet regression\n       stan regression\n\n prediction modules:\n         mode   engine                          methods\n   regression      glm                     numeric, raw\n   regression   glmnet                     numeric, raw\n   regression   hurdle                     numeric, raw\n   regression     stan conf_int, numeric, pred_int, raw\n   regression zeroinfl                     numeric, raw\n\n\n\nset_model_mode(model = \"poisson_reg\", mode = \"regression\")\nset_model_engine(\n  \"poisson_reg\", \n  mode = \"regression\", \n  eng = \"PLN\"\n)\nset_dependency(\"poisson_reg\", eng = \"PLN\", pkg = \"PLNmodels\")\n\nOn peut vérifier ce qu’on a ajouté.\n\nshow_model_info(\"poisson_reg\")\n\nInformation for `poisson_reg`\n modes: unknown, regression \n\n engines: \n   regression: glm¹, glmnet¹, hurdle¹, PLNNA, stan¹, zeroinfl¹\n\n¹The model can use case weights.\n\n arguments: \n   glmnet: \n      penalty --&gt; lambda\n      mixture --&gt; alpha\n\n fit modules:\n     engine       mode\n        glm regression\n     hurdle regression\n   zeroinfl regression\n     glmnet regression\n       stan regression\n\n prediction modules:\n         mode   engine                          methods\n   regression      glm                     numeric, raw\n   regression   glmnet                     numeric, raw\n   regression   hurdle                     numeric, raw\n   regression     stan conf_int, numeric, pred_int, raw\n   regression zeroinfl                     numeric, raw\n\n\nSi notre modèle a des arguments supplémentaires que ceux existants, on peut les ajouter.\n\n\nEtape 2 : Créer la fonction principale associée au modèle le cas échéant\nIci comme nous avons seulement ajouté un moteur à un modèle préexistant ce n’est pas nécessaire.\ntodo: regarder comment ajouter l’information possible d’utilisation de poids\n\n\nEtape 3 : Préciser le module d’ajustement (fit)\n\nL’argument interface, peut prendre les valeurs formula, data ou matrices.\nprotect est une liste optionnelle d’arguments qui ne devraient pas être modifié par l’utilisateur.\nfunc est un vecteur précisant le package et la fonction qui sera appelé pour l’ajustement.\ndefaults est une liste optionnelle d’arguments que l’utilisateur peut modifier mais pour laquelle on peut spécifier des valeurs par défaut.\n\n\nset_fit(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  value = list(\n    interface = \"formula\",\n    protect = c(\"formula\", \"data\"),\n    func = c(pkg = \"PLNmodels\", fun = \"PLN\"),\n    defaults = list(control = PLN_param(), weights = NULL, subset = NULL)\n  )\n)\n\nOn peut ajouter des traitements par défaut pour les variables explicatives, tels que calculs de variables indicatrices, calcul d’une constante etc…\n\nset_encoding(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  options = list(\n    predictor_indicators = \"traditional\",\n    compute_intercept = TRUE,\n    remove_intercept = TRUE,\n    allow_sparse_x = FALSE\n  )\n)\n\n\n\nEtape 4 : Ajouter un module pour la prédiction (predict)\n\nset_pred(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  type = \"numeric\",\n  value = list(\n    pre = NULL,\n    post = NULL,\n    func = c(fun = \"predict\"),\n    args =\n      list(\n        object = expr(object$fit),\n        newdata = expr(new_data),\n        type = \"response\"\n      )\n  )\n)\n\n\n\n\nApplication sur les données trichoptera\n\nPLN dans PLNmodelsPLN dans parsnip\n\n\n\nprep_trichoptera &lt;- PLNmodels::prepare_data(trichoptera$Abundance, trichoptera$Covariate)\nmyPLN &lt;- PLN(Abundance ~ 1 , data = prep_trichoptera)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nmyPLN\n\nA multivariate Poisson Lognormal fit with full covariance model.\n==================================================================\n nb_param    loglik       BIC       ICL\n      170 -1130.047 -1460.852 -2229.083\n==================================================================\n* Useful fields\n    $model_par, $latent, $latent_pos, $var_par, $optim_par\n    $loglik, $BIC, $ICL, $loglik_vec, $nb_param, $criteria\n* Useful S3 methods\n    print(), coef(), sigma(), vcov(), fitted()\n    predict(), predict_cond(), standard_error()\n\n\n\n\n\nresPLN &lt;- poisson_reg() %&gt;% \n  set_engine(\"PLN\") %&gt;% \n  fit(Abundance ~ 1 , data = prep_trichoptera)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nresPLN\n\nparsnip model object\n\nA multivariate Poisson Lognormal fit with full covariance model.\n==================================================================\n nb_param    loglik       BIC       ICL\n      170 -1130.047 -1460.852 -2229.083\n==================================================================\n* Useful fields\n    $model_par, $latent, $latent_pos, $var_par, $optim_par\n    $loglik, $BIC, $ICL, $loglik_vec, $nb_param, $criteria\n* Useful S3 methods\n    print(), coef(), sigma(), vcov(), fitted()\n    predict(), predict_cond(), standard_error()\n\n\n\n\n\n\nsummary(resPLN)\n\n             Length Class       Mode       \nlvl           0     -none-      NULL       \nspec          8     poisson_reg list       \nfit          32     PLNfit      environment\npreproc       1     -none-      list       \nelapsed       1     -none-      list       \ncensor_probs  0     -none-      list       \n\nresPLN$spec\n\nPoisson Regression Model Specification (regression)\n\nComputational engine: PLN \n\nModel fit template:\nPLNmodels::PLN(formula = missing_arg(), data = missing_arg(), \n    control = list(backend = \"nlopt\", trace = 1, covariance = \"full\", \n        Omega = NULL, config_post = list(jackknife = FALSE, bootstrap = 0L, \n            rsquared = TRUE, variational_var = FALSE, sandwich_var = FALSE, \n            trace = 1), config_optim = list(algorithm = \"CCSAQ\", \n            maxeval = 10000, ftol_rel = 1e-08, xtol_rel = 1e-06, \n            ftol_abs = 0, xtol_abs = 0, maxtime = -1, trace = 1), \n        inception = NULL), weights = NULL, subset = NULL)\n\n# Pour recuperer les coefficients\ncoef(resPLN$fit)\n\n                  Che       Hyc      Hym       Hys      Psy        Aga\n(Intercept) -2.833542 -4.023858 1.056175 -2.176389 3.305965 -0.3468842\n                  Glo       Ath       Cea       Ced        Set        All\n(Intercept) -2.205421 -1.657137 -3.343267 0.3683657 -0.5991094 -0.8440133\n                  Han       Hfo        Hsp       Hve       Sta\n(Intercept) -1.233492 -2.123357 -0.2549654 -2.750357 0.9776199\n\nall.equal(coef(myPLN), coef(resPLN$fit))\n\n[1] TRUE\n\n# Pour faire de la prediction\npred_pln &lt;- predict(myPLN, newdata  = prep_trichoptera, type = \"response\")\npred_pln %&gt;% head(n=3)\n\n         Che        Hyc      Hym       Hys     Psy     Aga       Glo       Ath\n1 0.06171337 0.05998778 3.831122 0.1225325 91.0535 2.91355 0.2540807 0.2926166\n2 0.06171337 0.05998778 3.831122 0.1225325 91.0535 2.91355 0.2540807 0.2926166\n3 0.06171337 0.05998778 3.831122 0.1225325 91.0535 2.91355 0.2540807 0.2926166\n        Cea      Ced      Set      All     Han      Hfo      Hsp       Hve\n1 0.1071243 2.570283 3.703422 1.080023 11.0092 1.054269 5.761769 0.1990118\n2 0.1071243 2.570283 3.703422 1.080023 11.0092 1.054269 5.761769 0.1990118\n3 0.1071243 2.570283 3.703422 1.080023 11.0092 1.054269 5.761769 0.1990118\n       Sta\n1 7.495402\n2 7.495402\n3 7.495402\n\n# On peut appliquer les methodes \n#pred_parsnipfit &lt;- predict(resPLN$fit, newdata  = prep_trichoptera)\npred_parsnip &lt;- predict(resPLN, new_data  = trichoptera$Abundance)\npred_parsnip %&gt;% head(n=3)\n\n# A tibble: 3 × 17\n  .pred_Che .pred_Hyc .pred_Hym .pred_Hys .pred_Psy .pred_Aga .pred_Glo\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1    0.0617    0.0600      3.83     0.123      91.1      2.91     0.254\n2    0.0617    0.0600      3.83     0.123      91.1      2.91     0.254\n3    0.0617    0.0600      3.83     0.123      91.1      2.91     0.254\n# ℹ 10 more variables: .pred_Ath &lt;dbl&gt;, .pred_Cea &lt;dbl&gt;, .pred_Ced &lt;dbl&gt;,\n#   .pred_Set &lt;dbl&gt;, .pred_All &lt;dbl&gt;, .pred_Han &lt;dbl&gt;, .pred_Hfo &lt;dbl&gt;,\n#   .pred_Hsp &lt;dbl&gt;, .pred_Hve &lt;dbl&gt;, .pred_Sta &lt;dbl&gt;\n\n\n\n\nTest d’un workflow\n\n# separation du jeu de donnees en test et apprentissage\nset.seed(123)\ntri_split &lt;- initial_split(data = prep_trichoptera, prop = 0.9)\n#tri_train &lt;- training(tri_split)\n#tri_test &lt;- testing(tri_split)\np_recipe &lt;- \n  recipe(Abundance ~ 1 + Temperature, data = training(tri_split))\n\npln_model &lt;- \n  poisson_reg()%&gt;%\n  set_engine(\"PLN\") %&gt;%\n  set_mode(\"regression\")\n\npln_workflow &lt;- workflow() %&gt;%\n  add_recipe(p_recipe) %&gt;%\n  add_model(pln_model)\n\nfitted_workflow &lt;-  pln_workflow %&gt;%\n  fit(training(tri_split)) \n\n# Predicition sur le jeu d'entrainement\ntest_pred &lt;- fitted_workflow %&gt;% predict(new_data = testing(tri_split))\n\nPour la suite du workflow, calcul de performance sur un rééchantillonnage etc., ce serait possible mais nécessite un peu de code. Il faudrait ici que la sortie de prédiction soit en format plus ‘tidy’ ou réécrire le calcul de métrique sur des matrices.\n\n\nAutre jeu de données, exemple en régression univariée\n\np &lt;- read.csv(\"https://stats.idre.ucla.edu/stat/data/poisson_sim.csv\")\np &lt;- within(p, {\n  prog &lt;- factor(prog, levels=1:3, labels=c(\"General\", \"Academic\", \n                                            \"Vocational\"))\n  id &lt;- factor(id)\n})\n\nOn essaie maintenant en utilisant {parsnip}.\n\nglm de baseglm dans parsnipplnPLN dans parsnip\n\n\n\nsummary(m1 &lt;- glm(num_awards ~ prog + math, family=\"poisson\", data=p))\n\n\nCall:\nglm(formula = num_awards ~ prog + math, family = \"poisson\", data = p)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -5.24712    0.65845  -7.969 1.60e-15 ***\nprogAcademic    1.08386    0.35825   3.025  0.00248 ** \nprogVocational  0.36981    0.44107   0.838  0.40179    \nmath            0.07015    0.01060   6.619 3.63e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 189.45  on 196  degrees of freedom\nAIC: 373.5\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\npoisson_reg() %&gt;% \n     set_engine(\"glm\") %&gt;%\n     set_mode(\"regression\") %&gt;%\n     fit(num_awards ~ prog + math, data = p)  %&gt;%\n     predict(p)\n\n# A tibble: 200 × 1\n    .pred\n    &lt;dbl&gt;\n 1 0.135 \n 2 0.0934\n 3 0.167 \n 4 0.145 \n 5 0.126 \n 6 0.100 \n 7 0.192 \n 8 0.126 \n 9 0.0771\n10 0.192 \n# ℹ 190 more rows\n\n\n\n\n\nmod_pln &lt;- PLN(as.matrix(num_awards) ~ prog + math, data = p)  \n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nmod_pln %&gt;%\n     predict(p, type = \"response\") %&gt;%\n     head(n = 10)\n\n            Y\n1  0.13402450\n2  0.09294198\n3  0.16581305\n4  0.14387844\n5  0.12484545\n6  0.09977539\n7  0.19109165\n8  0.12484545\n9  0.07597876\n10 0.19109165\n\n\n\n\n\npoisson_reg() %&gt;% \n     set_engine(\"PLN\") %&gt;%\n     set_mode(\"regression\") %&gt;%\n     fit(as.matrix(num_awards) ~ prog + math, data = p) %&gt;% \n     predict(p)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n# A tibble: 200 × 1\n   .pred_Y\n     &lt;dbl&gt;\n 1  0.134 \n 2  0.0929\n 3  0.166 \n 4  0.144 \n 5  0.125 \n 6  0.0998\n 7  0.191 \n 8  0.125 \n 9  0.0760\n10  0.191 \n# ℹ 190 more rows\n\n\n\n\n\nOn peut vérifier la commande associée au modèle programmé.\n\npoisson_reg() %&gt;% translate(engine = \"PLN\")\n\nPoisson Regression Model Specification (regression)\n\nComputational engine: PLN \n\nModel fit template:\nPLNmodels::PLN(formula = missing_arg(), data = missing_arg(), \n    control = list(backend = \"nlopt\", trace = 1, covariance = \"full\", \n        Omega = NULL, config_post = list(jackknife = FALSE, bootstrap = 0L, \n            rsquared = TRUE, variational_var = FALSE, sandwich_var = FALSE, \n            trace = 1), config_optim = list(algorithm = \"CCSAQ\", \n            maxeval = 10000, ftol_rel = 1e-08, xtol_rel = 1e-06, \n            ftol_abs = 0, xtol_abs = 0, maxtime = -1, trace = 1), \n        inception = NULL), weights = NULL, subset = NULL)"
  },
  {
    "objectID": "tidymodels_build_new_model.html#pour-aller-plus-loin",
    "href": "tidymodels_build_new_model.html#pour-aller-plus-loin",
    "title": "Construire un modèle parsnip",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nDans le cadre tidymodels, tout est assez modulaire et personnalisable : on peut ajouter de nouvelles recettes de pré-traitement, personnaliser son rééchantillonnage, le calcul de métrique etc.\nUn peu de documentation sur le site de {tidymodels] dans la section Develop custom modeling tools."
  },
  {
    "objectID": "jax-getting-started.html",
    "href": "jax-getting-started.html",
    "title": "Premiers pas avec jax",
    "section": "",
    "text": "Le but de cette vignette est d’implémenter une régression logistique et/ou une régression multivariée avec JAX."
  },
  {
    "objectID": "jax-getting-started.html#préliminaires",
    "href": "jax-getting-started.html#préliminaires",
    "title": "Premiers pas avec jax",
    "section": "Préliminaires",
    "text": "Préliminaires\n\nInstallation\n\nConda\nJax est disponible dans le channel conda-forge et peut donc s’installer dans un environnement conda\n#| eval: true\nconda create -n jax\nconda activate jax\n## Install the CPU version\nconda install jax -c conda-forge\n## Install packages necessary for the render\nconda install nbclient nbformat ipykernel\nPour des instruction détaillées pour l’installation en mode GPU ou TPU, se référer à la documentation officielle.\nIl suffit alors d’activer l’environnement jax pour produire le html à partir du qmd\n#| eval: false\nconda activate jax\nquarto render my_document.qmd --to html\n\n\nPip\nSi vous préférez une installation via pip (pour une version cpu),\n#| eval: false\npip3 install jax jaxlib\nPour une installation GPU (avec cuda 12 par exemple, on vous laisse gérer la compatibilité de vos driver Nvidia and Cie),\n#| eval: false\npip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\nL’utilisation de venv est recommandable (mais non obligatoire).\nOn installe également optax pour avoir accès à des optimiseurs.\n#| eval: false\npip3 install optax\nImportant Pour utiliser optax, il vaut mieux utiliser pip pour installer jax et jaxlib, les versions disponibles dans les dépôts conda sont en effet trop anciennes pour optax."
  },
  {
    "objectID": "jax-getting-started.html#premiers-pas",
    "href": "jax-getting-started.html#premiers-pas",
    "title": "Premiers pas avec jax",
    "section": "Premiers pas",
    "text": "Premiers pas\n\nPhilosophie\nEn quelques mots, JAX est une bibliothèque Python développée par Google et initialement utilisée dans TensorFLow. Elle permet de faire de l’algèbre linéaire à la numpy, avec 2 propriétés clés la rendant extrêmement performante:\n\nun autograd permettant la différenciation automatique de calcul Python/Numpy\nun compileur pour GPU et autres (XLA), dédié à l’algèbre linéaire qui permet d’optimiser les temps d’exécution grâce à une approche JIT (Just-in Time, c’est-à-dire une optimisation du code à l’exécution et non pas avant l’appel comme avec un compileur classique).\n\nL’objectif de la bibliothèque est de proposer une expérience utilisateur aussi proche que possible de calculs à la Numpy, notamment à l’aide de décorateurs Python. Néanmoins, pour accéder pleinement aux capacités de JAX, un certain nombre de contraintes d’écriture des programmes s’appliquent, que nous allons essayer de présenter pas à pas.\n\n\nImport de la bibliothèque\nL’import complet/standard est le suivant:\n\nimport jax.numpy as jnp\nfrom jax import grad, jit, vmap\nfrom jax import random\nimport optax\nimport matplotlib.pyplot as plt\n\nOn peut détailler les fonctionnalités des modules comme suit:\n\nle module jax.numpy, aka jnp, porte les opérations matricielles usuelles de manière quasi transparente\nle module random définit les outils de génération de nombres aléatoires, propres à JAX et très différents de Numpy\nle module grad gère l’autodifférenciation\nle module jit gère la “just-in time” compilation (accélération du code)\nle module vmap permet de vectoriser automatiquement certaines opérations\n\n\n\nJax.numpy: interface Algèbre linéaire haut-niveau\nOn commence par simuler des données aléatoires via les outils de jax. Attention la gestion de la clé aléatoire est explicite. Après avoir créé une clé et avant chaque appel à une fonction aléatoire, il faut faire évoluer la graine à la main\n\nkey,subkey = random.split(key, 2)\n\net utiliser subkey (les sous-clés) dans l’appel à la fonction aléatoire (ou aux fonctions aléatoire) comme écrit ci-dessous.\n\nn = 10000\np = 100\nkey = random.PRNGKey(0)\nkey,sub1,sub2 = random.split(key, 3)\nones = jnp.ones((n, 1))\nx = random.normal(sub1, (n, p-1))\nx = jnp.concatenate([ones, x], axis = 1)\nbeta_true = random.normal(sub2, (p,1))\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\nAvant de les multiplier. On utilise ici la fonction block_until_ready() uniquement pour mesurer le temps effectif de calcul. En effet, JAX fait de l’évaluation asynchrone (comme {future} en R) pour rendre la main à l’utilisateur après l’envoi de la commande.\n\n%timeit odds = jnp.dot(x, beta_true).block_until_ready()  # runs on the CPU\n\n174 µs ± 1.33 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n\n\nOn échantillonne ensuite des variables suivant une loi de Bernoulli.\n\nodds = jnp.dot(x, beta_true)\nkey,subkey = random.split(key, 2)\ny = random.bernoulli(subkey, odds)\n\net une perte logistique\n\\[\\ell(y, x, \\theta) = -\\log p(y; \\sigma(x^{\\top}\\theta)) = -y (x^\\top \\theta) + \\log(1 + e^{x^\\top \\theta})\\]\n\ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n\nQu’on peut tester sur un exemple simple\n\n## Should be log(2)\nlogistic_loss(True, 1.0, 0)\n\nArray(0.6931472, dtype=float32)\n\n\n\n\nJust-in-time compilation\nLa version normale de notre fonction logistique est déjà rapide.\n\n%timeit logistic_loss(y, x, beta_true).block_until_ready()\n\n323 µs ± 3.57 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\nmais on peut l’accélerer en compilant la fonction via le décorateur @jit ou la fonction jit() de façon complètement transparente pour l’utilisateur.\n\n## Utilisation du décorateur @jit\n@jit \ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n\n\n## Utilisation de jit()\nlogistic_loss_jit = jit(logistic_loss)\n%timeit logistic_loss_jit(y, x, beta_true).block_until_ready()\n\n238 µs ± 4.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\nLa différence n’est pas très importante dans cet exemple. jit() permet des gains d’autant plus importants qu’on travaille sur des fonctions complexes.\nAttention, il n’est pas toujours possible de jitter une fonction, en particulier, si cette fonction implique un branchement conditionnel:\n\ndef f(x):\n  if x &gt; 5:\n    return x\n  else:\n    return 2*x\n\nL’erreur provient du fait que la définition de la fonction dépend de la valeur des entrées.\n\nf_jit = jit(f)\n## Renvoie une erreur\nf_jit(1)\n\nTracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function f at /tmp/ipykernel_6581/2514275982.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError\n\n\nComme l’indique le message d’erreur\nThis concrete value was not available in Python because it depends on the value of the argument x.\n\n\ngrad: auto-différentiation\nJAX permet de calculer le gradient d’une fonction via grad(). La syntaxe est différente de torch et plus proche de ce qu’on ferait dans une fonction mathématique.\n\ndef loss(theta):\n  return logistic_loss(y, x, theta)\n\n\n## random start for theta\nkey,subkey = random.split(key, 2)\ntheta = random.normal(key, (p, 1))\ngrad_loss = grad(loss)\n\n\ngrad_loss = grad(loss)\n%timeit grad_loss(theta)\n\n9.89 ms ± 312 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\ngrad() peut-être combiné à jit() dans tous les sens à condition que les fonctions s’y prêtent.\n\ngrad_loss = jit(grad(loss))\n## Warmup to cache grad loss\ngrad_loss(theta).shape\n## Actual time recording\n%timeit grad_loss(theta)\n\n349 µs ± 7.17 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\nMais ce n’est pas toujours intéressant.\n\ngrad_loss = jit(grad(jit(loss)))\n## Warmup to cache grad loss\ngrad_loss(theta).shape\n## Actual time recording\n%timeit grad_loss(theta)\n\n350 µs ± 5.42 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\n\n\nVectorisation\nJAX permet enfin de vectoriser automatiquement des opérations de façon efficace (en faisant descendre la boucle à l’intérieur de la fonction, au niveau des primitives utilisées pour le calcul).\nConsidérons un exemple simple où on veut calculer des logs-odds sur mesures répétées.\n\n## Matrice de covariables, répétées en temps \n## [temps, individu, variable]\nkey,subkey = random.split(key, 2)\nX = random.normal(key, (10, n, p))\ndef compute_odds(x, theta):\n  return jnp.dot(x, theta)\ndef compute_odds_batched(X,  theta):\n  return jnp.stack([compute_odds(x, theta) for x in X]) \n\nEt testons ce qui se passe. On appelle la fonction sur une tranche de X\n\n%timeit compute_odds(X[:1,:, :], beta_true)\n\n3.72 ms ± 105 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nPuis sur toutes les tranches de X avec notre fonction vectorisée manuellement.\n\n%timeit compute_odds_batched(X, beta_true)\n\n17.8 ms ± 213 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nPuis sur toutes les tranches de X avec notre fonction vectorisée via vmap().\n\ndef compute_odds_batched_vmap(X,  theta):\n  def f(x):\n    return compute_odds(x, theta)\n  return vmap(f)(X)\n\n\ncompute_odds_batched_vmap(X, beta_true).shape\n\n(10, 10000, 1)\n\n\n\n%timeit compute_odds_batched_vmap(X, beta_true)\n\n15.2 ms ± 205 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nÀ comparer à la version native jax qui est déjà nativement vectorisée pour cette opération\n\n%timeit compute_odds(X, beta_true)\n\n14 ms ± 191 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nLe gain n’est pas très important dans cette exemple précis mais on se rapproche quand même de la performance de la version native, par rapport à notre vectorisation manuelle."
  },
  {
    "objectID": "jax-getting-started.html#optimisation-de-la-fonction-objective",
    "href": "jax-getting-started.html#optimisation-de-la-fonction-objective",
    "title": "Premiers pas avec jax",
    "section": "Optimisation de la fonction objective",
    "text": "Optimisation de la fonction objective\n\nÀ la main\nContrairement à torch, on n’a pas d’optimiseur défini clé en main dans JAX. La dérivée est néanmoins une fonction comme les autres et on peut donc écrire très simplement un algorithme simple de descente de gradient.\n\n%%time\nnum_iterations = 50\nloss_vector = []\n## Learning rate\nlr = 0.001\n## Initialisation de theta\ntheta = jnp.zeros(p)\n## Fonction de perte, en mode jit\n@jit\ndef loss(theta):\n  return logistic_loss(y, x, theta)\n## Gradient de la fonction de perte, en mode jit\ngrad_loss = jit(grad(loss))\n\n## Descente de gradient\nfor i in range(num_iterations):\n    # Suivi de la fonction de perte\n    loss_vector.append(loss(theta))\n    # Mise à jour du paramètre\n    theta = theta - lr * grad_loss(theta) \n\nCPU times: user 294 ms, sys: 15.7 ms, total: 309 ms\nWall time: 309 ms\n\n\nEt on peut vérifier que la fonction de perte décroit au cours du temps.\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\nEt que les paramètres de régression estimés se rapprochent des vraies valeurs\n\nplt.plot(beta_true, theta, marker='o', linestyle=\"none\")\nplt.plot([-3, 3], [-3, 3], color='r', linestyle='-', linewidth=2)\nplt.xlabel('True parameter')\nplt.ylabel('Estimated parameter')\nplt.title('Estimated versus true parameter')\nplt.show()\n\n\n\n\n\n\nAvec Optax\nOn peut néanmoins utiliser la librairie optax pour définir des optimiseurs comme en torch. On va utiliser ici Adam.\n\nFonction objective\nOn commence par définir la fonction objective avec un ordre précis pour les arguments:\n\nparamètres à optimiser (typiquement \\(\\theta\\), les coefficients de régression)\nparamètres additionels (pénalités, etc)\ndonnées (avec le mot clé data)\n\n\ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\ndef objective_and_grad(params, penalty, data):\n  x = data[:, :-1]\n  y = data[:, -1]\n  def loss(params):\n    return logistic_loss(y, x, params)\n  loss_value = loss(params)\n  loss_grad = grad(loss)(params)\n  return [loss_value, loss_grad]\n\n\n\nItérateur de données\nAdam est un algorithme d’optimisation stochastique. On définit donc un itérateur qui va échantillonner les données.\n\nbatch_size = 100\nn_iter = 1000\n# key, subkey = random.split(key, 2)\ndef data_iterator(key, data):    \n    return random.choice(key, data, (batch_size, ), replace = False)\n\n\n\nOptimisation\nOn définit enfin une fonction de fit qui travaille sur des batchs.\n\ndef fit(data, params, optimizer, key):\n  opt_state = optimizer.init(params)\n  loss_vector = []\n\n  @jit\n  def step(params, opt_state, batch):\n    loss_value, grads = objective_and_grad(params, 0, batch)\n    updates, opt_state = optimizer.update(grads, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, opt_state, loss_value\n\n  for i in range(n_iter):\n    key, subkey = random.split(key, 2)\n    batch = data_iterator(subkey, data)\n    params, opt_state, loss_value = step(params, opt_state, batch)\n    loss_vector.append(loss_value.item())\n    if i % 100 == 0:\n      print(f'step {i}, loss: {loss_value}')\n\n  return [params, loss_vector]\n\nFinalement, on peut ajuster notre fonction paramétrée en utilisant l’optimiseur Adam fourni par optax.\n\n%%time \ninitial_params = jnp.zeros((x.shape[1], ))\noptimizer = optax.adam(learning_rate=1e-2)\ndata = jnp.concatenate([x, y], axis = 1)\nparams,loss_vector = fit(data, initial_params, optimizer, key)\n\nstep 0, loss: 69.3147201538086\nstep 100, loss: 18.580368041992188\nstep 200, loss: 12.382568359375\nstep 300, loss: 11.707901000976562\nstep 400, loss: 8.840866088867188\nstep 500, loss: 10.6444091796875\nstep 600, loss: 8.130218505859375\nstep 700, loss: 8.6331787109375\nstep 800, loss: 8.014801025390625\nstep 900, loss: 5.246734619140625\nCPU times: user 9.39 s, sys: 280 ms, total: 9.67 s\nWall time: 9.26 s\n\n\nOn peut vérifier que la fonction objective converge sans décroître systématiquement,\n\nplt.plot(range(1, n_iter+1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\net que les paramètres sont proches des bonnes valeurs.\n\nplt.plot(beta_true, params, marker='o', linestyle=\"none\")\nplt.plot([-3, 3], [-3, 3], color='r', linestyle='-', linewidth=2)\nplt.xlabel('True parameter')\nplt.ylabel('Estimated parameter')\nplt.title('Estimated versus true parameter')\nplt.show()"
  },
  {
    "objectID": "jit-example-pln.html",
    "href": "jit-example-pln.html",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We study Just In Time (JIT) compilation with pytorch. This tutorial is to be compared with JIT compilation in pytorch where much more explanations are given.\n\n\n\nReferences to pytorch JIT compilation, by order of difficulty:\n\npytorch jit official documentation\npytorch jit trace documentation\nTorchScript official tutorial\npytorch jit intermediate guide\npytorch jit intermediate / advanced guide\npytorch jit advanced guide\n\nMake necessary imports\nimport torch\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\nUsing a GPU.\nNote: We use pytorch GPU ! JIT compilation is particularly efficient on GPU. On this particular example, we were not able to see any speed up on CPU between jitted code and non-jitted code. We suppose it might be possible to get a CPU speed up on other case study, considering neural networks for example..\ndevice =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\ntorch.set_default_dtype(torch.float32)\nmyfloat = np.float32\ncuda\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 5000\nlr = 1e-2\n\n\n\nWe reuse the code from PLN in pytorch.\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device:\n    torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol=1e-8) :\n      self.ELBO = np.zeros(N_iter, dtype=myfloat)\n      optimizer = torch.optim.Adam([self.B, self.M, self.S], lr=lr)\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\nLet’s create the PLN object:\n%%time\nmyPLN = PLN(Y, O, X, device)\nCPU times: user 523 ms, sys: 67 ms, total: 590 ms\nWall time: 134 ms\nand run the learning process:\n%%time\nmyPLN.fit(N_iter, lr = lr, tol=1e-8)\nCPU times: user 34.5 s, sys: 193 ms, total: 34.7 s\nWall time: 35.3 s\n\n\n\nThere are two ways to create the computational graph: eager execution and graph execution. The default mode in pytorch is eager, this means the computational graph is created at each forward pass in the graph. On the other hand, the graph mode adds an additional compilation step which builds the graph only once and lets the computations be done at a lower level.\nJIT (Just In Time) compilation is the process that builds an Intermediate Representation (IR) of the graph. This is the additional compilation step mentioned above.\nUsing graph mode, we gain:\n\nefficiency since the graph is precomputed and can be optimized to factorize redundant operations or delete useless operations.\nportability since this IR can be reused in another language.\n\nHowever, we lose:\n\nflexibility since we are tied to fixed array sizes, we cannot easily use control flows, …\n\nThere are two ways in pytorch to JIT our code, hence, there are two ways to use require the graph mode. We study these two ways in the next sections.\n\n\n\nBy reading the above mentioned references, we get that we cannot jit the fit function. Some reasons are:\n\nN_iter is variable at compilation time (shape might change depending on input).\nthe pytorch optimizer’s operations cannot be jitted.\ntorch.jit.script cannot handle control flow or loops.\n\nclass jitPLN(torch.jit.ScriptModule) :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        super().__init__()\n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    @torch.jit.script_method\n    def _log_stirling(self, integer):\n        integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n        return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\n    @torch.jit.script_method\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    @torch.jit.script_method\n    def get_inv(self, S):\n      return torch.inverse(S)\n\n    @torch.jit.script_method\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(self._log_stirling(self.Y))\n      return elbo\n\ndef fit(pln, N_iter, lr, tol = 1e-8) :\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - pln.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = pln.get_Sigma()\n        pln.Omega = pln.get_inv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nLet’s create the jitted PLN object:\n%%time\nmyjitPLN = jitPLN(Y, O, X, device)\nCPU times: user 194 ms, sys: 4.8 ms, total: 199 ms\nWall time: 19.4 ms\nand run the learning process:\n%%time\nscriptELBO = fit(myjitPLN, N_iter, lr = lr, tol = 1e-8)\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: operator() profile_node %760 : int[] = prim::profile_ivalue(%dims.24)\n does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\n\nCPU times: user 27.3 s, sys: 164 ms, total: 27.4 s\nWall time: 28.2 s\n\n\n\nHere we use torch.jit.trace over each of the computational functions, the PLN class is just a container for the objects. The previous limitations from torch.jit.script are still present, notably, we cannot jit the main for loop.\nclass tracejitPLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : torch.Tensor\n    p : torch.Tensor\n    d : torch.Tensor\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.n = torch.tensor(self.n)\n        self.p = torch.tensor(self.p)\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n        self.device = device\nLet’s create the PLN object and the jitted functions:\n%%time\nmytracePLN = tracejitPLN(Y, O, X, device)\n\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\ntraced_logstirling = torch.jit.trace(_log_stirling, (mytracePLN.Y))\n\ndef get_ELBO(S, X, B, O, M, n, Omega, Y, p): \n    S2 = torch.square(S)\n    XB = X @ B\n    A = torch.exp(O + M + XB + S2/2)\n\n    elbo = n/2 * torch.logdet(Omega)\n    elbo += torch.sum(- A + Y * (O + M + XB) + .5 * torch.log(S2))\n    elbo -= .5 * torch.trace(M.T @ M + torch.diag(torch.sum(S2, dim = 0)) @ Omega)\n    elbo += .5 * n * p  - torch.sum(traced_logstirling(Y))\n    return elbo\n\ntraced_getELBO = torch.jit.trace(get_ELBO, (mytracePLN.S, mytracePLN.X, mytracePLN.B, mytracePLN.O, mytracePLN.M,\n    mytracePLN.n, mytracePLN.Omega, mytracePLN.Y, mytracePLN.p))\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + torch.diag(torch.sum(S**2, dim = 0)))\n\ntraced_getSigma = torch.jit.trace(get_Sigma, (mytracePLN.n, mytracePLN.M, mytracePLN.S))\n\ndef get_inv(S):\n    return torch.inverse(S)\n\ntraced_getInv = torch.jit.trace(get_inv, get_Sigma(mytracePLN.n, mytracePLN.M, mytracePLN.S))\nCPU times: user 401 ms, sys: 4.63 ms, total: 406 ms\nWall time: 56 ms\n\n\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n  if a.grad is not None:\ndef tracefit(pln, N_iter, lr, tol = 1e-8) :\n\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -traced_getELBO(pln.S, pln.X, pln.B, pln.O, pln.M,\n            pln.n, pln.Omega, pln.Y, pln.p)\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = traced_getSigma(pln.n, pln.M, pln.S)\n        pln.Omega = traced_getInv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nand run the learning process:\n%%time\ntraceELBO = tracefit(mytracePLN, N_iter, lr = lr, tol = 1e-8)\nCPU times: user 25.6 s, sys: 171 ms, total: 25.8 s\nWall time: 26.5 s\n\n\n\nWe check that we get the same results with each method:\nplt.plot(np.log(-myPLN.ELBO), label='NO jit')\nplt.plot(np.log(-scriptELBO), label='jit script')\nplt.plot(np.log(-traceELBO), label='jit trace')\nplt.legend()\nplt.show()\n\n\n\nelbo_graph.png\n\n\n\nWe see that jit script and jit trace reduce computation time by a few second over the non jitted code. Hence, jit compilation in pytorch can be interesting but induces strict limitations that the user must be aware of.\nWe should try to consider a more involved problem computationally speaking (bigger input data, computations involving neural networks, …)"
  },
  {
    "objectID": "jit-example-pln.html#jit-compilation-with-pytorch",
    "href": "jit-example-pln.html#jit-compilation-with-pytorch",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We study Just In Time (JIT) compilation with pytorch. This tutorial is to be compared with JIT compilation in pytorch where much more explanations are given."
  },
  {
    "objectID": "jit-example-pln.html#set-up",
    "href": "jit-example-pln.html#set-up",
    "title": "JIT with pytorch",
    "section": "",
    "text": "References to pytorch JIT compilation, by order of difficulty:\n\npytorch jit official documentation\npytorch jit trace documentation\nTorchScript official tutorial\npytorch jit intermediate guide\npytorch jit intermediate / advanced guide\npytorch jit advanced guide\n\nMake necessary imports\nimport torch\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\nUsing a GPU.\nNote: We use pytorch GPU ! JIT compilation is particularly efficient on GPU. On this particular example, we were not able to see any speed up on CPU between jitted code and non-jitted code. We suppose it might be possible to get a CPU speed up on other case study, considering neural networks for example..\ndevice =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\ntorch.set_default_dtype(torch.float32)\nmyfloat = np.float32\ncuda\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 5000\nlr = 1e-2"
  },
  {
    "objectID": "jit-example-pln.html#original-non-jitted-version",
    "href": "jit-example-pln.html#original-non-jitted-version",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We reuse the code from PLN in pytorch.\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device:\n    torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol=1e-8) :\n      self.ELBO = np.zeros(N_iter, dtype=myfloat)\n      optimizer = torch.optim.Adam([self.B, self.M, self.S], lr=lr)\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\nLet’s create the PLN object:\n%%time\nmyPLN = PLN(Y, O, X, device)\nCPU times: user 523 ms, sys: 67 ms, total: 590 ms\nWall time: 134 ms\nand run the learning process:\n%%time\nmyPLN.fit(N_iter, lr = lr, tol=1e-8)\nCPU times: user 34.5 s, sys: 193 ms, total: 34.7 s\nWall time: 35.3 s"
  },
  {
    "objectID": "jit-example-pln.html#eager-graph-mode",
    "href": "jit-example-pln.html#eager-graph-mode",
    "title": "JIT with pytorch",
    "section": "",
    "text": "There are two ways to create the computational graph: eager execution and graph execution. The default mode in pytorch is eager, this means the computational graph is created at each forward pass in the graph. On the other hand, the graph mode adds an additional compilation step which builds the graph only once and lets the computations be done at a lower level.\nJIT (Just In Time) compilation is the process that builds an Intermediate Representation (IR) of the graph. This is the additional compilation step mentioned above.\nUsing graph mode, we gain:\n\nefficiency since the graph is precomputed and can be optimized to factorize redundant operations or delete useless operations.\nportability since this IR can be reused in another language.\n\nHowever, we lose:\n\nflexibility since we are tied to fixed array sizes, we cannot easily use control flows, …\n\nThere are two ways in pytorch to JIT our code, hence, there are two ways to use require the graph mode. We study these two ways in the next sections."
  },
  {
    "objectID": "jit-example-pln.html#jit-with-torch.jit.script",
    "href": "jit-example-pln.html#jit-with-torch.jit.script",
    "title": "JIT with pytorch",
    "section": "",
    "text": "By reading the above mentioned references, we get that we cannot jit the fit function. Some reasons are:\n\nN_iter is variable at compilation time (shape might change depending on input).\nthe pytorch optimizer’s operations cannot be jitted.\ntorch.jit.script cannot handle control flow or loops.\n\nclass jitPLN(torch.jit.ScriptModule) :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        super().__init__()\n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    @torch.jit.script_method\n    def _log_stirling(self, integer):\n        integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n        return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\n    @torch.jit.script_method\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    @torch.jit.script_method\n    def get_inv(self, S):\n      return torch.inverse(S)\n\n    @torch.jit.script_method\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(self._log_stirling(self.Y))\n      return elbo\n\ndef fit(pln, N_iter, lr, tol = 1e-8) :\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - pln.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = pln.get_Sigma()\n        pln.Omega = pln.get_inv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nLet’s create the jitted PLN object:\n%%time\nmyjitPLN = jitPLN(Y, O, X, device)\nCPU times: user 194 ms, sys: 4.8 ms, total: 199 ms\nWall time: 19.4 ms\nand run the learning process:\n%%time\nscriptELBO = fit(myjitPLN, N_iter, lr = lr, tol = 1e-8)\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: operator() profile_node %760 : int[] = prim::profile_ivalue(%dims.24)\n does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\n\nCPU times: user 27.3 s, sys: 164 ms, total: 27.4 s\nWall time: 28.2 s"
  },
  {
    "objectID": "jit-example-pln.html#jit-with-torch.jit.trace",
    "href": "jit-example-pln.html#jit-with-torch.jit.trace",
    "title": "JIT with pytorch",
    "section": "",
    "text": "Here we use torch.jit.trace over each of the computational functions, the PLN class is just a container for the objects. The previous limitations from torch.jit.script are still present, notably, we cannot jit the main for loop.\nclass tracejitPLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : torch.Tensor\n    p : torch.Tensor\n    d : torch.Tensor\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.n = torch.tensor(self.n)\n        self.p = torch.tensor(self.p)\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n        self.device = device\nLet’s create the PLN object and the jitted functions:\n%%time\nmytracePLN = tracejitPLN(Y, O, X, device)\n\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\ntraced_logstirling = torch.jit.trace(_log_stirling, (mytracePLN.Y))\n\ndef get_ELBO(S, X, B, O, M, n, Omega, Y, p): \n    S2 = torch.square(S)\n    XB = X @ B\n    A = torch.exp(O + M + XB + S2/2)\n\n    elbo = n/2 * torch.logdet(Omega)\n    elbo += torch.sum(- A + Y * (O + M + XB) + .5 * torch.log(S2))\n    elbo -= .5 * torch.trace(M.T @ M + torch.diag(torch.sum(S2, dim = 0)) @ Omega)\n    elbo += .5 * n * p  - torch.sum(traced_logstirling(Y))\n    return elbo\n\ntraced_getELBO = torch.jit.trace(get_ELBO, (mytracePLN.S, mytracePLN.X, mytracePLN.B, mytracePLN.O, mytracePLN.M,\n    mytracePLN.n, mytracePLN.Omega, mytracePLN.Y, mytracePLN.p))\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + torch.diag(torch.sum(S**2, dim = 0)))\n\ntraced_getSigma = torch.jit.trace(get_Sigma, (mytracePLN.n, mytracePLN.M, mytracePLN.S))\n\ndef get_inv(S):\n    return torch.inverse(S)\n\ntraced_getInv = torch.jit.trace(get_inv, get_Sigma(mytracePLN.n, mytracePLN.M, mytracePLN.S))\nCPU times: user 401 ms, sys: 4.63 ms, total: 406 ms\nWall time: 56 ms\n\n\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n  if a.grad is not None:\ndef tracefit(pln, N_iter, lr, tol = 1e-8) :\n\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -traced_getELBO(pln.S, pln.X, pln.B, pln.O, pln.M,\n            pln.n, pln.Omega, pln.Y, pln.p)\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = traced_getSigma(pln.n, pln.M, pln.S)\n        pln.Omega = traced_getInv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nand run the learning process:\n%%time\ntraceELBO = tracefit(mytracePLN, N_iter, lr = lr, tol = 1e-8)\nCPU times: user 25.6 s, sys: 171 ms, total: 25.8 s\nWall time: 26.5 s"
  },
  {
    "objectID": "jit-example-pln.html#conclusion",
    "href": "jit-example-pln.html#conclusion",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We check that we get the same results with each method:\nplt.plot(np.log(-myPLN.ELBO), label='NO jit')\nplt.plot(np.log(-scriptELBO), label='jit script')\nplt.plot(np.log(-traceELBO), label='jit trace')\nplt.legend()\nplt.show()\n\n\n\nelbo_graph.png\n\n\n\nWe see that jit script and jit trace reduce computation time by a few second over the non jitted code. Hence, jit compilation in pytorch can be interesting but induces strict limitations that the user must be aware of.\nWe should try to consider a more involved problem computationally speaking (bigger input data, computations involving neural networks, …)"
  },
  {
    "objectID": "torch_Python-PLN.html",
    "href": "torch_Python-PLN.html",
    "title": "PLN version Python",
    "section": "",
    "text": "Comme vous pourrez le constater, les syntaxtes {torch} et Pytorch sont très proches.\n\n\nOn charge le jeu de données oaks contenu dans le package python pyPLNmodels\n\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\noaks = load_oaks()\nY = oaks['counts']\nO = np.log(oaks['offsets'])\nX = np.ones([Y.shape[0],1])\n\nPour référence, on optimise avec le package dédié (qui utilise pytorch et l’optimiseur Rprop.\n\npln = Pln.from_formula(\"counts ~ 1 \", data = oaks, take_log_offsets = True)\n%timeit pln.fit()\n\nFitting a Pln model with full covariance model.\nInitialization ...\nInitialization finished\nTolerance 0.001 reached in 264 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 265 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 299 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 300 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 332 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 347 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 362 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 371 iterations\nThe slowest run took 34.98 times longer than the fastest. This could mean that an intermediate result is being cached.\n56.2 ms ± 44.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n\nimport torch\nimport numpy as np\nimport math\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN() :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    ELBO_list : list\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array) : \n        self.Y = torch.tensor(Y)\n        self.O = torch.tensor(O)\n        self.X = torch.tensor(X)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad = True)\n        self.S = torch.full(Y.shape, 1.0, requires_grad = True)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad = True)\n        self.Sigma = torch.eye(self.p)\n        self.Omega = torch.eye(self.p)\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega) +  torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2)) - .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega) + .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n      self.ELBO = np.zeros(N_iter)\n      optimizer = torch.optim.Rprop([self.B, self.M, self.S], lr = lr)\n      objective0 = np.infty\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n        \n        if (abs(objective0 - objective)/abs(objective) &lt; tol):\n          self.ELBO = self.ELBO[0:i]\n          break\n        else:\n          objective0 = objective\n\n\n\n\nTestons notre implémentation simple de PLN utilisant:\n\nmyPLN = PLN(Y, O, X)\n%timeit myPLN.fit(50, lr = 0.1, tol = 1e-8)\nplt.plot(np.log(-myPLN.ELBO))\n\n245 ms ± 6.73 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n```"
  },
  {
    "objectID": "torch_Python-PLN.html#pln-with-pytorch",
    "href": "torch_Python-PLN.html#pln-with-pytorch",
    "title": "PLN version Python",
    "section": "",
    "text": "Comme vous pourrez le constater, les syntaxtes {torch} et Pytorch sont très proches.\n\n\nOn charge le jeu de données oaks contenu dans le package python pyPLNmodels\n\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\noaks = load_oaks()\nY = oaks['counts']\nO = np.log(oaks['offsets'])\nX = np.ones([Y.shape[0],1])\n\nPour référence, on optimise avec le package dédié (qui utilise pytorch et l’optimiseur Rprop.\n\npln = Pln.from_formula(\"counts ~ 1 \", data = oaks, take_log_offsets = True)\n%timeit pln.fit()\n\nFitting a Pln model with full covariance model.\nInitialization ...\nInitialization finished\nTolerance 0.001 reached in 264 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 265 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 299 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 300 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 332 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 347 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 362 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 371 iterations\nThe slowest run took 34.98 times longer than the fastest. This could mean that an intermediate result is being cached.\n56.2 ms ± 44.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n\nimport torch\nimport numpy as np\nimport math\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN() :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    ELBO_list : list\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array) : \n        self.Y = torch.tensor(Y)\n        self.O = torch.tensor(O)\n        self.X = torch.tensor(X)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad = True)\n        self.S = torch.full(Y.shape, 1.0, requires_grad = True)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad = True)\n        self.Sigma = torch.eye(self.p)\n        self.Omega = torch.eye(self.p)\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega) +  torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2)) - .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega) + .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n      self.ELBO = np.zeros(N_iter)\n      optimizer = torch.optim.Rprop([self.B, self.M, self.S], lr = lr)\n      objective0 = np.infty\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n        \n        if (abs(objective0 - objective)/abs(objective) &lt; tol):\n          self.ELBO = self.ELBO[0:i]\n          break\n        else:\n          objective0 = objective\n\n\n\n\nTestons notre implémentation simple de PLN utilisant:\n\nmyPLN = PLN(Y, O, X)\n%timeit myPLN.fit(50, lr = 0.1, tol = 1e-8)\nplt.plot(np.log(-myPLN.ELBO))\n\n245 ms ± 6.73 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n```"
  },
  {
    "objectID": "torch_and_rcpp.html",
    "href": "torch_and_rcpp.html",
    "title": "Torch & Rcpp",
    "section": "",
    "text": "library(Rcpp)\nlibrary(RcppArmadillo)\nlibrary(torch)\nlibrary(tictoc)\nlibrary(bench) # comparaison des vitesses\nlibrary(ggplot2)\nlibrary(ggbeeswarm)"
  },
  {
    "objectID": "torch_and_rcpp.html#torch-on-r",
    "href": "torch_and_rcpp.html#torch-on-r",
    "title": "Torch & Rcpp",
    "section": "Torch on R",
    "text": "Torch on R\nLa librairie {torch} de R permet la manipulation de tenseur en R. Elle permet notamment de faire la différenciation automatique, c-a-d d’évaluer numériquement le gradient d’une fonction et d’effectuer des descentes de gradient.\nPrésentation finistR2022\nTorch and Automatic differentiation"
  },
  {
    "objectID": "torch_and_rcpp.html#rcpp",
    "href": "torch_and_rcpp.html#rcpp",
    "title": "Torch & Rcpp",
    "section": "Rcpp",
    "text": "Rcpp\nL’utilisation de {Rcpp} permet d’exporter des fonctions C++ en R. Les fonctions seront alors directement utilisables dans un script et avec des arguments R. Ainsi on peut tirer partie de la compilation d’un code C++, et accélérer de nombreux calculs algébriques.\nPour le calcul algébrique il est utile d’intégrer le package {RcppArmadillo} qui donne accès à la librairie {Armadillo} de C++ lorsque l’on appel une fonction {Rcpp} dans R.\nPrésentation finistR2018\n\nExample\nDans cet exemple nous allons calculer la perte d’une fonction logistique en R et en C++. Puis comparer les résultats avec le package {bench} de R.\n\nCoder la fonction en C++\n\n// [[Rcpp::depends(RcppArmadillo)]]\n#include &lt;RcppArmadillo.h&gt;\n\n// Logistic loss\n// [[Rcpp::export]]\n// const : pas de changement de valeur dans la fonction\n// arma:: : se sont les classes de Armadillo\n// using namespace arma to erase all arma::\n// & :  appel sans copie donc plus rapide\ndouble loss_cpp( const arma::vec theta, const arma::vec& y, const arma::mat& x ) {\n  arma::vec odds(x.n_rows);\n  odds = x * theta;\n  double log_lik;\n  log_lik = arma::dot(y, odds) - arma::sum(arma::log(1 + arma::exp(odds)));\n  return(-log_lik);\n}\n\n\n\nAppel et compilation du script depuis R avec la fonction sourceCpp() de {Rcpp}\n\nsourceCpp(file = \"logisticloss.cpp\")\n\n\n\nFonction loss en R\n\nloss_R &lt;- function(theta, y, x) {\n  odds &lt;- x %*% theta\n  log_lik &lt;- sum(y * odds - log(1 + exp(odds)))\n  return(-as.numeric(log_lik))\n}\n\n\n\nRésultats\nOn remarque que les résultats sont identiques pour la fonction {Rcpp} et la fonction en R.\n\ntheta = c(0.5, 0.1)\ny = 1.0\nx = matrix(c(0.1, 0.2), 1, 2)\n\n\nloss_cpp(theta, y, x)\n\n[1] 0.6587596\n\n\n\nloss_R(theta, y, x)\n\n[1] 0.6587596\n\n\nDans l’optique de comparer les performances de ces deux fonctions on utilise la fonction mark() du package {bench}.\n\nn_covar &lt;- 300\nsize &lt;- 1000\n\ntheta &lt;- rnorm(n_covar)\ny &lt;- as.numeric(rbinom(size, 1, 0.3))\nx &lt;- matrix(rnorm(size * n_covar), size, n_covar)\n\n\ncomp_tbl &lt;- bench::mark(\n  loss_R(theta = theta, y = y, x = x),\n  loss_cpp(theta = theta, y = y, x = x),\n  iterations = 1000\n)\n\nautoplot(comp_tbl)\n\nLoading required namespace: tidyr\n\n\n\n\n\nComme on peut le voir sur le graphique plus haut la fonction loss_cpp() est environ 2 fois plus efficace que la fonction loss_R().\n\n\nAttention aux librairies BLAS et LAPACK\nLa librairie BLAS de OpenBlas présentée lors de cette même session ne fonctionne pas correctement avec {Rcpp}. On observe une baisse de fonctionnement très quantitative (facteur 100). La librairie BLAS de Intel MKL reste quant à elle plus efficace."
  },
  {
    "objectID": "torch_and_rcpp.html#références",
    "href": "torch_and_rcpp.html#références",
    "title": "Torch & Rcpp",
    "section": "Références",
    "text": "Références\n\nCours state of the R (2023)\nfinistR2022 - Torch Auto Diff"
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html",
    "href": "how_to_maintain_a_dockerfile.html",
    "title": "Gestion d’un Dockerfile en projet collaboratif",
    "section": "",
    "text": "Lors d’un évènement comme finistR nous travaillons tous, sur des interfaces, des systèmes et des langages différents. Lors de finistR2023 par exemple, nous avons dû utiliser dans un même conteneur docker les langages R, Python et Julia et compiler cela via quarto. Construire un docker est quasiment aussi simple en principe que de suivre la recette d’une salade. Mais lorsque les problèmes arrivent et que la mayonnaise ne marche plus, il ne vous reste plus qu’à manger votre clavier…\nSur cette page vous trouverez premièrement un petit rappel sur ce qu’est un Dockerfile et le fonctionnement général de docker. Puis deuxièmement des indications plus particulières au conteneur de finistR2023 c’est à dire un docker R, Python, Julia et quarto"
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#i---un-dockerfile",
    "href": "how_to_maintain_a_dockerfile.html#i---un-dockerfile",
    "title": "Gestion d’un Dockerfile en projet collaboratif",
    "section": "I - Un Dockerfile ?",
    "text": "I - Un Dockerfile ?\nDocker est une technologie permettant de créer et utiliser de manière efficace des conteneurs logiciels. Ces conteneurs logiciel sont en fait des environnements de travail spécialisables, versionnés et facilement partageable. Docker permet donc de partager : des environnements de calculs pour des travaux en équipe, des applications (par exemple {shiny}), mais aussi permet l’intégration continue de site web et autres.\nVoici le Dockerfile utilisé pour ce projet:\n\n## Source Dockerfile\nFROM rocker/geospatial:4\n\n### JULIA\n\n## Copy Julia's tar.gz and install it\n## using 1.8.3 version because it does work with quarto on my computer\nRUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.3-linux-x86_64.tar.gz && \\\n    tar zxvf julia-1.8.3-linux-x86_64.tar.gz && \\\n    ## Connect to Julia's directory link with real jula's bin\n    cp -r julia-1.8.3 /opt/ && \\\n    ln -s /opt/julia-1.8.3/bin/julia /usr/local/bin/julia\n\n## Install Julias package (IJulia &lt;-- to connect with jupyter)\n## Installing from julia\nRUN julia -e 'import Pkg; Pkg.add(\"GeoDataFrames\"); Pkg.add(\"Distributed\"); Pkg.add(\"StatsAPI\"); Pkg.add(\"Plots\"); Pkg.add(\"DelimitedFiles\"); Pkg.add(\"DataFrames\"); Pkg.add(\"CSV\"); Pkg.add(\"GeoStats\"); Pkg.add(\"Rasters\"); Pkg.add(\"Shapefile\"); Pkg.add(\"GeoTables\"); Pkg.add(\"CairoMakie\"); Pkg.add(\"WGLMakie\"); Pkg.add(\"IJulia\")'\n\n## non Interactive terminal for this docker for the site\nRUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\\n    && apt-get install -y pandoc \\\n    pandoc-citeproc\n\n### R packages\n\n## Defining web acces for CRAN\nENV R_CRAN_WEB=\"https://cran.rstudio.com/\"\nRUN R -e \"install.packages('INLA',repos=c(getOption('repos'),INLA='https://inla.r-inla-download.org/R/stable'), dep=TRUE)\"\nRUN R -e \"install.packages(c('dyplr','ggplot2','remotes','microbenchmark','purrr','BiocManager','httr','cowplot','torch','PLNmodels','torchvision','reticulate','inlabru', 'lme4', 'ggpolypath', 'RColorBrewer', 'geoR','tidymodels', 'brulee', 'reprex','poissonreg','ggbeeswarm', 'tictoc', 'bench', 'circlize', 'JuliaCall', 'GeoModels','sp','terra','gstat','sf'))\"\nRUN R -e \"BiocManager::install('BiocPkgTools')\"\nRUN R -e \"torch::install_torch(type = 'cpu')\"\nRUN R -e \"JuliaCall::install_julia()\"\n\n### Ubuntu libraries (for python ?)\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n  jags \\\n  mercurial gdal-bin libgdal-dev gsl-bin libgsl-dev \\\n  libc6-i386\n\n### Jupyter Python torch jax etc\n## Downloading Python\nRUN apt-get install -y --no-install-recommends unzip python3-pip dvipng pandoc wget git make python3-venv && \\\n    pip3 install jupyter jupyter-cache flatlatex matplotlib && \\\n    apt-get --purge -y remove texlive.\\*-doc$ && \\\n    apt-get clean\n\nRUN pip3 install jax jaxlib torch numpy matplotlib pandas scikit-learn torchvision torchaudio pyplnmodels optax\n\nMalgré ce format peu tentant, l’écriture d’un Dockerfile est facile tant que l’on maîtrise bien les outils que le docker doit contenir.\n\na) FROM Le récypient de la reccette\nPour construire un conteneur docker on utilise en général au départ… un conteneur docker. De préférence il faut trouver un conteneur plus ou moins adapté à ce que l’on veux. Ici nous utilisons rocker/geospatial:4, les conteneurs rocker contiennent R avec ici une adaptation particulière au geospatial.\n\n\nb) RUN Les ingrédients de la recette\nAvec RUN il est possible d’effectuer des commandes en bash pour installer ce dont on a besoin dans le Docker. Pour rappel, ici il faut que nous puissions compiler un site web de manière automatique, et aussi compiler des quarto (Julia, R et Python) à l’origine des pages web. Pour chacune de ces étapes il faut vérifier l’installation du langage, installer les dépendances nécessaires au code. Et enfin s’assurer de la compatibilité entre les outils.\n\n\nc) Exemple - Instalation de Julia pour quarto\nIci R est déjà installé via rocker mais pas Julia. Le paragraphe suivant consiste à l’installation complète de Julia-1.8.3 dans un système type ubuntu.\n\nRUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.3-linux-x86_64.tar.gz && \\\n    tar zxvf julia-1.8.3-linux-x86_64.tar.gz && \\\n    ## Connect to Julia's directory link with real jula's bin\n    cp -r julia-1.8.3 /opt/ && \\\n    ln -s /opt/julia-1.8.3/bin/julia /usr/local/bin/julia\n\nLe symbole && \\ permet si la ligne à gauche est un succès de lancer la ligne suivante et le tout dans un seul RUN. En général il vaux mieux avoir peu de longue ligne de code que beaucoup de ligne faisant un appel systématique à RUN.\n\nwget télécharge Julia\ntar décompresse le fichier téléchargé\ncp copie Julia dans le dossier des programmes\nln créé un lien symbolique qui permet de lancer des script avec la commande $ julia depuis le terminal.\n\nCependant pour pouvoir lancer Julia depuis quarto cela ne suffit pas. Premièrement la version actuelle du langage ne communique pas correctement avec quarto alors que la version Julia-1.8.3 semble bien fonctionner. Deuxièmement il est nécessaire de créer un kernel IJulia pour connecter Julia à jupyter. C’est jupyter qui vas ensuite communiquer avec quarto. Pour faire cela, il faut installer le package {IJulia}.\n\nRUN julia -e 'import Pkg; Pkg.add(\"IJulia\")'\n\nOn prendra soins d’importer les autres packages dont nos quarto dépendent\n\nRUN julia -e 'import Pkg; Pkg.add(\"DataFrames\"); Pkg.add(\"GeoDataFrames\"); Pkg.add(\"IJulia\")'\n\nPar sécurité nous avons aussi choisi de faire la commande R suivante qui installe une petite dépendance de Julia dans R.\n\nRUN R -e \"JuliaCall::install_julia()\""
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#ii---construire-mon-dockerfile",
    "href": "how_to_maintain_a_dockerfile.html#ii---construire-mon-dockerfile",
    "title": "Gestion d’un Dockerfile en projet collaboratif",
    "section": "II - Construire mon Dockerfile ?",
    "text": "II - Construire mon Dockerfile ?\nPour arriver à écrire cela, avoir déjà installé le programme voulu en local est très utile ! Mais si votre ordinateur est un Windows cela ne vous aidera pas… Arriver à vos fin peut être compliqué et dans tout les cas il vas vous falloir essayer … La compilation d’un docker est assez longue donc chaque essais peut-être coûteux. Il existe cependant différents moyens de gagner du temps. Commencez d’abord par chercher les routines d’installation des vos dépendances sur ubuntu.\n\na) Organiser son fichier\nUne image docker lors de sa compilation en local, va garder en cache énormément d’information de manière séquentielle. Changer des lignes au début de mon Dockerfile est plus coûteux que de changer des lignes à la fin. Ainsi il est toujours plus intéressant lors du développement d’un conteneur de garder les lignes les moins sûres vers la fin du fichier (dans la mesure du possible).\n\n\nb) Compilation\nPour compiler mon conteneur il suffit de lancer la commande dans le répertoire où est mon Docker.\n\ndocker build -f Dockerfile --progress=plain -t nom_image:num_version .\n\nUn changement de numéro de version suffit à générer une nouvelle image en tirant toujours profit des données en cache.\n\n\nc) Tester rapidement un conteneur (exemple non-interactif)\nLe conteneur fabriqué pour le site de finistR est non interactif, une fois activé avec la ligne\n\ndocker run nom_image:num_version\n\nil n’est pas possible de lancer des commandes dans l’environnement créé depuis un terminal. Il n’est donc pas évident de tester les installations dans le conteneur.\nUne possibilité est de créé un deuxième Dockerfile (que l’on peut nommer 'DockerfileTest'). Voici un exemple\n\n## Source DockerfileTest\nFROM nom_image:num_version\n\nRUN quarto check jupyter\nRUN julia -e 'using GeoDataFrames'\n\nCe Dockerfile se build avec la commande\n\ndocker build -f DockerfileTest --progress=plain -t nom_image_test:num_version .\n\nUn intérêt de cette méthode est que l’on peux assez rapidement rééditer le conteneur le premier étant inchangé. Dans cet exemple :\n\nquarto check jupyter permet de vérifier si quarto a bien accès à jupyter mais aussi de vérifier si le kernel {IJulia} existe.\njulia -e 'using GeoDataFrames' vérifie si le package a bien été installé dans Julia.\n\nC’est lors de ce build que vous pouvez vérifier si ces commandes rendent les résultats attendus.\nDans le cas du conteneur de finistR, la compilation du conteneur sur github dure environ 45 min et le test à la suite d’une pull request dure environ 30 min. Grace à ces conseils un conteneur modifié aux dernières lignes se compile quasi immédiatement en local (idem pour DockerfileTest).\n\n\nd) Des bonnes pratiques oui ! Mais du groupe avant tout\nL’idéal dans ce genre de projet en groupe, est de pouvoir faire un suivis des packages et langages à installer. Pour cela lorsque que l’on effectue une pull request incluant un nouveau document, il est préférable de joindre explicitement en message :\n\nles dépendances\nla version du langage utilisé\nle système d’exploitation\n\nEn cas de problème avec un conteneur, ces informations sont très utiles pour résoudre les incompatibilités qui ont lieux."
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#références",
    "href": "how_to_maintain_a_dockerfile.html#références",
    "title": "Gestion d’un Dockerfile en projet collaboratif",
    "section": "Références",
    "text": "Références\n\nhttps://www.docker.com/"
  },
  {
    "objectID": "Readme.html",
    "href": "Readme.html",
    "title": "Ateliers Finist’R 2023",
    "section": "",
    "text": "Ateliers Finist’R 2023\n\n\n\nwebsite\n\n\nL’atelier Finist’R 2023 – ou bootcamp R s’est déroulé à la station biologique de Roscoff du 21 au 25 août 2023.\nIl s’agit de la septième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et dévelopeurs de paquets pour explorer les dernières fonctionalités du logiciel et les nouvelles pratiques de développement. A l’issu de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLa restitution se fait sous forme de site web. Le site de l’édition 2023 sera disponible ici"
  },
  {
    "objectID": "exams.html",
    "href": "exams.html",
    "title": "Nouveautés {learnr} et {exams}",
    "section": "",
    "text": "Introduction\nNous allons ici discuter du package {exams} qui permet de créer des feuilles d’examens (papier ou en ligne).\n\n\nexams\n{exams} est un package R disponible sur le CRAN. Il permet de construire des examens de manière automatique au format markdown ou LaTeX, incluant des chunks de code R dynamiques. Comme pour {learnr} les exercices peuvent être à choix multiples ou simples, des problèmes arithmétiques, du code…\nhttps://www.r-exams.org/\nUn examen exams a plusieurs sorties possibles:\n\nfichiers autonomes : PDF, HTML, Docx, ODT, …\nfichiers dynamiques: Moodle XML, QTI 1.2, QTI 2.1, Blackboard, Canvas, OpenOLAT, ARSnova, and TCExam\n\nIl est possible de scanner les feuilles d’examens imprimées et de les évaluer automatiquement avec l’outil NOPS.\nUne autre option intéressante, pour réduire le risque de triche, {exams} propose un mécanisme de variations aléatoires des exercices:\n\nmélange de l’ordre des questions\nmélange des réponses possibles pour les QCMs\nmélange des données des exercices\n\nIl est également possible de combiner {exams} avec un tutoriel {learnr}: https://www.r-exams.org/tutorials/exams2learnr/.\n\n\nRéférences\n\nhttps://www.r-exams.org/\nhttps://www.r-exams.org/tutorials/\nhttps://www.r-exams.org/intro/dynamic/"
  },
  {
    "objectID": "Utilisation_de_git.html",
    "href": "Utilisation_de_git.html",
    "title": "FinistR : Utilisation de git",
    "section": "",
    "text": "Introduction\nL’objectif de cet atelier était de voir comment intéragir avec le dépôt github finistR2023 afin de pouvoir contribuer à la réalisation de la page web. Nous avons pour cela crée une branche dédiée à cet atelier sur laquelle nous avons interagi avec deux ordinateurs différents. Ce compte rendu consitste en la restitution chronologique des commandes exécutées par ces deux ordinateurs, et détaille les problèmes rencontrés en cours de route.\n\n\nChronologie des commandes\nOrdinateur 1\nOn commence par cloner le dépôt github StateOfTheR/finistR2023 :\ngit clone git@github.com:StateOfTheR/finistR2023.git\nOn crée une nouvelle branche pour cet atelier git :\ngit branch Utilisation_de_git\nOn se déplace sur cette branche :\ngit checkout Utilisation_de_git\nOn crée un fichier qmd dans un nouveau dossier dédié à cet atelier :\n\nmkdir Utilisation_de_git\ncd Utilisation_de_git\nnvim Utilisation_de_git.qmd\n\nOn commit les modification et on les push dans le dépôt.\n\ngit add .\ngit commit -m \"création d'une branche pour l'atelier sur git\"\ngit push --set-upstream origin Utilisation_de_git \n\nLa partie --set-upstream origin Utilisation_de_git de la troisième commande n’est utile que parce que la branche n’existe pas encore dans le dépôt. Les prochains push se feront simplement avec la commande git push.\nA ce stade, le fichier Utilisation_de_git.qmd est comme suit :\n ————————————————————————————————————————————-\nOrdinateur 2\nAvec le deuxième ordinateur, nous avons cloné le dépôt, nous nous sommes placés sur la branche crée précédemment, nous avons ajouté du texte au fichier qmd sans modifier le texte déjà présent, puis nous avons pushé ces modifications sur le dépôt. Le fichier Utilisation_de_git.qmd était comme suit au moment du push :\n ————————————————————————————————————————————-\nOrdinateur 1\nEn parallèle de cette opération, nous avons aussi fait un ajout de texte avec le premier ordinateur :\n\nAprès avoir commité cette ajout de texte, nous avons fait un git pull et nous avons eu un conflit auquel nous ne nous attendions pas étant donné la nature des différences entre le fichier sur le dépôt et le fichier en local. Le message d’erreur était le suivant :\nYou have divergent branches and need to specify how to reconcile them. You can do so by running one of the following commands sometime before your next pull:\n\ngit config pull.rebase false # merge (the default strategy)\ngit config pull.rebase true # rebase\ngit config pull.ff only # fast-forward only\n\nYou can replace “git config” with “git config –global” to set a default preference for all repositories. You can also pass –rebase, –no-rebase, or –ff-only on the command line to override the configured default per invocation.\nNous pensions pouvoir résoudre ce conflit en fast forward, nous avons donc configuré le pull de cette façon :\ngit config pull.ff only\nPuis nous avons fait un git pull, mais cela n’a pas fonctionné.\nNous avons alors utilisé rebase :\ngit pull --rebase\nPuis nous avons ouvert le fichier qmd pour gérer les conflits en supprimant les “=” et les “&gt;”, après quoi nous avons commité ces modifications. Nous avons alors essayé de faire un push et nous avons eu le message d’erreur suivant :\nfatal: You are not currently on a branch. To push the history leading to the current (detached HEAD) state now, use \n\ngit push origin HEAD:&lt;name-of-the-remote-branch&gt; \n\nEffectivement, la commande git branch nous donnait le résultat suivant :\n*(no branch, rebasing Utilisation_de_git) Utilisation_de_git main\nNous avons résolu le problème avec\ngit rebase --continue\nEt le push a ensuite bien fonctionné. ————————————————————————————————————————————-\nA ce stade, nous nous sommes dits que nous avions mal géré le problème et que nous aurions dû utiliser la stratégie par défaut proposée dans le premier message d’erreur. Dans la suite, nous avons donc reconfiguré le pull (git config pull.rebase false) et nous avons recommencé ces ajouts de textes en parallèle avec les deux ordinateurs pour voir si c’était la bonne solution. Mais malgré cette reconfiguration du pull, git tentait toujours de le faire en fast forward. Cela venait de la commande git config pull.ff only exécutée précédemment et nous nous en sommes rendu compte en utilisant la commande git config -l qui permet de voir la configuration de certaines commandes git. Nous avons donc reconfiguré pull.ff :\ngit config pull.ff false\nEt le merge des deux fichiers a bien fonctionné.\nAu cours de ce travail, nous avons utilisé l’application gitk (installée avec sudo apt install gitk) qui permet de visualiser l’arbre des commits d’un répertoire git. Cette application s’utilise simplement en exécutant la commande gitk depuis le répertoire git désiré. Des options sont disponible pour customiser la vue et en particulier pour filtrer certaines branches de l’arbre (aller dans View &gt; New view). La figure ci-dessous représente l’arbre de notre branche à la fin des différents tests que l’on a effectués.\n\nPar ailleurs, un point important à mentionner est le recours à la commande history de bash pour accéder à l’historique de ce dernier (aussi accessible dans le fichier ~/.bash_history (pour les linuxiens)). En effet, cela nous a permis de retracer ce qui s’était passé et de mieux comprendre certaines choses. Nous avons cependant regrété que les log des commandes git ne soient pas automatiquement sauvegardés. Cela nous aurait beaucoup aidé.\n\n\nCommandes utiles\nCommandes précédées de git\n\nclone : clone un dépôt distant (de gitHub par exemple) dans un nouveau répertoire local.\nbranch\n\nbranch : affiche les noms des branches sur lesquelles on a travaillé, celle avec une étoile correspond à celle sur laquelle on est.\nbranch -a : affiche les noms de toutes les branches.\nbranch new_branch_name : créer une nouvelle branche.\n\ncheckout\n\ncheckout branch_name : se déplacer sur une branche.\ncheckout -b new_branch_name : créer une nouvelle branche et se déplacer sur cette nouvelle branche.\n\nstatus : affiche des informations sur la situation de notre git (la branche sur laquelle on est, les commits en cours,…)\nadd : Instruction à réaliser avant un commit, pour indiquer à git quels fichiers on veut suivre. Si on ne précise pas les noms des fichiers, par défaut tous les fichiers du répertoire sont ajoutés au suivi (sauf ceux du .gitignore).\ncommit -m commit_message : “commit” les changements réalisés dans les fichiers suivis (ceux qu’on a indiqué avec l’instruction add). On conseille de mettre un message explicite, c’est utile lorsqu’on souhaite revenir à une version précedente.\npush : envoi des modifications des fichiers commités sur le dépot distant.\npull par défaut équivalent à git fetch suivi de git merge : télécharge la branche distante (fetch) et la merge à la branche locale\n\npull : incorpore les modifications du dépot distant dans le répertoire local.\n\npull –rebase : pull en faisant un rebase\npull –merge : pull en faisant un merge\n\nconfig config permet de customiser la configuration des dossiers git, il y a une configuration locale (le dossier git courrant) et une configuration globale (valable pour tous les dossiers git)\n\nconfig -l : affiche les configurations de notre git pour le dossier courrant.\nconfig pull.rebase true : indique a git de faire un rebase par défaut au moment du pull, pour le dossier git courrant.\nconfig –global pull.rebase true : même chose mais pour tous les dossiers gits.\n\nrebase –continue : continue un rebase avorté par un échec de merge, après l’édition des fichiers conflictuels\nlog\n\nlog : affiche l’historique des commits de la branche sur laquelle on se trouve.\nlog –oneline : idem mais avec un affichage plus concis, sur une seule ligne.\n\n\n\n\nPerspectives\nAu cours de cet atelier, nous avons pu voir l’intérêt de git pour un projet collaboratif comme celui de la réalisation d’un site web. Néanmoins, n’étant pour la plupart d’entre nous que des utilisateurs novices de git dont l’utilisation se résume parfois à celle d’un simple drive, nous nous sommes demandés quels bénéfices nous pouvions en tirer pour une utilisation solitaire. En particulier pour en finir avec les répertoires remplis de fichiers comme analyse.ipynb, analyse_V2.ipynb, …, analyse_Vn.ipynb, dont l’un des intérêts est que cela permet de travailler simultanément sur plusieurs fichiers à la fois.\nUne solution basée sur la création de différentes branches et des commandes git stash et git popa émergé au moment de la restitution et sera testée prochainement.\n\n\nLiens utiles\n\nlearngitbranching\n\n\n\nRemerciements\nUn grand merci à Marie-Pierre sans qui cet atelier aurait pû durer très longtemps !"
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Créer une branche propre à l’atelier nommée explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCréer un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs éventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir à mettre à jour l’image docker"
  },
  {
    "objectID": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "href": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Créer une branche propre à l’atelier nommée explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCréer un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs éventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir à mettre à jour l’image docker"
  },
  {
    "objectID": "instructions.html#détails-du-fonctionnement",
    "href": "instructions.html#détails-du-fonctionnement",
    "title": "Instructions pour le dépot sur le site web",
    "section": "Détails du fonctionnement",
    "text": "Détails du fonctionnement\n\nLe docker\n(Lien vers la fiche pense-bête)[https://www.docker.com/sites/default/files/d8/2019-09/docker-cheat-sheet.pdf]\nPour créer des images Docker en local sur sa machine, voici une liste de commandes utiles\n\nPour construire une image docker, il faut créer un fichier Dockerfile qui contient la recette du Docker. Pour ce site le ficher Dockerfile a la forme suivante\n\n\n\n\nFROM rocker/geospatial:4\nRUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\\n && apt-get install -y pandoc \\\n    pandoc-citeproc\nRUN R -e \"install.packages('remotes')\"\nRUN R -e \"install.packages('microbenchmark')\"\nRUN R -e \"install.packages('purrr')\" # map function\nRUN R -e \"install.packages('BiocManager')\" # map function\nRUN R -e \"BiocManager::install('BiocPkgTools')\"\nRUN R -e \"install.packages('httr')\" # GET function\nENV R_CRAN_WEB=\"https://cran.rstudio.com/\"\nRUN R -e \"install.packages('cowplot')\" # GET function\nRUN R -e \"install.packages('torch')\"\nRUN R -e \"torch::install_torch(type = 'cpu')\"\nRUN R -e \"install.packages('PLNmodels')\"\nRUN R -e \"install.packages('torchvision')\"\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n  jags \\\n  mercurial gdal-bin libgdal-dev gsl-bin libgsl-dev \\\n  libc6-i386\n\n\nRUN R -e \"install.packages('INLA',repos=c(getOption('repos'),INLA='https://inla.r-inla-download.org/R/stable'), dep=TRUE)\"\nRUN R -e \"install.packages('reticulate')\"\nRUN R -e \"install.packages(c('inlabru', 'lme4', 'ggpolypath', 'RColorBrewer', 'geoR'))\"\nRUN R -e \"install.packages(c('tidymodels', 'brulee', 'reprex'))\"\nRUN R -e \"install.packages(c('poissonreg'))\"\nRUN apt-get install -y --no-install-recommends unzip python3-pip dvipng pandoc wget git make python3-venv && \\\n    pip3 install jupyter jupyter-cache flatlatex matplotlib && \\\n    apt-get --purge -y remove texlive.\\*-doc$ && \\\n    apt-get clean\n\nRUN pip3 install jax jaxlib torch numpy matplotlib pandas scikit-learn torchvision torchaudio\nRUN pip3 install pyplnmodels\nRUN pip3 install optax\n\n\npuis demander la construction de l’image à l’aide de la commande\n\n docker build -t nom_depot_dockerhub/nom_du_repo:version  . ## avec un nom\n\net enfin pousser sur Dockerhub\n\n docker push nom_depot_dockerhub/nom_du_repo:version\n\n\n\nLes actions\nDans les action de Github, on peut spécifier un container docker à utiliser, c’est ce que fait la ligne container du fichier d’action suivant, utiliser pour créer ce site web\n\n\nname: website\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    name: Build website with rmarkdown\n    runs-on: ubuntu-latest\n    container: stateofther/r-finistr2023:0.5\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Additional Packages\n        run: Rscript -e \"install.packages(c('ggbeeswarm', 'tictoc', 'bench', 'circlize', 'JuliaCall', 'GeoModels'))\"\n      - name: erase R-Julia-Geostats.qmd\n        run: rm \"R-Julia-Geostats.qmd\"\n      - name: Generate slides\n        run: \"quarto render\"\n      - name: GitHub Pages action\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./_site"
  },
  {
    "objectID": "torch_Python_R_ResNet.html",
    "href": "torch_Python_R_ResNet.html",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "",
    "text": "Le but est de comparer la syntaxe utilisée par les deux langages, seuls les exemples en R sont exécutés (difficultés de faire un quarto avec deux langages, voir issue ici ou de faire tourner pytorch avec {reticulate}). L’exemple d’application est un ResNet.\nPour charger installer la bibliothèque, en python, plusieurs possibilités sont données sur le site web officiel. Vous pouvez utiliser pip ou conda, avec ou sans cuda. Pour R, cela a déjà été fait à la session 2022 de finistR.\n\ninstall.packages(torch)\ntorch::install_torch() ## si vous avez un GPU compatible avec CUDA\n## torch::install_torch(type = \"cpu\") ## sinon\n\nUn bon ouvrage pour démarrer : Deep Learning and Scientific Computing with R torch."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#intro",
    "href": "torch_Python_R_ResNet.html#intro",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "",
    "text": "Le but est de comparer la syntaxe utilisée par les deux langages, seuls les exemples en R sont exécutés (difficultés de faire un quarto avec deux langages, voir issue ici ou de faire tourner pytorch avec {reticulate}). L’exemple d’application est un ResNet.\nPour charger installer la bibliothèque, en python, plusieurs possibilités sont données sur le site web officiel. Vous pouvez utiliser pip ou conda, avec ou sans cuda. Pour R, cela a déjà été fait à la session 2022 de finistR.\n\ninstall.packages(torch)\ntorch::install_torch() ## si vous avez un GPU compatible avec CUDA\n## torch::install_torch(type = \"cpu\") ## sinon\n\nUn bon ouvrage pour démarrer : Deep Learning and Scientific Computing with R torch."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#appel-des-fonctions",
    "href": "torch_Python_R_ResNet.html#appel-des-fonctions",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "Appel des fonctions",
    "text": "Appel des fonctions\nEn python, un premier exemple serait déjà d’importer la bibliothèque et de créer un tensor :\nimport torch\nt1 = torch.tensor(1)\nt1\nDonnera en R :\n\nlibrary(torch)\nt1 &lt;- torch_tensor(1)\nt1\n\ntorch_tensor\n 1\n[ CPUFloatType{1} ]\n\n\nOn comprend que la convention de nommage garde torch_ en préfix de toutes les fonctions implémentées."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#construction-dun-réseau-de-neurone-exemple-dun-resnet",
    "href": "torch_Python_R_ResNet.html#construction-dun-réseau-de-neurone-exemple-dun-resnet",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "Construction d’un réseau de neurone, exemple d’un ResNet",
    "text": "Construction d’un réseau de neurone, exemple d’un ResNet\n\nChargement des données\nOn va utiliser torchvision pour importer un jeu de données connu (des images annotées). On veut appliquer des transformations sur le jeu de test, mais hélas tout n’est pas encore implémenté. On commente les transformations pas encore implementées.\ntransform = transforms.Compose([\n    #transforms.Pad(4),\n    #transforms.RandomHorizontalFlip(),\n    #transforms.RandomCrop(32),\n    transforms.ToTensor()])\n\ntransform &lt;- function(img) {\n  # img &lt;- torchvision::transform_pad(img, 4) # pas implémenté\n  # img &lt;- torchvision::transform_random_horizontal_flip(img) # pas implémenté\n  # img &lt;- torchvision::transform_random_crop(img, 32) # bug sur la taille des images\n  img &lt;- torchvision::transform_to_tensor(img)\n  return(img)\n}\n\nVoici le code pour charger les données en python et R :\nnum_samples = 1000\n\ntrainData = torchvision.datasets.CIFAR10(root=\"./data\",\n                                         train=True,\n                                         transform=transform,\n                                         download=True)\n\ntestData = torchvision.datasets.CIFAR10(root=\"./data\",\n                                        train=False,\n                                        transform=transforms.ToTensor())\n\ntrainLoader = torch.utils.data.DataLoader(\n    dataset=Subset(trainData, range(num_samples)),\n    batch_size=256,\n    shuffle=True)\n\ntestLoader = torch.utils.data.DataLoader(\n    dataset=Subset(testData, range(num_samples)),\n    batch_size=256,\n    shuffle=False)\n\nnum_samples = 1000\n\ntrain_data &lt;- torchvision::cifar10_dataset(\n  root = \"./data\",\n  train = TRUE,\n  transform = transform,\n  download = TRUE\n)\n\ntest_data &lt;- torchvision::cifar10_dataset(\n  root = \"./data\",\n  train = FALSE,\n  transform = torchvision::transform_to_tensor\n)\n\ntrain_loader &lt;- dataloader(\n  dataset = dataset_subset(train_data, 1:num_samples),\n  batch_size = 256,\n  shuffle = TRUE\n)\n\ntest_loader &lt;- dataloader(\n  dataset = dataset_subset(test_data, 1:num_samples),\n  batch_size = 256,\n  shuffle = FALSE\n)\n\n\n\nConstruction d’un block residual\nPour définir notre block residual, on crée une classe torch.nn.Module et on y définit deux méthodes : __init__ et forward : qui hérite de torch.nn.Module.\ndef align(num_in, num_out, stride):\n    if num_in != num_out or stride &gt; 1:\n        return nn.Sequential(\n            nn.Conv2d(\n                num_in, num_out, kernel_size=3, stride=stride, padding=1, bias=False\n                ),\n            nn.BatchNorm2d(num_out)\n            )\n    else:\n        return lambda x: x\n\nclass ResBlock(nn.Module):\n    def __init__(self, num_in, num_out, stride):\n        super(ResBlock, self).__init__()\n        self.align = align(num_in, num_out, stride)\n        self.conv1 = nn.Conv2d(num_in, num_out, kernel_size=3,\n                            stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(num_out)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(num_out, num_out, kernel_size=3,\n                            stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(num_out)\n\n    def forward(self, x):\n        o = self.conv1(x)\n        o = self.bn1(o)\n        o = self.relu(o)\n        o = self.conv2(o)\n        o = self.bn2(o)\n        o = o + self.align(x)\n        o = self.relu(o)\n        return o\nDe la même manière, on peut créer un objet nn_module en R et y spécifier init et forward :\n\nalign &lt;- function(num_in, num_out, stride) {\n  if (num_in != num_out || stride &gt; 1) {\n    return(nn_sequential(\n      nn_conv2d(\n        num_in, num_out,\n        kernel_size = 3, stride = stride, padding = 1,\n        bias = FALSE\n      ),\n      nn_batch_norm2d(num_out)\n    ))\n  } else {\n    return(function(x) x)\n  }\n}\n\nres_block &lt;- nn_module(\n  initialize = function(num_in, num_out, stride) {\n    self$align &lt;- align(num_in, num_out, stride)\n    self$conv1 &lt;- nn_conv2d(num_in, num_out,\n      kernel_size = 3,\n      stride = stride, padding = 1, bias = FALSE\n    )\n    self$bn1 &lt;- nn_batch_norm2d(num_out)\n    self$relu &lt;- nn_relu(inplace = TRUE)\n    self$conv2 &lt;- nn_conv2d(num_out, num_out,\n      kernel_size = 3,\n      stride = 1, padding = 1, bias = FALSE\n    )\n    self$bn2 &lt;- nn_batch_norm2d(num_out)\n  },\n  forward = function(x) {\n    o &lt;- self$conv1(x)\n    o &lt;- self$bn1(o)\n    o &lt;- self$relu(o)\n    o &lt;- self$conv2(o)\n    o &lt;- self$bn2(o)\n    o &lt;- o + self$align(x)\n    o &lt;- self$relu(o)\n    return(o)\n  }\n)\n\n\n\nConstructeur ResNet\nPour construire notre ResNet, on veut créer des block residuals en chaîne. En python, on le fait de la manière suivante (toujours en utilisant torch.nn.Module) :\ndef buildResBlocks(num_in, num_out, stride, num_blocks):\n    blocks = [ResBlock(num_in, num_out, stride)]\n    for _ in range(1, num_blocks):\n        blocks.append(ResBlock(num_out, num_out, 1))\n    return nn.Sequential(*blocks)\n\nclass ResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet, self).__init__()\n        self.blocks0 = nn.Sequential(\n            nn.Conv2d(\n                3, 16, kernel_size=3,\n                stride=1, padding=1, bias=False\n                ),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True)\n            )\n        self.blocks1 = buildResBlocks(16, 16, 1, 2)\n        self.blocks2 = buildResBlocks(16, 32, 2, 2)\n        self.blocks3 = buildResBlocks(32, 64, 2, 2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        n = x.shape[0]\n        o = self.blocks0(x)\n        o = self.blocks1(o)\n        o = self.blocks2(o)\n        o = self.blocks3(o)\n        o = self.avgpool(o)\n        o = self.fc(o.reshape(n, -1))\n        return o\nEn R, cela donne :\n\nbuild_res_blocks &lt;- function(num_in, num_out, stride, num_blocks) {\n  blocks &lt;- list(res_block(num_in, num_out, stride))\n  for (i in 2:num_blocks) {\n    blocks[[i]] &lt;- res_block(num_out, num_out, 1)\n  }\n  return(do.call(nn_sequential, blocks))\n}\n\nres_net &lt;- nn_module(\n  initialize = function(num_classes) {\n    self$blocks0 &lt;- nn_sequential(\n      nn_conv2d(\n        3,\n        16,\n        kernel_size = 3,\n        stride = 1,\n        padding = 1,\n        bias = FALSE\n      ),\n      nn_batch_norm2d(16),\n      nn_relu(inplace = TRUE)\n    )\n    self$blocks1 &lt;- build_res_blocks(16, 16, 1, 2)\n    self$blocks2 &lt;- build_res_blocks(16, 32, 2, 2)\n    self$blocks3 &lt;- build_res_blocks(32, 64, 2, 2)\n    self$avgpool &lt;- nn_avg_pool2d(kernel_size = 8)\n    self$fc &lt;- nn_linear(64, num_classes)\n  },\n  forward = function(x) {\n    n &lt;- dim(x)[1]\n    o &lt;- self$blocks0(x)\n    o &lt;- self$blocks1(o)\n    o &lt;- self$blocks2(o)\n    o &lt;- self$blocks3(o)\n    o &lt;- self$avgpool(o)\n    o &lt;- torch_flatten(o, start_dim = 2)\n    o &lt;- self$fc(o)\n    return(o)\n  }\n)\n\n\n\nInstanciation modèle et optimiseurs\nPartie un peu plus rapide et simple, quasi identique dans les deux cas :\ndevice = \"cpu\"\nmodel = ResNet(10).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ndevice = \"cpu\"\nmodel &lt;- res_net$new(10)$to(device = device)\nmodel\n\nAn `nn_module` containing 195,738 parameters.\n\n── Modules ─────────────────────────────────────────────────────────────────────\n• blocks0: &lt;nn_sequential&gt; #464 parameters\n• blocks1: &lt;nn_sequential&gt; #9,344 parameters\n• blocks2: &lt;nn_sequential&gt; #37,184 parameters\n• blocks3: &lt;nn_sequential&gt; #148,096 parameters\n• avgpool: &lt;nn_avg_pool2d&gt; #0 parameters\n• fc: &lt;nn_linear&gt; #650 parameters\n\n\n\noptimizer &lt;- optim_adam(model$parameters, lr = 0.001)\noptimizer\n\n&lt;optim_adam&gt;\n  Inherits from: &lt;torch_optimizer&gt;\n  Public:\n    add_param_group: function (param_group) \n    clone: function (deep = FALSE) \n    defaults: list\n    initialize: function (params, lr = 0.001, betas = c(0.9, 0.999), eps = 1e-08, \n    load_state_dict: function (state_dict, ..., .refer_to_state_dict = FALSE) \n    param_groups: list\n    state: State, R6\n    state_dict: function () \n    step: function (closure = NULL) \n    zero_grad: function () \n  Private:\n    step_helper: function (closure, loop_fun) \n\n\n\n\nApprentissage\ndef train():\n    for epoch in range(1, 11):\n        for i, (x, y) in enumerate(trainLoader):\n            (x, y) = x.to(device), y.to(device)\n            o = model(x)\n            loss = F.cross_entropy(o, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if i % 100 == 0:\n                 print(\"Epoch: {}\\tLoss: {}\".format(epoch, loss.item()))\n\ntrain &lt;- function() {\n  for (epoch in 1:10) {\n    i &lt;- 0\n    coro::loop(for (batch in train_loader) {\n      x &lt;- batch[[1]]\n      y &lt;- batch[[2]]\n      o &lt;- model(x)\n      loss &lt;- nnf_cross_entropy(o, y)\n\n      optimizer$zero_grad()\n      loss$backward()\n      optimizer$step()\n      if (i %% 100 == 0) {\n        cat(sprintf(\"Epoch: %d\\tLoss: %.4f\\n\", epoch, loss$item()))\n      }\n      i &lt;- i + 1\n    })\n  }\n}\n\n\n\nComparaison temps de calcul\ntic = time.time()\ntrain()\nprint(time.time()-tic, \"s\")\n\ntic &lt;- system.time(\n  train()\n)\n\nEpoch: 1    Loss: 2.3981\nEpoch: 2    Loss: 1.9986\nEpoch: 3    Loss: 1.8066\nEpoch: 4    Loss: 1.6200\nEpoch: 5    Loss: 1.5309\nEpoch: 6    Loss: 1.5572\nEpoch: 7    Loss: 1.3535\nEpoch: 8    Loss: 1.3265\nEpoch: 9    Loss: 1.1657\nEpoch: 10   Loss: 1.1286\n\ntic\n\n   user  system elapsed \n 94.612   4.971  66.169 \n\n\nSur mon ordinateur : - python : 27.6s (elapsed) - R : 33.1s\nDes temps de calcul très comparables !\n\n\nPrécision\nPour tester la précision :\nn, N = 0, 0\nwith torch.no_grad():\n    for (x, y) in testLoader:\n        (x, y) = x.to(device), y.to(device)\n        o = model(x)\n        _, ŷ = torch.max(o, 1)\n        N += y.size(0)\n        n += torch.sum(ŷ == y).item()\n    print(\"Accuracy: {}\".format(n/N))\n\nwith_no_grad({\n  n_tests_ok &lt;- 0\n  n_tests &lt;- 0\n  coro::loop(for (batch in test_loader) {\n    x &lt;- batch[[1]]\n    y &lt;- batch[[2]]\n    o &lt;- model(x)\n    yest &lt;- torch_max(o, dim = 2)[[2]]\n    n_tests &lt;- n_tests + y$shape\n    n_tests_ok &lt;- n_tests_ok + torch_sum(y == yest)$item()\n  })\n  cat(\"Accuracy\", n_tests_ok / n_tests, \"\\n\")\n})\n\nAccuracy 0.422 \n\n\nLes deux codes donnent des résultats semblables !"
  },
  {
    "objectID": "torch_Python_regression.html",
    "href": "torch_Python_regression.html",
    "title": "Introduction à Pytorch",
    "section": "",
    "text": "Cette page constitue une traduction en Python avec pytorch de la page équivalente produite avec {torch} lors de FinistR 2022."
  },
  {
    "objectID": "torch_Python_regression.html#installation",
    "href": "torch_Python_regression.html#installation",
    "title": "Introduction à Pytorch",
    "section": "Installation",
    "text": "Installation\nUne façon (parmi d’autres) d’avoir une installation fonctionnelle de torch consiste à l’installer via conda. La page officielle est très bien documentée et fournit toutes les instructions nécessaires. La solution adoptée ici consiste à créer un environnement conda (nommé torch) pour y installer torch (en version CPU).\n#| eval: false\nconda create -n torch\nconda install pytorch torchvision torchaudio cpuonly -c pytorch\nconda install pandas matplotlib scikit-learn jupyter\nIl suffit alors d’activer l’environnement torch pour produire le html à partir du qmd\n#| eval: false\nconda activate torch\nquarto render my_document.qmd --to html"
  },
  {
    "objectID": "torch_Python_regression.html#exploration-de-torch-pour-la-différentiation-automatique",
    "href": "torch_Python_regression.html#exploration-de-torch-pour-la-différentiation-automatique",
    "title": "Introduction à Pytorch",
    "section": "Exploration de {torch} pour la différentiation automatique",
    "text": "Exploration de {torch} pour la différentiation automatique\n\nimport torch\nimport torch.distributions as dist\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression"
  },
  {
    "objectID": "torch_Python_regression.html#principe-du-calcul-de-gradient",
    "href": "torch_Python_regression.html#principe-du-calcul-de-gradient",
    "title": "Introduction à Pytorch",
    "section": "Principe du calcul de gradient",
    "text": "Principe du calcul de gradient\n{torch} fonctionne avec ses propres types numériques, qu’il faut créer avec la fonction torch.tensor() et ses propres fonctions torch.*(). Considérons un exemple très simple: \\(x \\mapsto x^2\\)\n\nx = torch.tensor(3)\ny = torch.square(x)\n\n\ny\n\ntensor(9)\n\n\nOn va pouvoir calculer \\(\\frac{dy}{dx}\\) en définissant x avec l’argument require_grad = True. Cet argument va spécifier que ‘x’ est entrainable et va démarrer l’enregistrement par autograd des opérations sur ce tenseur.\nAutograd est un module de torch qui permet de collecter les gradients. Il le fait en enregistrant des données (tenseurs) et toutes les opérations exécutées dans un graphe acyclique dirigé dont les feuilles sont les tenseurs d’entrée et les racines les tenseurs de sorties. Ces opérations sont stockées comme des fonctions et au moment du calcul des gradients, sont appliquées depuis le noeud de sortie en ‘backpropagation’ le long du réseau.\nAttention, torch ne peut stocker un gradient que pour des valeurs numériques (float), pas pour des entiers.\n\nx = torch.tensor(2.0, requires_grad = True)\nx\n\ntensor(2., requires_grad=True)\n\n\nOn remarque que x possède désormais un champ grad (même si ce dernier n’est pas encore défini).\n\nx.grad\n\nLorsqu’on calcule \\(y = x^2\\), ce dernier va également hériter d’un nouveau champ $grad_fn:\n\ny = torch.log(torch.square(x))\ny\ny.grad_fn\n\n&lt;LogBackward0 at 0x7fd0e88a6680&gt;\n\n\nqui indique comment calculer le gradient en utilisant la dérivée des fonctions composées:\n\\[\n(g\\circ f)'(x) = f'(x) \\times g'(f(x))\n\\]\net les fonctions\n\\[\n\\frac{dx^2}{dx} = 2x \\quad \\frac{d \\log(x)}{dx} = \\frac{1}{x}\n\\]\nLe calcul effectif du gradient est déclenché lors de l’appel à la méthode .backward() de y et est stocké dans le champ .grad de x.\n\nx.grad ## gradient non défini\ny.backward() \nx.grad ## gradient défini = 1\n\ntensor(1.)\n\n\nOn a bien:\n\\[\n\\frac{dy}{dx} = \\underbrace{\\frac{dy}{dz}}_{\\log}(z) \\times \\underbrace{\\frac{dz}{dx}}_{\\text{power}}(x) = \\frac{1}{4} \\times 2*2 = 1\n\\]\nIntuitivement au moment du calcul de y, torch construit un graphe computationnel qui lui permet d’évaluer numériquement \\(y\\) et qui va également servir pour calculer \\(\\frac{dy}{dz}\\) au moment de l’appel à la fonction .backward() issue du module autograd.\nEssayons de reproduire le calcul dans notre exemple. Le calcul forward donne\n\\[\nx = 2 \\xrightarrow{x \\mapsto x^2} z = 4 \\mapsto \\xrightarrow{x \\mapsto \\log(x)} y = \\log(4)\n\\]\nPour le calcul backward, il faut donc construire le graphe formel suivant. La première étape du graphe est accessible via $grad_fn\n\ny.grad_fn\n\n&lt;LogBackward0 at 0x7fd0e88a6680&gt;\n\n\net les fonctions suivantes via $next_functions\n\ny.grad_fn.next_functions\n\n((&lt;PowBackward0 at 0x7fd0116a1720&gt;, 0),)\n\n\nDans notre exemple, on a donc:\n\\[\n\\frac{dy}{dy} = 1 \\xrightarrow{x \\mapsto \\text{logBackward}(x)} \\frac{dy}{dz} = \\frac{dy}{dy} \\times \\text{logBackward}(z) \\xrightarrow{x \\mapsto \\text{powerBackward}(x)} \\frac{dy}{dx} = \\frac{dy}{dz} \\times \\text{logBackward}(x)\n\\]\nDans cet exemple:\n\n\\(\\text{logBackward}(x) = \\frac{1}{x}\\)\n\\(\\text{powBackward}(x) = 2x\\)\n\nEt la propagation des dérivées donne donc\n\\[\n\\frac{dy}{dy} = 1 \\to \\frac{dy}{dz} = 1 \\times \\frac{1}{4} = \\frac{1}{4} \\to \\frac{dy}{dx} = \\frac{1}{4} \\times 4 = 1\n\\]\nCe graphe est illustré ci-dessous pour la fonction \\((x_1, x_2) \\mapsto z = sin(x_2) log(x_1 x_2)\\)\n\nPour (beaucoup) plus de détails sur le graphe computationnel, on peut consulter la documentation officielle de PyTorch.\nIl faut juste noter que dans torch, le graphe computationnel est construit de façon dynamique, au moment du calcul de y."
  },
  {
    "objectID": "torch_Python_regression.html#régression-logistique-avec-torch",
    "href": "torch_Python_regression.html#régression-logistique-avec-torch",
    "title": "Introduction à Pytorch",
    "section": "Régression logistique avec torch",
    "text": "Régression logistique avec torch\nOn va adopter un simple modèle de régression logistique:\n\\[\nY_i \\sim \\mathcal{B}(\\sigma(\\theta^T x_i)) \\quad \\text{avec} \\quad \\sigma(x) = \\frac{1}{1 + e^{x}}\n\\]\nLe but est d’estimer \\(\\theta\\) et éventuellement les erreurs associées. On commence par générer des données.\n\n# Générer les paramètres\ntorch.manual_seed(45)\nn = 100\np = 3\n# Générer la matrice X\nX = torch.randn(n, p)\n# Générer le vecteur theta\ntheta = torch.randn(3)\n# Calculer les probabilités\nprobs = 1 / (1 + torch.exp(torch.mv(X, theta)))\n# Générer les observations Y en utilisant une distribution Bernoulli\nbernoulli_dist = dist.Bernoulli(probs=probs)\nY = bernoulli_dist.sample()\n\ntorch fonctionne avec ses propres types numériques, qu’il faut créer avec la fonction torch.tensor(). C’est ce qu’on a fait avec les fonctions torch.randn() et bernoulli_dist.sample() mais on pourrait forcer la conversion avec torch.tensor().\n\nx = X.clone()\ny = Y.clone()\n\nOn écrit ensuite la fonction de vraisemblance\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta) = \\sum_{i=1}^n y_i (\\theta^Tx_i) - \\sum_{i=1}^n log(1 + e^{\\theta^T x_i})\n\\]\n\ndef logistic_loss(theta, x, y):\n    odds = torch.mv(x, theta)\n    log_lik = torch.dot(y, odds) - torch.sum(torch.log(1 + torch.exp(odds)))\n    return -log_lik\n\navant de vérifier qu’elle fonctionne:\n\nlogistic_loss(theta = theta, x = x, y = y)\n\ntensor(80.1576)\n\n\nOn veut ensuite définir une fonction objective à maximiser (qui ne dépend que de theta):\n\ndef eval_loss(theta, verbose=True):\n    loss = logistic_loss(theta, x, y)\n    if verbose:\n        print(\"Theta:\", theta, \": Loss:\", float(loss))\n    return loss\n\net vérifier qu’elle fonctionne\n\neval_loss(theta, verbose = True)\n\nTheta: tensor([-0.2633, -0.2123,  0.5694]) : Loss: 80.15764617919922\n\n\ntensor(80.1576)\n\n\navant de procéder à l’optimisation à proprement parler. Pour cette dernière, on commence par définir notre paramètre sous forme d’un tenseur qui va être mis à jour\n\ntheta_current = torch.zeros(len(theta), requires_grad=True)\n\net d’un optimiseur:\n\noptimizer = optim.Rprop([theta_current])\n\nOn considère ici l’optimiseur Rprop (resilient backpropagation) qui ne prend pas en compte l’amplitude du gradient mais uniquement le signe de ses coordonnées (voir ici pour une introduction pédagogique à Rprop).\nIntuitivement, l’optimiseur a juste besoin de la valeur de \\(\\theta\\) et de son gradient pour le mettre à jour. Mais à ce stade on ne connaît pas encore le gradient \\(\\nabla_\\theta \\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta)\\)\n\ntheta_current.grad\n\net il faut donc le calculer:\n\nloss = eval_loss(theta_current, verbose = False)\nloss.backward()\n\nOn peut vérifier que le gradient est stocké dans theta\n\ntheta_current.grad\n\ntensor([-5.4452, -9.6232,  5.0331])\n\n\net effectuer la mise à jour avec une étape d’optimisation\n\noptimizer.step()\n\nOn peut vérifier que le paramètre courant a été mis à jour.\n\ntheta_current\n\ntensor([ 0.0100,  0.0100, -0.0100], requires_grad=True)\n\n\nIl ne reste plus qu’à recommencer pour un nombre d’itérations donné. Attention, il faut réinitialiser le gradient avant de le mettre à jour, le comportement par défaut de mise à jour étant l’accumulation plutôt que le remplacement.\n\nnum_iterations = 100\nloss_vector = []\n\nfor i in range(num_iterations):\n    optimizer.zero_grad()\n    loss = eval_loss(theta_current, verbose=False)\n    loss.backward()\n    optimizer.step()\n    loss_vector.append(loss.item())\n\nOn vérifie que la perte diminue au cours du temps.\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\nOn constate que notre optimiseur aboutit à peu près au même résultat que glm()\n\n# Ajustement du modèle GLM\nmodel = LogisticRegression(fit_intercept=False, penalty = None)\nmodel.fit(X, Y)\nsklearn_coeffs = model.coef_.tolist()[0]\n\n# Comparer les valeurs obtenues avec torch et glm\ndf = pd.DataFrame({\n    'torch': theta_current.detach().numpy().tolist(),\n    'sklearn': sklearn_coeffs\n})\nprint(df)\n\n      torch   sklearn\n0  0.125890  0.125891\n1  0.423913  0.423912\n2 -0.341100 -0.341100\n\n\nAttention la mécanique présentée ci-dessus avec .step() ne fonctionne pas pour certaines routines d’optimisation (BFGS, gradient conjugué) qui nécessite de calculer plusieurs fois la fonction objective. Dans ce cas, il faut définir une closure, qui renvoie la fonction objective, et la passer en argument à .step().\n\n%%time\n# Remise à zéro du paramètre courant\ntheta_current = torch.zeros(len(theta), requires_grad=True)\noptimizer = optim.Rprop([theta_current], lr=0.01)\n\n# Définition de la closure\ndef calc_loss():\n    optimizer.zero_grad()\n    loss = eval_loss(theta_current, verbose=False)\n    loss.backward()\n    return loss\n\n# Optimisation avec la closure\nnum_iterations = 100\nloss_vector = []\n\nfor i in range(num_iterations):\n    loss = optimizer.step(calc_loss).item()\n    loss_vector.append(loss)\n\nCPU times: user 60 ms, sys: 0 ns, total: 60 ms\nWall time: 59.9 ms\n\n\nOn peut vérifier qu’on obtient des résultats identiques dans les deux cas d’utilisation:\n\ntheta_current\n\ntensor([ 0.1259,  0.4239, -0.3411], requires_grad=True)\n\n\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()"
  },
  {
    "objectID": "torch_Python_regression.html#exemple-de-régression-multivariée",
    "href": "torch_Python_regression.html#exemple-de-régression-multivariée",
    "title": "Introduction à Pytorch",
    "section": "Exemple de régression multivariée",
    "text": "Exemple de régression multivariée\nOn considère un exemple de régression multiple, réalisé à partir du blog torch for optimization, où l’on cherche à estimer les paramètres de moyenne ainsi que la variance par maximisation de la vraisemblance.\nOn génère les données\n\n# Définir la graine aléatoire pour la reproductibilité\ntorch.manual_seed(45)\n# Générer la matrice X\nn = 100\nX = torch.cat((torch.ones(n, 1), torch.randn(n, 10)), dim=1)\n# Générer le vecteur Beta.true\nBeta_true = torch.randn(11)\n# Générer la variable dépendante Y\nY = torch.matmul(X, Beta_true) + torch.randn(n)\n\nLa fonction de perte à optimiser (ici la log-vraisemblance) va dépendre d’inputs définis comme des “tenseurs torch”:\n\n## Declare the parameter for the loss function\n## 11 parameters for Beta, 1 for sigma\nTheta = torch.ones(12, requires_grad = True)\n\nQuelques remarques :\n\nle paramètre \\(\\theta\\) à optimiser est ici défini comme un tenseur, i.e. un objet qui va notamment stocker la valeur courante de \\(\\theta\\). Avec l’option requires_grad=True la valeur courante du gradient de la dernière fonction appelée dépendant de \\(\\theta\\) va aussi être stockée.\nla matrice \\(X\\) est aussi définie comme un tenseur, mais l’option “requires_grad=TRUE” n’a pas été spécifiée, le gradient ne sera donc pas stocké pour cet objet. Cette distinction est explicitée lorsque l’on affiche les deux objets:\n\n\nTheta[:3]\nX[:3, :3]\n\ntensor([[ 1.0000,  0.1371,  1.5252],\n        [ 1.0000,  0.3665,  1.2984],\n        [ 1.0000, -0.1322,  0.0068]])\n\n\nLa fonction de perte est ici la log-vraisemblance, elle-même définie à partir d’opérateurs torch élémentaires :\n\ndef LogLik():\n    n = X.shape[0]  \n    # Last term of Theta is the std\n    sigma = Theta[11]\n    log_sigma = torch.log(sigma)\n    squared_residuals = torch.norm(Y - torch.matmul(X, Theta[:11])) ** 2\n    term1 = n * log_sigma\n    term2 = squared_residuals / (2 * (sigma ** 2))\n    return term1 + term2\n\nLa fonction LogLik peut être appliquée comme une fonction R qui prendra directement en argument les valeurs courantes de X.tensor et \\(\\theta\\), et produira en sortie un tenseur\n\nLogLik()\n\ntensor(736.3355, grad_fn=&lt;AddBackward0&gt;)\n\n\nOutre la valeur courante de la fonction, ce tenseur contient la “recette” du graphe computationnel utilisé dans calcul backward du gradient de la fonction LogLik par rapport à \\(\\theta\\). On peut ainsi afficher la dernière opération de ce graphe\n\ntoto = LogLik()\ntoto.grad_fn\n\n&lt;AddBackward0 at 0x7fd01179bc10&gt;\n\n\ncorrespondant à l’addition (AddBackward) des deux termes \\[  n\\times \\log(\\theta[11]) \\quad \\text{et} \\quad ||Y-X\\theta[0:10]||^2/(2*\\theta[11]^2)\\] dans le calcul de la perte. On peut afficher les opérations suivantes dans le graphe comme suit:\n\ntoto.grad_fn.next_functions\n\n((&lt;MulBackward0 at 0x7fd0116a27a0&gt;, 0), (&lt;DivBackward0 at 0x7fd00f1806d0&gt;, 0))\n\n\nL’étape suivante consiste à choisir la méthode d’optimisation à appliquer. L’intérêt d’utiliser le package {torch} est d’avoir accès à une large gamme de méthodes d’optimisation, on considère ici la méthode rprop qui réalise une descente de gradient à pas adaptatif et spécifique à chaque coordonnée:\n\n## Specify the optimization parameters\nlr = 0.01\noptimizer = optim.Rprop([Theta],lr)\n\nOn décrit maintenant un pas de calcul du gradient, contenant les étapes suivantes : - réinitialisation du gradient de \\(\\theta\\),\n- évaluation de la fonction de perte (avec la valeur courante de \\(\\theta\\)),\n- calcul backward du gradient. On inclut tout cela dans une fonction:\n\n## Optimization step description\ndef calc_loss():\n    optimizer.zero_grad()\n    value = LogLik()\n    value.backward()\n    return value\n\nCommençons par regarder ce que fait concrètement cette fonction. L’état courant du paramètre est le suivant:\n\nTheta\nTheta.grad\n\nOn applique une première fois la fonction, et on obtient la mise à jour suivante :\n\ncalc_loss()\nTheta\nTheta.grad\n\ntensor([  -73.6607,   133.4165,  -100.1567,   134.5971,    38.0697,   123.4896,\n           49.8657,    82.5681,   -27.1204,   185.5123,   176.2979, -1372.6710])\n\n\nComme on le voit la valeur courante du paramètre n’a pas changée, en revanche Theta.grad contient maintenant le gradient de la fonction de perte calculé en \\(\\theta\\). Dans le cas où la méthode d’optimisation considérée n’a besoin que de la valeur courante du gradient et du paramètre, on peut directement faire la mise à jour de \\(\\theta\\) :\n\noptimizer.step()\nTheta\nTheta.grad\n\ntensor([  -73.6607,   133.4165,  -100.1567,   134.5971,    38.0697,   123.4896,\n           49.8657,    82.5681,   -27.1204,   185.5123,   176.2979, -1372.6710])\n\n\nIl n’y a plus qu’à itérer !\n\n%%time\n## Run the optimization\nnum_iterations = 100\nloss_vector = torch.empty(num_iterations)\n\nfor i in range(num_iterations):\n    loss_vector[i] = calc_loss().item()\n    optimizer.step()\n\nCPU times: user 84.2 ms, sys: 0 ns, total: 84.2 ms\nWall time: 84.1 ms\n\n\nOn vérifie que l’optimisation s’est bien passée (ie que l’on a minimisé la fonction de perte)\n\n## How does the loss function behave ?\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n## Are the gradients at 0 ?\nTheta.grad\n\n\n\n\ntensor([ 3.7193e-05,  4.4323e-05, -2.5496e-05, -6.4963e-05, -6.7316e-05,\n         9.8318e-05,  6.5755e-06, -2.4864e-05,  2.1660e-05, -5.0762e-05,\n         5.5040e-06,  5.3406e-05])\n\n\net que le résultat est comparable à la solution classique obtenue par OLS :\n\n# Ajuster un modèle de régression linéaire avec scikit-learn\nregressor = LinearRegression(fit_intercept=False)\nregressor.fit(X, Y)\n\n# Obtenir les coefficients du modèle\nbeta_hat = regressor.coef_\n\n# Afficher les coefficients et tracer une ligne y = x\nprint(\"Coefficients du modèle de régression linéaire :\\n\", beta_hat)\nprint(\"Coefficients de Theta :\\n\", Theta[:11].detach().numpy().tolist())\n\n# Tracer la ligne y = x pour la comparaison\nplt.scatter(beta_hat, Theta[:11].detach().numpy().tolist())\nplt.plot([beta_hat.min(), beta_hat.max()], [beta_hat.min(), beta_hat.max()], color='red', linestyle='--')\nplt.xlabel('Coefficients du modèle de régression linéaire')\nplt.ylabel('Coefficients de Theta')\nplt.title('Comparaison des coefficients')\nplt.show()\n\n# Calculer la variance des résidus\nresiduals = Y - torch.matmul(X, torch.tensor(beta_hat).t())\nsigma_squared_lm = np.var(residuals.detach().numpy())\nsigma_squared_theta = Theta[11]\n\nprint(\"Variance du modèle de régression linéaire :\", sigma_squared_lm)\nprint(\"Variance de Theta[12] :\", sigma_squared_theta.item())\n\nCoefficients du modèle de régression linéaire :\n [ 1.7637296  -0.32114202  1.4978627  -0.11171199  0.4011397  -0.06434376\n  0.20324951 -0.2590317   0.98098207 -0.7663114  -0.64790714]\nCoefficients de Theta :\n [1.7637280225753784, -0.32114285230636597, 1.4978631734848022, -0.1117125004529953, 0.40113937854766846, -0.06434360891580582, 0.20324911177158356, -0.25903084874153137, 0.9809806942939758, -0.7663116455078125, -0.6479087471961975]\nVariance du modèle de régression linéaire : 1.2505516\nVariance de Theta[12] : 1.1182799339294434"
  }
]