[
  {
    "objectID": "torch_R_PLN.html",
    "href": "torch_R_PLN.html",
    "title": "PLN version R",
    "section": "",
    "text": "On charge le jeu de donn√©es oaks contenu dans PLNmodels\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\ndata(oaks)\n\nPour r√©f√©rence, on optimise avec le package d√©di√© (qui utilise le backend NLOpt, une bilbioth√®que C++ d‚Äôoptimisation non lin√©aire. La variance CCSQA, utilisant les gradients explicites, est utilis√©e).\n\nsystem.time(myPLN_nlopt &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks))\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  6.896   1.776   4.507 \n\n\n\n\n\nOn d√©finit une simple classe avec une routine d‚Äôoptimisation utilisant Rprop et l‚Äôauto-differentiation sur le crit√®re √† optimiser (l‚ÄôELBO = Expected Lower BOund).\n\nlibrary(torch)\nlibrary(R6)\n\nlog_stirling &lt;- function(n_){\n  n_ &lt;- n_+ (n_==0)\n  torch_log(torch_sqrt(2*pi*n_)) + n_*log(n_/exp(1))\n}\n\nPLN &lt;-\n  R6Class(\"PLN\",\n    public = list(\n      Y = NULL,\n      O = NULL,\n      X = NULL,\n      n = NULL,\n      p = NULL,\n      d = NULL,\n      M = NULL,\n      S = NULL,\n      A = NULL,\n      B = NULL,\n      Sigma = NULL,\n      Omega = NULL,\n      loglik = NULL,\n      ELBO_list = NULL,\n\n      ## Constructor\n      initialize = function(Y, O, X){\n        self$Y &lt;- torch_tensor(Y)\n        self$O &lt;- torch_tensor(O)\n        self$X &lt;- torch_tensor(X)\n        self$n &lt;- nrow(Y)\n        self$p &lt;- ncol(Y)\n        self$d &lt;- ncol(X)\n        ## Variational parameters\n        self$M &lt;- torch_zeros(self$n, self$p, requires_grad = TRUE)\n        self$S &lt;- torch_ones(self$n , self$p, requires_grad = TRUE)\n        ## Model parameters\n        self$B &lt;- torch_full(c(self$d, self$p), -8.0, requires_grad = TRUE)\n        self$Sigma &lt;- torch_eye(self$p)\n        self$Omega &lt;- torch_eye(self$p)\n        ## Monitoring\n        self$ELBO_list &lt;- c()\n      },\n\n      get_Sigma = function(M, S){\n        1/self$n * (torch_mm(torch_t(M),M) + torch_diag(torch_sum(S**2, dim = 1)))\n      },\n\n      get_ELBO = function(B, M, S, Omega){\n        S2 &lt;- torch_square(S)\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        self$n/2 * torch_logdet(Omega) -\n          torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2))\n      },\n    \n      get_loglik = function(B, M, S, Omega) {\n        S2 &lt;- S**2\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        J &lt;- self$n/2 * torch_logdet(Omega) + \n            .5 * self$n * self$p - torch_sum(log_stirling(self$Y)) -\n            torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2)) -\n          .5 * torch_sum(torch_mm(M, Omega) * M + S2 * torch_diag(Omega))\n        J\n      },\n\n      fit = function(N_iter, lr, tol = 1e-8, verbose = FALSE){\n        self$ELBO_list &lt;- double(length = N_iter)\n        optimizer &lt;- optim_rprop(c(self$B, self$M, self$S), lr = lr)\n        objective0 &lt;- Inf\n        for (i in 1:N_iter){\n          ## reinitialize gradients\n          optimizer$zero_grad()\n\n          ## compute current ELBO\n          loss &lt;- - self$get_ELBO(self$B, self$M, self$S, self$Omega)\n\n          ## backward propagation and optimization\n          loss$backward()\n          optimizer$step()\n\n          ## update parameters with close form\n          self$Sigma &lt;- self$get_Sigma(self$M, self$S)\n          self$Omega &lt;- torch_inverse(self$Sigma)\n\n          objective &lt;- -loss$item()\n          if(verbose && (i %% 50 == 0)){\n            pr('i : ', i )\n            pr('ELBO', objective)\n          }\n          self$ELBO_list[i] &lt;- objective\n          if (abs(objective0 - objective)/abs(objective) &lt; tol) {\n            self$ELBO_list &lt;- self$ELBO_list[1:i]\n            break\n          } else {\n            objective0 &lt;- objective\n          }\n        }\n        self$loglik &lt;- self$get_loglik(self$B, self$M, self$S, self$Omega)\n      },\n\n      plotLogNegElbo = function(from = 10){\n        plot(log(-self$ELBO_list[from:length(self$ELBO_list) ]), type = \"l\")\n      }\n    )\n  )\n\n\n\n\nOn cr√©e une instance avec les donn√©es appropri√©es\n\nY &lt;- oaks$Abundance\nX &lt;- cbind(rep(1, nrow(Y)))\nO &lt;- log(oaks$Offset)\nmyPLN &lt;- PLN$new(Y = Y, O = O, X = X)\n\nTestons notre impl√©mentation simple de PLN utilisant R-torch:\n\nsystem.time(myPLN$fit(1000, lr = 0.05, tol = 1e-9))\n\n   user  system elapsed \n  2.664   0.878   1.919 \n\nplot(-myPLN$ELBO_list, type=\"l\")\n\n\n\n\nEn fait, un backend torch est d√©j√† disponible dans le package PLNmodels\n\nsystem.time(myPLN_torch &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks, control = PLN_param(backend = 'torch', config_optim = list(lr = 0.01))))\n\n\n Initialization...\n Adjusting a full covariance PLN model with torch optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n 10.147   2.546   6.609 \n\n\nLes vraisemblances finales sont comparables\n\nmyPLN_nlopt$loglik\n\n[1] -32086.86\n\nmyPLN_torch$loglik\n\n[1] -32173.24\n\nmyPLN$loglik\n\ntorch_tensor\n-31816.6250\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward0&gt; ]\n\n\nAinsi que les param√®tres\n\nplot(myPLN$B,\n     myPLN_nlopt$model_par$B, \n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Regression coefficients\"); abline(0, 1, col = \"red\")\nplot(myPLN_torch$model_par$Sigma,\n     myPLN$Sigma,\n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Covariance matrix\"); abline(0, 1, col = \"red\")"
  },
  {
    "objectID": "torch_R_PLN.html#pln-with-r-torch",
    "href": "torch_R_PLN.html#pln-with-r-torch",
    "title": "PLN version R",
    "section": "",
    "text": "On charge le jeu de donn√©es oaks contenu dans PLNmodels\n\nlibrary(PLNmodels)\n\nThis is packages 'PLNmodels' version 1.0.3\n\n\nUse future::plan(multicore/multisession) to speed up PLNPCA/PLNmixture/stability_selection.\n\ndata(oaks)\n\nPour r√©f√©rence, on optimise avec le package d√©di√© (qui utilise le backend NLOpt, une bilbioth√®que C++ d‚Äôoptimisation non lin√©aire. La variance CCSQA, utilisant les gradients explicites, est utilis√©e).\n\nsystem.time(myPLN_nlopt &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks))\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n  6.896   1.776   4.507 \n\n\n\n\n\nOn d√©finit une simple classe avec une routine d‚Äôoptimisation utilisant Rprop et l‚Äôauto-differentiation sur le crit√®re √† optimiser (l‚ÄôELBO = Expected Lower BOund).\n\nlibrary(torch)\nlibrary(R6)\n\nlog_stirling &lt;- function(n_){\n  n_ &lt;- n_+ (n_==0)\n  torch_log(torch_sqrt(2*pi*n_)) + n_*log(n_/exp(1))\n}\n\nPLN &lt;-\n  R6Class(\"PLN\",\n    public = list(\n      Y = NULL,\n      O = NULL,\n      X = NULL,\n      n = NULL,\n      p = NULL,\n      d = NULL,\n      M = NULL,\n      S = NULL,\n      A = NULL,\n      B = NULL,\n      Sigma = NULL,\n      Omega = NULL,\n      loglik = NULL,\n      ELBO_list = NULL,\n\n      ## Constructor\n      initialize = function(Y, O, X){\n        self$Y &lt;- torch_tensor(Y)\n        self$O &lt;- torch_tensor(O)\n        self$X &lt;- torch_tensor(X)\n        self$n &lt;- nrow(Y)\n        self$p &lt;- ncol(Y)\n        self$d &lt;- ncol(X)\n        ## Variational parameters\n        self$M &lt;- torch_zeros(self$n, self$p, requires_grad = TRUE)\n        self$S &lt;- torch_ones(self$n , self$p, requires_grad = TRUE)\n        ## Model parameters\n        self$B &lt;- torch_full(c(self$d, self$p), -8.0, requires_grad = TRUE)\n        self$Sigma &lt;- torch_eye(self$p)\n        self$Omega &lt;- torch_eye(self$p)\n        ## Monitoring\n        self$ELBO_list &lt;- c()\n      },\n\n      get_Sigma = function(M, S){\n        1/self$n * (torch_mm(torch_t(M),M) + torch_diag(torch_sum(S**2, dim = 1)))\n      },\n\n      get_ELBO = function(B, M, S, Omega){\n        S2 &lt;- torch_square(S)\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        self$n/2 * torch_logdet(Omega) -\n          torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2))\n      },\n    \n      get_loglik = function(B, M, S, Omega) {\n        S2 &lt;- S**2\n        XB &lt;- torch_mm(self$X, B)\n        A  &lt;- torch_exp(self$O + M + XB + S2/2)\n        J &lt;- self$n/2 * torch_logdet(Omega) + \n            .5 * self$n * self$p - torch_sum(log_stirling(self$Y)) -\n            torch_sum(A - self$Y * (self$O + M + XB) - .5 * torch_log(S2)) -\n          .5 * torch_sum(torch_mm(M, Omega) * M + S2 * torch_diag(Omega))\n        J\n      },\n\n      fit = function(N_iter, lr, tol = 1e-8, verbose = FALSE){\n        self$ELBO_list &lt;- double(length = N_iter)\n        optimizer &lt;- optim_rprop(c(self$B, self$M, self$S), lr = lr)\n        objective0 &lt;- Inf\n        for (i in 1:N_iter){\n          ## reinitialize gradients\n          optimizer$zero_grad()\n\n          ## compute current ELBO\n          loss &lt;- - self$get_ELBO(self$B, self$M, self$S, self$Omega)\n\n          ## backward propagation and optimization\n          loss$backward()\n          optimizer$step()\n\n          ## update parameters with close form\n          self$Sigma &lt;- self$get_Sigma(self$M, self$S)\n          self$Omega &lt;- torch_inverse(self$Sigma)\n\n          objective &lt;- -loss$item()\n          if(verbose && (i %% 50 == 0)){\n            pr('i : ', i )\n            pr('ELBO', objective)\n          }\n          self$ELBO_list[i] &lt;- objective\n          if (abs(objective0 - objective)/abs(objective) &lt; tol) {\n            self$ELBO_list &lt;- self$ELBO_list[1:i]\n            break\n          } else {\n            objective0 &lt;- objective\n          }\n        }\n        self$loglik &lt;- self$get_loglik(self$B, self$M, self$S, self$Omega)\n      },\n\n      plotLogNegElbo = function(from = 10){\n        plot(log(-self$ELBO_list[from:length(self$ELBO_list) ]), type = \"l\")\n      }\n    )\n  )\n\n\n\n\nOn cr√©e une instance avec les donn√©es appropri√©es\n\nY &lt;- oaks$Abundance\nX &lt;- cbind(rep(1, nrow(Y)))\nO &lt;- log(oaks$Offset)\nmyPLN &lt;- PLN$new(Y = Y, O = O, X = X)\n\nTestons notre impl√©mentation simple de PLN utilisant R-torch:\n\nsystem.time(myPLN$fit(1000, lr = 0.05, tol = 1e-9))\n\n   user  system elapsed \n  2.664   0.878   1.919 \n\nplot(-myPLN$ELBO_list, type=\"l\")\n\n\n\n\nEn fait, un backend torch est d√©j√† disponible dans le package PLNmodels\n\nsystem.time(myPLN_torch &lt;- PLN(Abundance ~ 1 + offset(log(Offset)), data = oaks, control = PLN_param(backend = 'torch', config_optim = list(lr = 0.01))))\n\n\n Initialization...\n Adjusting a full covariance PLN model with torch optimizer\n Post-treatments...\n DONE!\n\n\n   user  system elapsed \n 10.147   2.546   6.609 \n\n\nLes vraisemblances finales sont comparables\n\nmyPLN_nlopt$loglik\n\n[1] -32086.86\n\nmyPLN_torch$loglik\n\n[1] -32173.24\n\nmyPLN$loglik\n\ntorch_tensor\n-31816.6250\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward0&gt; ]\n\n\nAinsi que les param√®tres\n\nplot(myPLN$B,\n     myPLN_nlopt$model_par$B, \n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Regression coefficients\"); abline(0, 1, col = \"red\")\nplot(myPLN_torch$model_par$Sigma,\n     myPLN$Sigma,\n     xlab = \"Naive torch\", ylab = \"PLN torch\", \n     main = \"Covariance matrix\"); abline(0, 1, col = \"red\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinistR : bootcamp R √† Roscoff",
    "section": "",
    "text": "L‚Äôatelier Finist‚ÄôR 2023 ‚Äì ou bootcamp R du groupe State Of The R s‚Äôest d√©roul√© √† la station biologique de Roscoff du 21 au 25 ao√ªt 2023.\nStateoftheR est un r√©seau du d√©partement MathNum INRAE.\n\n\nIl s‚Äôagissait de la septi√®me √©dition de l‚Äôatelier Finist‚ÄôR. Cet atelier r√©unit annuellement un groupe de chercheurs, ing√©nieurs, doctorants, tous utilisateurs avanc√©s de R et d√©veloppeurs de paquets pour explorer les derni√®res fonctionnalit√©s du logiciel et les nouvelles pratiques de d√©veloppement. A l‚Äôissue de l‚Äôatelier le collectif produit une synth√®se de cette veille logiciel de mani√®re √† progresser collectivement dans l‚Äôutilisation du logiciel mais surtout dans la production d‚Äôoutils statistiques √† destination de la communaut√©.\nLe r√©sultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#o√π-quand",
    "href": "index.html#o√π-quand",
    "title": "FinistR : bootcamp R √† Roscoff",
    "section": "",
    "text": "L‚Äôatelier Finist‚ÄôR 2023 ‚Äì ou bootcamp R du groupe State Of The R s‚Äôest d√©roul√© √† la station biologique de Roscoff du 21 au 25 ao√ªt 2023.\nStateoftheR est un r√©seau du d√©partement MathNum INRAE.\n\n\nIl s‚Äôagissait de la septi√®me √©dition de l‚Äôatelier Finist‚ÄôR. Cet atelier r√©unit annuellement un groupe de chercheurs, ing√©nieurs, doctorants, tous utilisateurs avanc√©s de R et d√©veloppeurs de paquets pour explorer les derni√®res fonctionnalit√©s du logiciel et les nouvelles pratiques de d√©veloppement. A l‚Äôissue de l‚Äôatelier le collectif produit une synth√®se de cette veille logiciel de mani√®re √† progresser collectivement dans l‚Äôutilisation du logiciel mais surtout dans la production d‚Äôoutils statistiques √† destination de la communaut√©.\nLe r√©sultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#participants",
    "href": "index.html#participants",
    "title": "FinistR : bootcamp R √† Roscoff",
    "section": "Participants",
    "text": "Participants\nEmr√© Anakok, Julie Aubert, Pierre Barbillon, Barbara Bricout, Caroline Cognot, F√©lix Cheysson, Julien Chiquet, Anna√Øg De Walsche, Marie-Pierre Etienne, Armand Favrot, Hugo Gangloff, Pierre Gloaguen, J√©r√©my Lamouroux, Corentin Lothod√©, Mahendra Mariadassou, Tristan Mary-Huard, Isabelle Sanchez, Florian Teste, Th√©odore Vanrentherghem, Emily Walker."
  },
  {
    "objectID": "index.html#soutien",
    "href": "index.html#soutien",
    "title": "FinistR : bootcamp R √† Roscoff",
    "section": "Soutien",
    "text": "Soutien"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html",
    "title": "R-Julia-Geostats",
    "section": "",
    "text": "L‚Äôobjectif est de comparer des packages R, et Julia pour du krigeage.\nOn va utiliser :\n- R : gstat\n- R : GeoModels\n- Julia : GeoStats\nOn compare les points suivant :\n- simplicit√© des donn√©es d‚Äôentr√©e\n- concision du code\n- vitesse d‚Äôex√©cution\n- type d‚Äôestimation\nPour chaque package, on calculera pour les m√™mes donn√©es le variogramme empirique, puis on ajustera un variogramme th√©orique et on fera un krigeage."
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#donn√©es",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#donn√©es",
    "title": "R-Julia-Geostats",
    "section": "Donn√©es",
    "text": "Donn√©es\n\nlibrary(sp)\nlibrary(sf)\nlibrary(terra)\ndata(meuse)\ndata(meuse.grid)\n\nlibrary(tidyverse)\nlibrary(gstat)\nlibrary(GeoModels)\n\nOn utilise les donn√©es meuse du package sp. Celles-ci contiennent des donn√©es de concentration en m√©taux pr√®s de la meuse, avec des coordonn√©es cart√©siennes en m.\nPour travailler sur ces concentrations, on passera tout au log afin de les normaliser.\nPour la visualisation en R, on utilise le package terra."
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#transformation-au-format-sf",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#transformation-au-format-sf",
    "title": "R-Julia-Geostats",
    "section": "Transformation au format sf",
    "text": "Transformation au format sf\n\ndf = select(meuse,x,y,cadmium,zinc)\ndf_grid = select(meuse.grid,x,y)\ndf_sf &lt;- df %&gt;% \n  sf::st_as_sf( coords = c('x','y'))\n\ndf_sf &lt;- sf::st_make_valid(df_sf)\ndf_grid_sf = df_grid%&gt;% sf::st_as_sf(coords = c('x','y'))%&gt;%sf::st_make_valid()\nggplot(df, aes(y=log(zinc))) + \n  geom_boxplot(notch=FALSE) +\n  labs(y = \"Log(Zn concentration)\") +\n  theme_minimal() +                                   \n  theme(\n    axis.text.x = element_blank(),\n    axis.ticks = element_blank(),\n    axis.line = element_blank()\n  )"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#variogramme-empirique",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#variogramme-empirique",
    "title": "R-Julia-Geostats",
    "section": "Variogramme empirique",
    "text": "Variogramme empirique\nPour simplifier la comparaison avec le package Julia, on va se contenter d‚Äôune moyenne constante sans introduire de pr√©dicteurs : on demande donc log(zinc)~1. Si on avait voulu, comme dans le tutoriel du package, expliquer la moyenne par la distance √† la rivi√®re, il faudrait modifier cette formule en log(zinc)~distance apr√®s avoir rajout√© une colonne distance au sf dataframe.\nAppeler plot sur un objet issu de variogram permet d‚Äôen obtenir un trac√©.\n\nstart_time &lt;- Sys.time()\ntest &lt;- variogram(log(zinc)~1  , df_sf,cutoff = 2000)\nend_time &lt;- Sys.time()\nend_time - start_time\n\nTime difference of 0.02771139 secs\n\nplot(test)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#le-type-vgm",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#le-type-vgm",
    "title": "R-Julia-Geostats",
    "section": "Le type vgm",
    "text": "Le type vgm\nPlusieurs mod√®les de variogrammes spatiaux sont disponibles dans la librairie.\n\nshow.vgms()\n\n\n\n(vgm())\n\n   short                                      long\n1    Nug                              Nug (nugget)\n2    Exp                         Exp (exponential)\n3    Sph                           Sph (spherical)\n4    Gau                            Gau (gaussian)\n5    Exc        Exclass (Exponential class/stable)\n6    Mat                              Mat (Matern)\n7    Ste Mat (Matern, M. Stein's parameterization)\n8    Cir                            Cir (circular)\n9    Lin                              Lin (linear)\n10   Bes                              Bes (bessel)\n11   Pen                      Pen (pentaspherical)\n12   Per                            Per (periodic)\n13   Wav                                Wav (wave)\n14   Hol                                Hol (hole)\n15   Log                         Log (logarithmic)\n16   Pow                               Pow (power)\n17   Spl                              Spl (spline)\n18   Leg                            Leg (Legendre)\n19   Err                   Err (Measurement error)\n20   Int                           Int (Intercept)\n\n\nUn variogramme th√©orique est un objet de type vgm, qui doit √™tre initialis√© avec des param√®tres avant de l‚Äôins√©rer dans la fonction d‚Äôestimation.\nUn inconv√©nient dans la cr√©ation d‚Äôun objet vgm est l‚Äôabsence de nom pour certains param√®tres, il faut se r√©f√©rer √† la documentation pour savoir √† quel place il faut rentrer quel argument lorsque‚Äôon appelle vgm(). Ne pas renseigner un argument initialise celui-ci √† NA. Utiliser fit.variogram sur un objet avec des NA fait appel √† une √©tape suppl√©mentaire qui initialise avec des param√®tres issus du variogramme empirique. Cela emp√™che de contr√¥ler les valeurs initiales de l‚Äôestimation."
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#estimation-du-variogramme-th√©orique",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#estimation-du-variogramme-th√©orique",
    "title": "R-Julia-Geostats",
    "section": "Estimation du variogramme th√©orique",
    "text": "Estimation du variogramme th√©orique\nLes param√®tres du variogramme th√©orique sont ajust√©s par moindres carr√©s sur le variogramme empirique.\nvgmModelwav &lt;- fit.variogram(test,vgm(‚ÄòWav‚Äô))\n\nvgmModelexp &lt;- fit.variogram(test, vgm(2, \"Exp\", 1000))\nvgmModelexp\n\n  model     psill    range\n1   Exp 0.6849652 421.2255\n\nvgmModelmat &lt;- fit.variogram(test, vgm(10, \"Mat\", 300, 4.5, kappa = 0.7))\nvgmModelmat\n\n  model      psill    range kappa\n1   Nug 0.05112814   0.0000   0.0\n2   Mat 0.62395526 340.0403   0.7\n\nvgmModelNA &lt;- fit.variogram(test,vgm('Mat'))\nvgmModelNA\n\n  model       psill    range kappa\n1   Nug 0.001864289   0.0000   0.0\n2   Mat 0.684275121 424.4234   0.5\n\nstart_time &lt;- Sys.time()\nvgmModelwav &lt;- fit.variogram(test,vgm('Wav'))\nend_time &lt;- Sys.time()\nend_time - start_time\n\nTime difference of 0.00620985 secs\n\nvgmModelwav\n\n  model     psill    range\n1   Nug 0.1556503   0.0000\n2   Wav 0.4407740 643.9395\n\n\nLa fonction plot() appel√©e sur un mod√®le estim√© trace en continu le variogramme th√©orique et en points le variogramme empirique.\n\nplot(test, vgmModelmat)\n\n\n\nplot(test, vgmModelwav)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#krigeage",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#krigeage",
    "title": "R-Julia-Geostats",
    "section": "Krigeage",
    "text": "Krigeage\n\nstart_time &lt;- Sys.time()\nkrig &lt;- krige(log(zinc)~1 , df_sf, df_grid_sf, model = vgmModelmat)\n\n[using ordinary kriging]\n\nend_time &lt;- Sys.time()\nend_time - start_time\n\nTime difference of 0.6506536 secs\n\nKres_pred = data.frame(x=meuse.grid$x,y=meuse.grid$y,pred=krig$var1.pred)\nkrig_res&lt;- terra::rast(Kres_pred, type=\"xyz\", crs=\"EPSG:2154\")\n\n\nKres_var = data.frame(x=meuse.grid$x,y=meuse.grid$y,pred=krig$var1.var)\nkrig_var&lt;- terra::rast(Kres_var, type=\"xyz\", crs=\"EPSG:2154\")\n\nplot((krig_res), main = 'Krigeage de log(zinc) - gstat')\n\n\n\nplot(krig_var,main = 'Erreur de krigeage pour log(zinc) - gstat')"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#variogramme-empirique-1",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#variogramme-empirique-1",
    "title": "R-Julia-Geostats",
    "section": "Variogramme empirique",
    "text": "Variogramme empirique\n\n# Variogramme empirique : \nstart_time &lt;- Sys.time()\nemp_vario = GeoVariogram(data, coordx, coordy=coordy,numbins = 16,maxdist = 2000)\n\nend_time &lt;- Sys.time()\nend_time - start_time\n\nTime difference of 0.01098108 secs\n\nplot(emp_vario,main = \"Variogramme empirique Zinc - GeoModels\")"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#mod√®les-support√©s",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#mod√®les-support√©s",
    "title": "R-Julia-Geostats",
    "section": "Mod√®les support√©s",
    "text": "Mod√®les support√©s\nVoir documentation, fonction ‚ÄúGeoCovMatrix‚Äù\nCorrParam, et NuisParam permettent d‚Äôobtenir la listes des param√®tres requis pour les mod√®les.\n\nNuisParam('Gaussian')\n\n[1] \"mean\"   \"nugget\" \"sill\"  \n\nCorrParam(\"Exp\")\n\n[1] \"scale\"\n\nCorrParam('Matern')\n\n[1] \"scale\"  \"smooth\""
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#estimation-du-variogramme-th√©orique-1",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#estimation-du-variogramme-th√©orique-1",
    "title": "R-Julia-Geostats",
    "section": "Estimation du variogramme th√©orique",
    "text": "Estimation du variogramme th√©orique\nL‚Äôestimation n√©cessite de donner en entr√©e deux listes, fixed et start, correspondant aux param√®tres fix√©s et libres dans l‚Äôajustement.\nATTENTION : si on ne fixe rien, il ne faut pas une liste vide mais un NULL, ou alors ne pas renseigner l‚Äôargument (NULL est la valeur par d√©faut)\nL‚Äôalgorithme v√©rifiera automatiquement que tous les param√®tres n√©cessaires sont remplis. Il n‚Äôy a pas comme dans gstat de m√©thode qui rempli automatiquement des oublis, il faut v√©rifier avec les fonctions pr√©c√©dentes qu‚Äôon a bien tout initialis√©.\n\nfixed = NULL\n\nstart = list( mean = 0 , sill=0.5,smooth=0.7,scale = 300,nugget = 0.044)\n\nmodelemat = GeoFit(data, coordx=coordx, coordy=coordy, fixed = fixed, start=start, \n\ncorrmodel=\"Matern\",distance=\"Eucl\",maxdist = 2000)\n\nmodelemat\n\n\n##################################################################\nMaximum  Composite-Likelihood Fitting of Gaussian Random Fields\n\nSetting: Marginal Composite-Likelihood \n\nModel: Gaussian \n\nType of the likelihood objects: Pairwise \n\nCovariance model: Matern \n\nOptimizer: Nelder-Mead \n\nNumber of spatial coordinates: 155 \nNumber of dependent temporal realisations: 1 \nType of the random field: univariate \nNumber of estimated parameters: 5 \n\nType of convergence: Successful \nMaximum log-Composite-Likelihood value: -37443.52\n\nEstimated parameters:\n    mean    nugget     scale      sill    smooth  \n  5.8692    0.9994  266.5697    0.5482   68.5193  \n\n##################################################################\n\n# Vario fit : il faut mettre en entr√©e des valeurs de d√©part et des valeurs qu'on fixe pour les param√®tres\n\nfixed = list(nugget = 0.044) #fixe la valeur obtenue avec gstat\n\nstart = list( mean = 0 , sill=0.5,smooth=0.7,scale = 300)\n\nmodelemat2 = GeoFit(data, coordx=coordx, coordy=coordy, fixed = fixed, start=start, \n\ncorrmodel=\"Matern\",distance=\"Eucl\",maxdist = 2000)\n\nmodelemat2\n\n\n##################################################################\nMaximum  Composite-Likelihood Fitting of Gaussian Random Fields\n\nSetting: Marginal Composite-Likelihood \n\nModel: Gaussian \n\nType of the likelihood objects: Pairwise \n\nCovariance model: Matern \n\nOptimizer: Nelder-Mead \n\nNumber of spatial coordinates: 155 \nNumber of dependent temporal realisations: 1 \nType of the random field: univariate \nNumber of estimated parameters: 4 \n\nType of convergence: Successful \nMaximum log-Composite-Likelihood value: -37218.17\n\nEstimated parameters:\n    mean     scale      sill    smooth  \n  5.8673  114.4160    0.5495    1.5971  \n\n##################################################################\n\n\n\nfixed = NULL\n\nstart = list( mean = 0 , sill=0.5,scale = 300,nugget = 0.044)\n\nstart_time &lt;- Sys.time()\nmodelewav = GeoFit(data, coordx=coordx, coordy=coordy, fixed = fixed, start=start, \n\ncorrmodel=\"Wave\",distance=\"Eucl\",maxdist = 2000)\n\nend_time &lt;- Sys.time()\nend_time - start_time\n\nTime difference of 0.7888947 secs\n\nmodelewav\n\n\n##################################################################\nMaximum  Composite-Likelihood Fitting of Gaussian Random Fields\n\nSetting: Marginal Composite-Likelihood \n\nModel: Gaussian \n\nType of the likelihood objects: Pairwise \n\nCovariance model: Wave \n\nOptimizer: Nelder-Mead \n\nNumber of spatial coordinates: 155 \nNumber of dependent temporal realisations: 1 \nType of the random field: univariate \nNumber of estimated parameters: 4 \n\nType of convergence: Successful \nMaximum log-Composite-Likelihood value: -37191.31\n\nEstimated parameters:\n    mean    nugget     scale      sill  \n  5.8669    0.3839  200.4165    0.5509  \n\n##################################################################\n\n\nOn peut comparer les mod√®les que l‚Äôon vient de faire avec le variogramme empirique :\n\n# Comparaison avec l'empirique matern :\n\nGeoCovariogram(modelemat, distance=\"Eucl\",show.vario= TRUE,vario = emp_vario)\n\n\n\nGeoCovariogram(modelemat2, distance=\"Eucl\",show.vario= TRUE,vario = emp_vario)\n\n\n\n# Comparaison avec l'empirique Wave :\n\nGeoCovariogram(modelewav, distance=\"Eucl\",show.vario= TRUE,vario = emp_vario)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#krigeage-1",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#krigeage-1",
    "title": "R-Julia-Geostats",
    "section": "Krigeage",
    "text": "Krigeage\n\nlocskrig = data.frame (x =meuse.grid$x,y= meuse.grid$y)\n\nstart_time &lt;- Sys.time()\nkrig_geomodels = GeoKrig(loc= locskrig,coordx=coordx, coordy=coordy,corrmodel = 'Wave',param = c(modelemat$fixed,modelewav$param),mse =TRUE,data=data)\n\nend_time &lt;- Sys.time()\nend_time - start_time\n\nTime difference of 0.8939211 secs\n\ncoords  = cbind(coordx,coordy)\n\nKres_pred_geo = data.frame(x=meuse.grid$x,y=meuse.grid$y,pred=krig_geomodels$pred)\n\nkrig_res_geo&lt;- terra::rast(Kres_pred_geo, type=\"xyz\", crs=\"EPSG:2154\")\n\nKres_var_geo = data.frame(x=meuse.grid$x,y=meuse.grid$y,pred=krig_geomodels$mse)\n\nkrig_var_geo&lt;- terra::rast(Kres_var_geo, type=\"xyz\", crs=\"EPSG:2154\")\n\nplot((krig_res_geo), main = 'Krigeage de log(zinc) - GeoModels')\n\n\n\nplot(krig_var_geo,main = 'Erreur de krigeage pour log(zinc) - GeoModels')"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#biblioth√®ques-julia",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#biblioth√®ques-julia",
    "title": "R-Julia-Geostats",
    "section": "Biblioth√®ques Julia",
    "text": "Biblioth√®ques Julia\n\n# Import package\nusing GeoDataFrames, Distributed, StatsAPI, Plots, DelimitedFiles, DataFrames, CSV, GeoStats, Rasters,  Shapefile,GeoTables, CairoMakie; const GDF=GeoDataFrames; import WGLMakie as Mke"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#importer-les-donn√©es",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#importer-les-donn√©es",
    "title": "R-Julia-Geostats",
    "section": "Importer les donn√©es",
    "text": "Importer les donn√©es\n\n# Get the current working directory\ncurrent_directory = pwd()\n\n#import data\nmeuse = CSV.read(joinpath(current_directory,\"meuse.txt\"),DataFrame;delim=\",\" )\nmeuse_grid = CSV.read(joinpath(current_directory, \"meuse.grid.txt\"),DataFrame; delim=\",\")\nmeuse_geom = georef(CSV.File(joinpath(current_directory,\"meuse.txt\")),(:x,:y,:cadmium))\n\n#describe data\ndescribe(meuse)\ndescribe(meuse_grid)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#transformation-en-donn√©es-spatiale",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#transformation-en-donn√©es-spatiale",
    "title": "R-Julia-Geostats",
    "section": "Transformation en donn√©es spatiale",
    "text": "Transformation en donn√©es spatiale\n\n#add log zinc to the data\nlogmeuse = log.(meuse.zinc)\nmeuse.logzinc = logmeuse\n\n#create coord of data meuse\ncoord = [(x, y) for (x, y) in zip(meuse.x, meuse.y)]\n#create spatial object of meuse\nmeuselog = georef(meuse[:,[\"x\",\"y\",\"logzinc\"]],coord)\n\n# list of properties with coordinates\nprops = (logzinc=meuse.logzinc,)\nùíü = georef(props, coord)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#variogramme",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#variogramme",
    "title": "R-Julia-Geostats",
    "section": "Variogramme",
    "text": "Variogramme\nLe fit pour tester les diff√©rents variogramme va nous donner le SineHoleVariogram avec tous les param√®tres optimis√©. On d√©cide √† la base d‚Äôutiliser ce dernier mais il s‚Äôav√®re qu‚Äôil ne donne pas de bon r√©sultat pour le Krigeage. On utilisera donc un variogramme de Mat√©rn. Si vous voulez observer ce dernier dans le krigeage il suffira de mettre dans la fonction kriging, le variogramme d√©sir√©.\n\n# empirical variogram\n\n@time empvario = EmpiricalVariogram(meuselog, :logzinc, maxlag = 2000.)\n\n## plot of empirical variogram\n# Mke.plot(empvario) plot interactive\n# CairoMakie.plot(empvario) #plot sans interaction\n## plot theorical variogram\n# CairoMakie.plot(MaternVariogram(range=691, nugget=0.04))\n# CairoMakie.plot(SineHoleVariogram(range=691, nugget=0.25))\n\n#fit theorical and empirical variogramand \n@time fitvario = fit(Variogram, empvario)\n\n# CairoMakie.plot(empvario)\n# CairoMakie.plot!(fitvario, maxlag = 2000.)\n# CairoMakie.current_figure()"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#cr√©ation-de-la-grille",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#cr√©ation-de-la-grille",
    "title": "R-Julia-Geostats",
    "section": "Cr√©ation de la grille",
    "text": "Cr√©ation de la grille\n\n# grid creation\n# Convert the x and y coordinates to numeric arrays\nx_coords = Float64.(meuse.x)\ny_coords = Float64.(meuse.y)# Create the Cartesian grid dimensions, origin, and spacing\ndims = (100, 100)  # Number of grid points in x and y directions\norigin = (minimum(x_coords), minimum(y_coords)) # Lower left corner of the grid\nspacing = ((maximum(x_coords) - minimum(x_coords)) / (dims[1] - 1),\n           (maximum(y_coords) - minimum(y_coords)) / (dims[2] - 1)) \n # Cell spacing in x and y directions# Create the CartesianGrid\nùí¢ = CartesianGrid(dims, origin, spacing)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#krigeage-2",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#krigeage-2",
    "title": "R-Julia-Geostats",
    "section": "Krigeage",
    "text": "Krigeage\n\nùí´ = EstimationProblem(ùíü, ùí¢, :logzinc)\n\n@time ùíÆ = Kriging(:logzinc =&gt; (variogram=MaternVariogram(nugget = 0.21,sill = 0.59,range=706.78),))\n\n# perform estimation\n@time Œ© = solve(ùí´, ùíÆ)\n\n# CairoMakie.plot(Œ©.geometry, color = Œ©.logzinc_variance)"
  },
  {
    "objectID": "R-Julia-Geostats-v-fix-no-CairoMakie.html#affichage-du-krigeage",
    "href": "R-Julia-Geostats-v-fix-no-CairoMakie.html#affichage-du-krigeage",
    "title": "R-Julia-Geostats",
    "section": "Affichage du Krigeage",
    "text": "Affichage du Krigeage\n\n#Export Kriging\nGeoTables.save(joinpath(current_directory,\"data_geostats_julia/Kriging2.shp\"), Œ©,force=true )\n\n#read kriging\nshape =  Shapefile.Handle(joinpath(current_directory,\"data_geostats_julia/Kriging2.shp\")).shapes\n# read grid \ngrid_shp =  Shapefile.Handle(joinpath(current_directory,\"data_geostats_julia/boundary1.shp\")).shapes\n\n# Define a reducer function (e.g., to sum values within each cell)\nreducer(cell_values) = sum(cell_values)\n\nrasterized_krig = rasterize(shape, fill=Œ©.logzinc, reducer = reducer, size=(100, 100))\nPlots.plot(rasterized_krig)\n\nBurning each geometry to a BitArray slice...   0%|                                                  |  ETA: 0:48:28\n\nBurning each geometry to a BitArray slice... 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00\n\nReducing...   4%|‚ñà‚ñà                                                |  ETA: 0:00:02\n\nReducing...  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          |  ETA: 0:00:00\n\nReducing...  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     |  ETA: 0:00:00\n\nReducing... 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00\n\n\n#Crop \nmasked = mask(rasterized_krig,with=grid_shp)\nPlots.plot(masked, title = \"Krigeage logzinc\")"
  },
  {
    "objectID": "Utilisation_de_git.html",
    "href": "Utilisation_de_git.html",
    "title": "FinistR : Utilisation de git",
    "section": "",
    "text": "Introduction\nL‚Äôobjectif de cet atelier √©tait de voir comment int√©ragir avec le d√©p√¥t github finistR2023 afin de pouvoir contribuer √† la r√©alisation de la page web. Nous avons pour cela cr√©e une branche d√©di√©e √† cet atelier sur laquelle nous avons interagi avec deux ordinateurs diff√©rents. Ce compte rendu consitste en la restitution chronologique des commandes ex√©cut√©es par ces deux ordinateurs, et d√©taille les probl√®mes rencontr√©s en cours de route.\n\n\nChronologie des commandes\nOrdinateur 1\nOn commence par cloner le d√©p√¥t github StateOfTheR/finistR2023 :\ngit clone git@github.com:StateOfTheR/finistR2023.git\nOn cr√©e une nouvelle branche pour cet atelier git :\ngit branch Utilisation_de_git\nOn se d√©place sur cette branche :\ngit checkout Utilisation_de_git\nOn cr√©e un fichier qmd dans un nouveau dossier d√©di√© √† cet atelier :\n\nmkdir Utilisation_de_git\ncd Utilisation_de_git\nnvim Utilisation_de_git.qmd\n\nOn commit les modification et on les push dans le d√©p√¥t.\n\ngit add .\ngit commit -m \"cr√©ation d'une branche pour l'atelier sur git\"\ngit push --set-upstream origin Utilisation_de_git \n\nLa partie --set-upstream origin Utilisation_de_git de la troisi√®me commande n‚Äôest utile que parce que la branche n‚Äôexiste pas encore dans le d√©p√¥t. Les prochains push se feront simplement avec la commande git push.\nA ce stade, le fichier Utilisation_de_git.qmd est comme suit :\n ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-\nOrdinateur 2\nAvec le deuxi√®me ordinateur, nous avons clon√© le d√©p√¥t, nous nous sommes plac√©s sur la branche cr√©e pr√©c√©demment, nous avons ajout√© du texte au fichier qmd sans modifier le texte d√©j√† pr√©sent, puis nous avons push√© ces modifications sur le d√©p√¥t. Le fichier Utilisation_de_git.qmd √©tait comme suit au moment du push :\n ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-\nOrdinateur 1\nEn parall√®le de cette op√©ration, nous avons aussi fait un ajout de texte avec le premier ordinateur :\n\nApr√®s avoir commit√© cette ajout de texte, nous avons fait un git pull et nous avons eu un conflit auquel nous ne nous attendions pas √©tant donn√© la nature des diff√©rences entre le fichier sur le d√©p√¥t et le fichier en local. Le message d‚Äôerreur √©tait le suivant :\nYou have divergent branches and need to specify how to reconcile them. You can do so by running one of the following commands sometime before your next pull:\n\ngit config pull.rebase false # merge (the default strategy)\ngit config pull.rebase true # rebase\ngit config pull.ff only # fast-forward only\n\nYou can replace ‚Äúgit config‚Äù with ‚Äúgit config ‚Äìglobal‚Äù to set a default preference for all repositories. You can also pass ‚Äìrebase, ‚Äìno-rebase, or ‚Äìff-only on the command line to override the configured default per invocation.\nNous pensions pouvoir r√©soudre ce conflit en fast forward, nous avons donc configur√© le pull de cette fa√ßon :\ngit config pull.ff only\nPuis nous avons fait un git pull, mais cela n‚Äôa pas fonctionn√©.\nNous avons alors utilis√© rebase :\ngit pull --rebase\nPuis nous avons ouvert le fichier qmd pour g√©rer les conflits en supprimant les ‚Äú=‚Äù et les ‚Äú&gt;‚Äù, apr√®s quoi nous avons commit√© ces modifications. Nous avons alors essay√© de faire un push et nous avons eu le message d‚Äôerreur suivant :\nfatal: You are not currently on a branch. To push the history leading to the current (detached HEAD) state now, use \n\ngit push origin HEAD:&lt;name-of-the-remote-branch&gt; \n\nEffectivement, la commande git branch nous donnait le r√©sultat suivant :\n*(no branch, rebasing Utilisation_de_git) Utilisation_de_git main\nNous avons r√©solu le probl√®me avec\ngit rebase --continue\nEt le push a ensuite bien fonctionn√©. ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-\nA ce stade, nous nous sommes dits que nous avions mal g√©r√© le probl√®me et que nous aurions d√ª utiliser la strat√©gie par d√©faut propos√©e dans le premier message d‚Äôerreur. Dans la suite, nous avons donc reconfigur√© le pull (git config pull.rebase false) et nous avons recommenc√© ces ajouts de textes en parall√®le avec les deux ordinateurs pour voir si c‚Äô√©tait la bonne solution. Mais malgr√© cette reconfiguration du pull, git tentait toujours de le faire en fast forward. Cela venait de la commande git config pull.ff only ex√©cut√©e pr√©c√©demment et nous nous en sommes rendu compte en utilisant la commande git config -l qui permet de voir la configuration de certaines commandes git. Nous avons donc reconfigur√© pull.ff :\ngit config pull.ff false\nEt le merge des deux fichiers a bien fonctionn√©.\nAu cours de ce travail, nous avons utilis√© l‚Äôapplication gitk (install√©e avec sudo apt install gitk) qui permet de visualiser l‚Äôarbre des commits d‚Äôun r√©pertoire git. Cette application s‚Äôutilise simplement en ex√©cutant la commande gitk depuis le r√©pertoire git d√©sir√©. Des options sont disponible pour customiser la vue et en particulier pour filtrer certaines branches de l‚Äôarbre (aller dans View &gt; New view). La figure ci-dessous repr√©sente l‚Äôarbre de notre branche √† la fin des diff√©rents tests que l‚Äôon a effectu√©s.\n\nPar ailleurs, un point important √† mentionner est le recours √† la commande history de bash pour acc√©der √† l‚Äôhistorique de ce dernier (aussi accessible dans le fichier ~/.bash_history (pour les linuxiens)). En effet, cela nous a permis de retracer ce qui s‚Äô√©tait pass√© et de mieux comprendre certaines choses. Nous avons cependant regr√©t√© que les log des commandes git ne soient pas automatiquement sauvegard√©s. Cela nous aurait beaucoup aid√©.\n\n\nCommandes utiles\nCommandes pr√©c√©d√©es de git\n\nclone : clone un d√©p√¥t distant (de gitHub par exemple) dans un nouveau r√©pertoire local.\nbranch\n\nbranch : affiche les noms des branches sur lesquelles on a travaill√©, celle avec une √©toile correspond √† celle sur laquelle on est.\nbranch -a : affiche les noms de toutes les branches.\nbranch new_branch_name : cr√©er une nouvelle branche.\n\ncheckout\n\ncheckout branch_name : se d√©placer sur une branche.\ncheckout -b new_branch_name : cr√©er une nouvelle branche et se d√©placer sur cette nouvelle branche.\n\nstatus : affiche des informations sur la situation de notre git (la branche sur laquelle on est, les commits en cours,‚Ä¶)\nadd : Instruction √† r√©aliser avant un commit, pour indiquer √† git quels fichiers on veut suivre. Si on ne pr√©cise pas les noms des fichiers, par d√©faut tous les fichiers du r√©pertoire sont ajout√©s au suivi (sauf ceux du .gitignore).\ncommit -m commit_message : ‚Äúcommit‚Äù les changements r√©alis√©s dans les fichiers suivis (ceux qu‚Äôon a indiqu√© avec l‚Äôinstruction add). On conseille de mettre un message explicite, c‚Äôest utile lorsqu‚Äôon souhaite revenir √† une version pr√©cedente.\npush : envoi des modifications des fichiers commit√©s sur le d√©pot distant.\npull par d√©faut √©quivalent √† git fetch suivi de git merge : t√©l√©charge la branche distante (fetch) et la merge √† la branche locale\n\npull : incorpore les modifications du d√©pot distant dans le r√©pertoire local.\n\npull ‚Äìrebase : pull en faisant un rebase\npull ‚Äìmerge : pull en faisant un merge\n\nconfig config permet de customiser la configuration des dossiers git, il y a une configuration locale (le dossier git courrant) et une configuration globale (valable pour tous les dossiers git)\n\nconfig -l : affiche les configurations de notre git pour le dossier courrant.\nconfig pull.rebase true : indique a git de faire un rebase par d√©faut au moment du pull, pour le dossier git courrant.\nconfig ‚Äìglobal pull.rebase true : m√™me chose mais pour tous les dossiers gits.\n\nrebase ‚Äìcontinue : continue un rebase avort√© par un √©chec de merge, apr√®s l‚Äô√©dition des fichiers conflictuels\nlog\n\nlog : affiche l‚Äôhistorique des commits de la branche sur laquelle on se trouve.\nlog ‚Äìoneline : idem mais avec un affichage plus concis, sur une seule ligne.\n\n\n\n\nPerspectives\nAu cours de cet atelier, nous avons pu voir l‚Äôint√©r√™t de git pour un projet collaboratif comme celui de la r√©alisation d‚Äôun site web. N√©anmoins, n‚Äô√©tant pour la plupart d‚Äôentre nous que des utilisateurs novices de git dont l‚Äôutilisation se r√©sume parfois √† celle d‚Äôun simple drive, nous nous sommes demand√©s quels b√©n√©fices nous pouvions en tirer pour une utilisation solitaire. En particulier pour en finir avec les r√©pertoires remplis de fichiers comme analyse.ipynb, analyse_V2.ipynb, ‚Ä¶, analyse_Vn.ipynb, dont l‚Äôun des int√©r√™ts est que cela permet de travailler simultan√©ment sur plusieurs fichiers √† la fois.\nUne solution bas√©e sur la cr√©ation de diff√©rentes branches et des commandes git stash et git popa √©merg√© au moment de la restitution et sera test√©e prochainement.\n\n\nLiens utiles\n\nlearngitbranching\n\n\n\nRemerciements\nUn grand merci √† Marie-Pierre sans qui cet atelier aurait p√ª durer tr√®s longtemps !"
  },
  {
    "objectID": "torch_and_rcpp.html",
    "href": "torch_and_rcpp.html",
    "title": "Torch & Rcpp",
    "section": "",
    "text": "library(Rcpp)\nlibrary(RcppArmadillo)\nlibrary(torch)\nlibrary(tictoc)\nlibrary(bench) # comparaison des vitesses\nlibrary(ggplot2)\nlibrary(ggbeeswarm)"
  },
  {
    "objectID": "torch_and_rcpp.html#torch-on-r",
    "href": "torch_and_rcpp.html#torch-on-r",
    "title": "Torch & Rcpp",
    "section": "Torch on R",
    "text": "Torch on R\nLa librairie {torch} de R permet la manipulation de tenseur en R. Elle permet notamment de faire la diff√©renciation automatique, c-a-d d‚Äô√©valuer num√©riquement le gradient d‚Äôune fonction et d‚Äôeffectuer des descentes de gradient.\nPr√©sentation finistR2022\nTorch and Automatic differentiation"
  },
  {
    "objectID": "torch_and_rcpp.html#rcpp",
    "href": "torch_and_rcpp.html#rcpp",
    "title": "Torch & Rcpp",
    "section": "Rcpp",
    "text": "Rcpp\nL‚Äôutilisation de {Rcpp} permet d‚Äôexporter des fonctions C++ en R. Les fonctions seront alors directement utilisables dans un script et avec des arguments R. Ainsi on peut tirer partie de la compilation d‚Äôun code C++, et acc√©l√©rer de nombreux calculs alg√©briques.\nPour le calcul alg√©brique il est utile d‚Äôint√©grer le package {RcppArmadillo} qui donne acc√®s √† la librairie {Armadillo} de C++ lorsque l‚Äôon appel une fonction {Rcpp} dans R.\nPr√©sentation finistR2018\n\nExample\nDans cet exemple nous allons calculer la perte d‚Äôune fonction logistique en R et en C++. Puis comparer les r√©sultats avec le package {bench} de R.\n\nCoder la fonction en C++\n\n// [[Rcpp::depends(RcppArmadillo)]]\n#include &lt;RcppArmadillo.h&gt;\n\n// Logistic loss\n// [[Rcpp::export]]\n// const : pas de changement de valeur dans la fonction\n// arma:: : se sont les classes de Armadillo\n// using namespace arma to erase all arma::\n// & :  appel sans copie donc plus rapide\ndouble loss_cpp( const arma::vec theta, const arma::vec& y, const arma::mat& x ) {\n  arma::vec odds(x.n_rows);\n  odds = x * theta;\n  double log_lik;\n  log_lik = arma::dot(y, odds) - arma::sum(arma::log(1 + arma::exp(odds)));\n  return(-log_lik);\n}\n\n\n\nAppel et compilation du script depuis R avec la fonction sourceCpp() de {Rcpp}\n\nsourceCpp(file = \"logisticloss.cpp\")\n\n\n\nFonction loss en R\n\nloss_R &lt;- function(theta, y, x) {\n  odds &lt;- x %*% theta\n  log_lik &lt;- sum(y * odds - log(1 + exp(odds)))\n  return(-as.numeric(log_lik))\n}\n\n\n\nR√©sultats\nOn remarque que les r√©sultats sont identiques pour la fonction {Rcpp} et la fonction en R.\n\ntheta = c(0.5, 0.1)\ny = 1.0\nx = matrix(c(0.1, 0.2), 1, 2)\n\n\nloss_cpp(theta, y, x)\n\n[1] 0.6587596\n\n\n\nloss_R(theta, y, x)\n\n[1] 0.6587596\n\n\nDans l‚Äôoptique de comparer les performances de ces deux fonctions on utilise la fonction mark() du package {bench}.\n\nn_covar &lt;- 300\nsize &lt;- 1000\n\ntheta &lt;- rnorm(n_covar)\ny &lt;- as.numeric(rbinom(size, 1, 0.3))\nx &lt;- matrix(rnorm(size * n_covar), size, n_covar)\n\n\ncomp_tbl &lt;- bench::mark(\n  loss_R(theta = theta, y = y, x = x),\n  loss_cpp(theta = theta, y = y, x = x),\n  iterations = 1000\n)\n\nautoplot(comp_tbl)\n\nLoading required namespace: tidyr\n\n\n\n\n\nComme on peut le voir sur le graphique plus haut la fonction loss_cpp() est environ 2 fois plus efficace que la fonction loss_R().\n\n\nAttention aux librairies BLAS et LAPACK\nLa librairie BLAS de OpenBlas pr√©sent√©e lors de cette m√™me session ne fonctionne pas correctement avec {Rcpp}. On observe une baisse de fonctionnement tr√®s quantitative (facteur 100). La librairie BLAS de Intel MKL reste quant √† elle plus efficace."
  },
  {
    "objectID": "torch_and_rcpp.html#r√©f√©rences",
    "href": "torch_and_rcpp.html#r√©f√©rences",
    "title": "Torch & Rcpp",
    "section": "R√©f√©rences",
    "text": "R√©f√©rences\n\nCours state of the R (2023)\nfinistR2022 - Torch Auto Diff"
  },
  {
    "objectID": "torch_test-brulee.html",
    "href": "torch_test-brulee.html",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "",
    "text": "L‚Äôid√©e ici est d‚Äôexplorer la r√©gression logistique en utilisant {torch} √† l‚Äôaide du package {brulee}.\n\nlibrary(torch)\nlibrary(tidymodels)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 1.1.0 ‚îÄ‚îÄ\n\n\n‚úî broom        1.0.5     ‚úî recipes      1.0.7\n‚úî dials        1.2.0     ‚úî rsample      1.1.1\n‚úî dplyr        1.1.2     ‚úî tibble       3.2.1\n‚úî ggplot2      3.4.2     ‚úî tidyr        1.3.0\n‚úî infer        1.0.4     ‚úî tune         1.1.1\n‚úî modeldata    1.2.0     ‚úî workflows    1.1.3\n‚úî parsnip      1.1.1     ‚úî workflowsets 1.0.1\n‚úî purrr        1.0.2     ‚úî yardstick    1.2.0\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\n‚úñ purrr::discard() masks scales::discard()\n‚úñ dplyr::filter()  masks stats::filter()\n‚úñ dplyr::lag()     masks stats::lag()\n‚úñ recipes::step()  masks stats::step()\n‚Ä¢ Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(brulee)"
  },
  {
    "objectID": "torch_test-brulee.html#introduction",
    "href": "torch_test-brulee.html#introduction",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "",
    "text": "L‚Äôid√©e ici est d‚Äôexplorer la r√©gression logistique en utilisant {torch} √† l‚Äôaide du package {brulee}.\n\nlibrary(torch)\nlibrary(tidymodels)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 1.1.0 ‚îÄ‚îÄ\n\n\n‚úî broom        1.0.5     ‚úî recipes      1.0.7\n‚úî dials        1.2.0     ‚úî rsample      1.1.1\n‚úî dplyr        1.1.2     ‚úî tibble       3.2.1\n‚úî ggplot2      3.4.2     ‚úî tidyr        1.3.0\n‚úî infer        1.0.4     ‚úî tune         1.1.1\n‚úî modeldata    1.2.0     ‚úî workflows    1.1.3\n‚úî parsnip      1.1.1     ‚úî workflowsets 1.0.1\n‚úî purrr        1.0.2     ‚úî yardstick    1.2.0\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\n‚úñ purrr::discard() masks scales::discard()\n‚úñ dplyr::filter()  masks stats::filter()\n‚úñ dplyr::lag()     masks stats::lag()\n‚úñ recipes::step()  masks stats::step()\n‚Ä¢ Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(brulee)"
  },
  {
    "objectID": "torch_test-brulee.html#exemple",
    "href": "torch_test-brulee.html#exemple",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "Exemple",
    "text": "Exemple\nOn reprend l‚Äôexemple d√©taill√© l‚Äôan dernier pour la r√©gression logistique, disponible √† la page https://stateofther.github.io/finistR2022/autodiff.html.\n\nset.seed(45)\nn &lt;- 100\np &lt;- 3\nX &lt;- matrix(rnorm(n = n*p), ncol = p, nrow = n)\ntheta &lt;- rnorm(3) %&gt;% round(digits = 2)\nprobs &lt;- (X %*% theta) %&gt;% as.vector()\nY &lt;- purrr::rbernoulli(n = n, p = probs) + 0.\n\nWarning: `rbernoulli()` was deprecated in purrr 1.0.0.\n\nx &lt;- torch_tensor(X)\ny &lt;- torch_tensor(Y)\n\nlogistic_loss &lt;- function(theta, x, y) {\n  if (!is(theta, \"torch_tensor\")) {\n    stop(\"theta must be a torch tensor\")\n  }\n  odds &lt;- torch_matmul(x, theta)\n  log_lik &lt;- torch_dot(y, odds) - torch_sum(torch_log(1 + torch_exp(odds)))\n  return(-log_lik)\n}\nlogistic_loss(theta = torch_tensor(theta), x = x, y = y)\n\ntorch_tensor\n50.4573\n[ CPUFloatType{} ]\n\neval_loss &lt;- function(theta, verbose = TRUE) {\n  loss &lt;- logistic_loss(theta, x, y)\n  if (verbose) {\n    cat(paste(theta |&gt; as.numeric(), collapse=\", \"), \": \", as.numeric(loss), \"\\n\")\n  }\n  return(loss)\n}\neval_loss(torch_tensor(theta), verbose = FALSE)\n\ntorch_tensor\n50.4573\n[ CPUFloatType{} ]\n\ntheta_current &lt;- torch_tensor(rep(0, length(theta)), requires_grad = TRUE)\ntheta_optimizer &lt;- optim_rprop(theta_current)\nloss &lt;- eval_loss(theta_current, verbose = FALSE)\nloss$backward()\ntheta_optimizer$step()\n\nNULL\n\nnum_iterations &lt;- 100\nloss_vector &lt;- vector(\"numeric\", length = num_iterations)\nfor (i in 1:num_iterations) {\n  theta_optimizer$zero_grad()\n  loss &lt;- eval_loss(theta_current, verbose = FALSE)\n  loss$backward()\n  theta_optimizer$step()\n  loss_vector[i] &lt;- loss %&gt;% as.numeric()\n}\ndplyr::tibble(\n  torch = theta_current |&gt; as.numeric(),\n  glm   = glm(Y ~ 0 + X, family = \"binomial\") |&gt; coefficients()\n)\n\n# A tibble: 3 √ó 2\n   torch    glm\n   &lt;dbl&gt;  &lt;dbl&gt;\n1  1.79   1.79 \n2 -1.04  -1.04 \n3 -0.973 -0.973"
  },
  {
    "objectID": "torch_test-brulee.html#tidymodels",
    "href": "torch_test-brulee.html#tidymodels",
    "title": "{torch} avec {tidymodels} et {brulee}",
    "section": "Tidymodels",
    "text": "Tidymodels\nIl est possible d‚Äôeffectuer une r√©gression logistique √† l‚Äôaide de plusieurs engine dans {tidymodels} :\n\nshow_engines(\"logistic_reg\")\n\n# A tibble: 7 √ó 2\n  engine    mode          \n  &lt;chr&gt;     &lt;chr&gt;         \n1 glm       classification\n2 glmnet    classification\n3 LiblineaR classification\n4 spark     classification\n5 keras     classification\n6 stan      classification\n7 brulee    classification\n\n\nOn v√©rifie qu‚Äôon retrouve bien les m√™mes coefficient en utilisant le package {glm} dans {tidymodels} pour effectuer notre r√©gression logistique :\n\nset.seed(20)\ndata_df &lt;- data.frame(Y = as.factor(Y), X = X)\nlogistic_reg(engine = \"glm\") %&gt;% \n  fit(Y ~ 0 + X.1 + X.2 + X.3, family = \"binomial\", data = data_df) %&gt;% \n  extract_fit_engine() %&gt;% # besoin d'extraire l'objet lm\n  coef()\n\n       X.1        X.2        X.3 \n 1.7914697 -1.0379660 -0.9728552 \n\n\nLe package {brulee} de l‚Äôunivers tidymodels propose diff√©rents mod√®les classiques (r√©seau de neurones, r√©gression logistique, r√©gression lin√©aire, r√©gression multinomiale) via l‚Äôinfrastructure torch. La liste des loss disponibles dans le package :\n\nls(pattern = \"loss$\", envir = asNamespace(\"torch\"))\n\n [1] \"nn_adaptive_log_softmax_with_loss\"    \n [2] \"nn_bce_loss\"                          \n [3] \"nn_bce_with_logits_loss\"              \n [4] \"nn_cosine_embedding_loss\"             \n [5] \"nn_cross_entropy_loss\"                \n [6] \"nn_ctc_loss\"                          \n [7] \"nn_hinge_embedding_loss\"              \n [8] \"nn_kl_div_loss\"                       \n [9] \"nn_l1_loss\"                           \n[10] \"nn_loss\"                              \n[11] \"nn_margin_ranking_loss\"               \n[12] \"nn_mse_loss\"                          \n[13] \"nn_multi_margin_loss\"                 \n[14] \"nn_multilabel_margin_loss\"            \n[15] \"nn_multilabel_soft_margin_loss\"       \n[16] \"nn_nll_loss\"                          \n[17] \"nn_poisson_nll_loss\"                  \n[18] \"nn_smooth_l1_loss\"                    \n[19] \"nn_soft_margin_loss\"                  \n[20] \"nn_triplet_margin_loss\"               \n[21] \"nn_triplet_margin_with_distance_loss\" \n[22] \"nn_weighted_loss\"                     \n[23] \"nnf_cosine_embedding_loss\"            \n[24] \"nnf_ctc_loss\"                         \n[25] \"nnf_hinge_embedding_loss\"             \n[26] \"nnf_l1_loss\"                          \n[27] \"nnf_margin_ranking_loss\"              \n[28] \"nnf_mse_loss\"                         \n[29] \"nnf_multi_margin_loss\"                \n[30] \"nnf_multilabel_margin_loss\"           \n[31] \"nnf_multilabel_soft_margin_loss\"      \n[32] \"nnf_nll_loss\"                         \n[33] \"nnf_poisson_nll_loss\"                 \n[34] \"nnf_smooth_l1_loss\"                   \n[35] \"nnf_soft_margin_loss\"                 \n[36] \"nnf_triplet_margin_loss\"              \n[37] \"nnf_triplet_margin_with_distance_loss\"\n[38] \"torch__ctc_loss\"                      \n[39] \"torch__cudnn_ctc_loss\"                \n[40] \"torch__use_cudnn_ctc_loss\"            \n[41] \"torch_cosine_embedding_loss\"          \n[42] \"torch_cross_entropy_loss\"             \n[43] \"torch_ctc_loss\"                       \n[44] \"torch_hinge_embedding_loss\"           \n[45] \"torch_huber_loss\"                     \n[46] \"torch_l1_loss\"                        \n[47] \"torch_margin_ranking_loss\"            \n[48] \"torch_mse_loss\"                       \n[49] \"torch_multi_margin_loss\"              \n[50] \"torch_multilabel_margin_loss\"         \n[51] \"torch_nll_loss\"                       \n[52] \"torch_poisson_nll_loss\"               \n[53] \"torch_smooth_l1_loss\"                 \n[54] \"torch_soft_margin_loss\"               \n[55] \"torch_triplet_margin_loss\"            \n\n\nOn va regarder ici comment faire la m√™me r√©gression logistique que pr√©c√©demment. Il est possible de sp√©cifier soit avec les donn√©es sous forme de data.frame soit en utilisant des matrices. Deux proc√©dures d‚Äôoptimisation sont disponibles : ‚ÄòLBFGS‚Äô et ‚ÄòSGD‚Äô.\nA noter qu‚Äôil n‚Äôest pas possible de sp√©cifier un mod√®le sans intercept, ni avec 0+ ni avec -1.\n\nreg_log_brulee2 &lt;- brulee_logistic_reg(x = as.matrix(X), y = as.factor(Y),\n                         epochs = num_iterations, optimizer = \"SGD\", validation = 0)\n\nreg_log_brulee1 &lt;- brulee_logistic_reg(Y ~ X.1 + X.2 + X.3, data = data_df,\n                         epochs = num_iterations, optimizer = \"SGD\", validation = 0)\n\nEn th√©orie il est possible r√©cup√©rer les coefficients du mod√®le ajust√© avec la m√©thode coef en sp√©cifiant l‚Äôepoch d√©sir√©e. Si epoch = NULL la meilleure epoch est choisie.\n\nreg_log_brulee2 %&gt;% coef()\n\n\nreg_log_brulee2$estimates[[100]]\n\n$fc1.weight\n          [,1]       [,2]      [,3]\n[1,] -1.096883  0.5906312  1.178145\n[2,]  1.788497 -0.9432783 -1.099946\n\n$fc1.bias\n[1]  1.451596 -1.311797"
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html",
    "href": "how_to_maintain_a_dockerfile.html",
    "title": "Gestion d‚Äôun Dockerfile en projet collaboratif",
    "section": "",
    "text": "Lors d‚Äôun √©v√®nement comme finistR nous travaillons tous, sur des interfaces, des syst√®mes et des langages diff√©rents. Lors de finistR2023 par exemple, nous avons d√ª utiliser dans un m√™me conteneur docker les langages R, Python et Julia et compiler cela via quarto. Construire un docker est quasiment aussi simple en principe que de suivre la recette d‚Äôune salade. Mais lorsque les probl√®mes arrivent et que la mayonnaise ne marche plus, il ne vous reste plus qu‚Äô√† manger votre clavier‚Ä¶\nSur cette page vous trouverez premi√®rement un petit rappel sur ce qu‚Äôest un Dockerfile et le fonctionnement g√©n√©ral de docker. Puis deuxi√®mement des indications plus particuli√®res au conteneur de finistR2023 c‚Äôest √† dire un docker R, Python, Julia et quarto"
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#i---un-dockerfile",
    "href": "how_to_maintain_a_dockerfile.html#i---un-dockerfile",
    "title": "Gestion d‚Äôun Dockerfile en projet collaboratif",
    "section": "I - Un Dockerfile ?",
    "text": "I - Un Dockerfile ?\nDocker est une technologie permettant de cr√©er et utiliser de mani√®re efficace des conteneurs logiciels. Ces conteneurs logiciel sont en fait des environnements de travail sp√©cialisables, versionn√©s et facilement partageable. Docker permet donc de partager : des environnements de calculs pour des travaux en √©quipe, des applications (par exemple {shiny}), mais aussi permet l‚Äôint√©gration continue de site web et autres.\nVoici un Dockerfile utile pour ce projet:\n\n## Source Dockerfile\nFROM rocker/geospatial:4\n\n### JULIA\n\n## Copy Julia's tar.gz and install it\n## using 1.8.3 version because it does work with quarto on my computer\nRUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.3-linux-x86_64.tar.gz && \\\n    tar zxvf julia-1.8.3-linux-x86_64.tar.gz && \\\n    ## Connect to Julia's directory link with real jula's bin\n    cp -r julia-1.8.3 /opt/ && \\\n    ln -s /opt/julia-1.8.3/bin/julia /usr/local/bin/julia\n\n## Install Julias package (IJulia &lt;-- to connect with jupyter)\n## Installing from julia\nRUN julia -e 'import Pkg; Pkg.add(\"GeoDataFrames\"); Pkg.add(\"Distributed\"); Pkg.add(\"StatsAPI\"); Pkg.add(\"Plots\"); Pkg.add(\"DelimitedFiles\"); Pkg.add(\"DataFrames\"); Pkg.add(\"CSV\"); Pkg.add(\"GeoStats\"); Pkg.add(\"Rasters\"); Pkg.add(\"Shapefile\"); Pkg.add(\"GeoTables\"); Pkg.add(\"CairoMakie\"); Pkg.add(\"WGLMakie\"); Pkg.add(\"IJulia\")'\n\n## non Interactive terminal for this docker for the site\nRUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\\n    && apt-get install -y pandoc \\\n    pandoc-citeproc\n\n### R packages\n\n## Defining web acces for CRAN\nENV R_CRAN_WEB=\"https://cran.rstudio.com/\"\nRUN R -e \"install.packages('INLA',repos=c(getOption('repos'),INLA='https://inla.r-inla-download.org/R/stable'), dep=TRUE)\"\nRUN R -e \"install.packages(c('dyplr','ggplot2','remotes','microbenchmark','purrr','BiocManager','httr','cowplot','torch','PLNmodels','torchvision','reticulate','inlabru', 'lme4', 'ggpolypath', 'RColorBrewer', 'geoR','tidymodels', 'brulee', 'reprex','poissonreg','ggbeeswarm', 'tictoc', 'bench', 'circlize', 'JuliaCall', 'GeoModels','sp','terra','gstat','sf'))\"\nRUN R -e \"BiocManager::install('BiocPkgTools')\"\nRUN R -e \"torch::install_torch(type = 'cpu')\"\nRUN R -e \"JuliaCall::install_julia()\"\n\n### Ubuntu libraries (for python ?)\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n  jags \\\n  mercurial gdal-bin libgdal-dev gsl-bin libgsl-dev \\\n  libc6-i386\n\n### Jupyter Python torch jax etc\n## Downloading Python\nRUN apt-get install -y --no-install-recommends unzip python3-pip dvipng pandoc wget git make python3-venv && \\\n    pip3 install jupyter jupyter-cache flatlatex matplotlib && \\\n    apt-get --purge -y remove texlive.\\*-doc$ && \\\n    apt-get clean\n\nRUN pip3 install jax jaxlib torch numpy matplotlib pandas scikit-learn torchvision torchaudio pyplnmodels optax\n\nMalgr√© ce format peu tentant, l‚Äô√©criture d‚Äôun Dockerfile est facile tant que l‚Äôon ma√Ætrise bien les outils que le docker doit contenir.\n\na) FROM Le r√©cypient de la reccette\nPour construire un conteneur docker on utilise en g√©n√©ral au d√©part‚Ä¶ un conteneur docker. De pr√©f√©rence il faut trouver un conteneur plus ou moins adapt√© √† ce que l‚Äôon veux. Ici nous utilisons rocker/geospatial:4, les conteneurs rocker contiennent R avec ici une adaptation particuli√®re au geospatial.\n\n\nb) RUN Les ingr√©dients de la recette\nAvec RUN il est possible d‚Äôeffectuer des commandes en bash pour installer ce dont on a besoin dans le Docker. Pour rappel, ici il faut que nous puissions compiler un site web de mani√®re automatique, et aussi compiler des quarto (Julia, R et Python) √† l‚Äôorigine des pages web. Pour chacune de ces √©tapes il faut v√©rifier l‚Äôinstallation du langage, installer les d√©pendances n√©cessaires au code. Et enfin s‚Äôassurer de la compatibilit√© entre les outils.\n\n\nc) Exemple - Instalation de Julia pour quarto\nIci R est d√©j√† install√© via rocker mais pas Julia. Le paragraphe suivant consiste √† l‚Äôinstallation compl√®te de Julia-1.8.3 dans un syst√®me type ubuntu.\n\nRUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.3-linux-x86_64.tar.gz && \\\n    tar zxvf julia-1.8.3-linux-x86_64.tar.gz && \\\n    ## Connect to Julia's directory link with real jula's bin\n    cp -r julia-1.8.3 /opt/ && \\\n    ln -s /opt/julia-1.8.3/bin/julia /usr/local/bin/julia\n\nLe symbole && \\ permet si la ligne √† gauche est un succ√®s de lancer la ligne suivante et le tout dans un seul RUN. En g√©n√©ral il vaux mieux avoir peu de longue ligne de code que beaucoup de ligne faisant un appel syst√©matique √† RUN.\n\nwget t√©l√©charge Julia\ntar d√©compresse le fichier t√©l√©charg√©\ncp copie Julia dans le dossier des programmes\nln cr√©√© un lien symbolique qui permet de lancer des script avec la commande $ julia depuis le terminal.\n\nCependant pour pouvoir lancer Julia depuis quarto cela ne suffit pas. Premi√®rement la version actuelle du langage ne communique pas correctement avec quarto alors que la version Julia-1.8.3 semble bien fonctionner. Deuxi√®mement il est n√©cessaire de cr√©er un kernel IJulia pour connecter Julia √† jupyter. C‚Äôest jupyter qui vas ensuite communiquer avec quarto. Pour faire cela, il faut installer le package {IJulia}.\n\nRUN julia -e 'import Pkg; Pkg.add(\"IJulia\")'\n\nOn prendra soins d‚Äôimporter les autres packages dont nos quarto d√©pendent\n\nRUN julia -e 'import Pkg; Pkg.add(\"DataFrames\"); Pkg.add(\"GeoDataFrames\"); Pkg.add(\"IJulia\")'\n\nPar s√©curit√© nous avons aussi choisi de faire la commande R suivante qui installe une petite d√©pendance de Julia dans R.\n\nRUN R -e \"JuliaCall::install_julia()\""
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#ii---construire-mon-dockerfile",
    "href": "how_to_maintain_a_dockerfile.html#ii---construire-mon-dockerfile",
    "title": "Gestion d‚Äôun Dockerfile en projet collaboratif",
    "section": "II - Construire mon Dockerfile ?",
    "text": "II - Construire mon Dockerfile ?\nPour arriver √† √©crire cela, avoir d√©j√† install√© le programme voulu en local est tr√®s utile ! Mais si votre ordinateur est un Windows cela ne vous aidera pas‚Ä¶ Arriver √† vos fin peut √™tre compliqu√© et dans tout les cas il vas vous falloir essayer ‚Ä¶ La compilation d‚Äôun docker est assez longue donc chaque essais peut-√™tre co√ªteux. Il existe cependant diff√©rents moyens de gagner du temps. Commencez d‚Äôabord par chercher les routines d‚Äôinstallation des vos d√©pendances sur ubuntu.\n\na) Organiser son fichier\nUne image docker lors de sa compilation en local, va garder en cache √©norm√©ment d‚Äôinformation de mani√®re s√©quentielle. Changer des lignes au d√©but de mon Dockerfile est plus co√ªteux que de changer des lignes √† la fin. Ainsi il est toujours plus int√©ressant lors du d√©veloppement d‚Äôun conteneur de garder les lignes les moins s√ªres vers la fin du fichier (dans la mesure du possible).\n\n\nb) Compilation\nPour compiler mon conteneur il suffit de lancer la commande dans le r√©pertoire o√π est mon Docker.\n\ndocker build -f Dockerfile --progress=plain -t nom_image:num_version .\n\nUn changement de num√©ro de version suffit √† g√©n√©rer une nouvelle image en tirant toujours profit des donn√©es en cache.\n\n\nc) Tester rapidement un conteneur (exemple non-interactif)\nLe conteneur fabriqu√© pour le site de finistR est non interactif, une fois activ√© avec la ligne\n\ndocker run nom_image:num_version\n\nil n‚Äôest pas possible de lancer des commandes dans l‚Äôenvironnement cr√©√© depuis un terminal. Il n‚Äôest donc pas √©vident de tester les installations dans le conteneur.\nUne possibilit√© est de cr√©√© un deuxi√®me Dockerfile (que l‚Äôon peut nommer 'DockerfileTest'). Voici un exemple\n\n## Source DockerfileTest\nFROM nom_image:num_version\n\nRUN quarto check jupyter\nRUN julia -e 'using GeoDataFrames'\n\nCe Dockerfile se build avec la commande\n\ndocker build -f DockerfileTest --progress=plain -t nom_image_test:num_version .\n\nUn int√©r√™t de cette m√©thode est que l‚Äôon peux assez rapidement r√©√©diter le conteneur le premier √©tant inchang√©. Dans cet exemple :\n\nquarto check jupyter permet de v√©rifier si quarto a bien acc√®s √† jupyter mais aussi de v√©rifier si le kernel {IJulia} existe.\njulia -e 'using GeoDataFrames' v√©rifie si le package a bien √©t√© install√© dans Julia.\n\nC‚Äôest lors de ce build que vous pouvez v√©rifier si ces commandes rendent les r√©sultats attendus.\nDans le cas du conteneur de finistR, la compilation du conteneur sur github dure environ 45 min et le test √† la suite d‚Äôune pull request dure environ 30 min. Grace √† ces conseils un conteneur modifi√© aux derni√®res lignes se compile quasi imm√©diatement en local (idem pour DockerfileTest).\n\n\nd) Des bonnes pratiques oui ! Mais du groupe avant tout\nL‚Äôid√©al dans ce genre de projet en groupe, est de pouvoir faire un suivis des packages et langages √† installer. Pour cela lorsque que l‚Äôon effectue une pull request incluant un nouveau document, il est pr√©f√©rable de joindre explicitement en message :\n\nles d√©pendances\nla version du langage utilis√©\nle syst√®me d‚Äôexploitation\n\nEn cas de probl√®me avec un conteneur, ces informations sont tr√®s utiles pour r√©soudre les incompatibilit√©s qui ont lieux."
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#iii---la-r√©alit√©-une-limite-de-m√©moire",
    "href": "how_to_maintain_a_dockerfile.html#iii---la-r√©alit√©-une-limite-de-m√©moire",
    "title": "Gestion d‚Äôun Dockerfile en projet collaboratif",
    "section": "III - La r√©alit√©, une limite de m√©moire",
    "text": "III - La r√©alit√©, une limite de m√©moire\n\na) Un Dockerfile √ßa doit √™tre petit\nLors de ce projet nous avons utilis√© un autre Dockerfile (voir: Instructions pour le d√©pot sur le site web), car celui montr√© plus haut est beaucoup trop lourd (18GB), et ‚Ä¶ en pratique il ne rentre pas dans un runner GitHub (max 14GB) sans am√©nagement. Mes connaissances √©tant limit√©es, je ne sais comment √©conomiser de la m√©moire dans un docker.\n\n\nb) Abandon : Du docker plein au qmd fix√©s.\nPour r√©soudre ce probl√®me on vas donc transformer ce qmd (R & Julia) en un md fixe au moins pour la partie Julia. Je cr√©e donc un qmd contenant uniquement du texte et du Julia. Puis je le fais tourner en local pour produire un fichier md. Je remplace ensuite le passage en Julia dans mon qmd (R & Julia de base). Ainsi seul le R est du code r√©el. Pour finir je remplace les\n``` julia\navant chaque chunks de Julia par des\n```{r,eval = FALSE}\nCe qui va le faire s‚Äôafficher comme un chunk de R avec des couleurs dans le texte mais sans l‚Äô√©valuer."
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#conclusion",
    "href": "how_to_maintain_a_dockerfile.html#conclusion",
    "title": "Gestion d‚Äôun Dockerfile en projet collaboratif",
    "section": "Conclusion",
    "text": "Conclusion\nDocker c‚Äôest formidable √ßa permet de simplifier √©norm√©ment de processus en remotes, d‚Äôautomatiser des actions de contr√¥les et de diffusion mais aussi de partager des programmes plus simplement. Cependant c‚Äôest une technologie qui n√©cessite une liste claire des d√©pendances de chaque code. Enfin lorsque des proc√©d√©s complexes sont n√©cessaires, comme par exemples m√©langer de nombreux outils diff√©rents, il vaux tout de m√™me mieux jouer la carte de l‚Äô√©conomie, et reporter la plus part des calculs en local. Et ainsi faire travailler un minimum le runner √† chaque action."
  },
  {
    "objectID": "how_to_maintain_a_dockerfile.html#r√©f√©rences",
    "href": "how_to_maintain_a_dockerfile.html#r√©f√©rences",
    "title": "Gestion d‚Äôun Dockerfile en projet collaboratif",
    "section": "R√©f√©rences",
    "text": "R√©f√©rences\n\nhttps://www.docker.com/"
  },
  {
    "objectID": "jit-example-pln-jax.html",
    "href": "jit-example-pln-jax.html",
    "title": "JIT with JAX",
    "section": "",
    "text": "JAX is a Python library, basically a wrapper around numpy for efficient scientific programming: automatic differentiation, parallelization, JIT, etc. Many numpy functions are rewritten in a low level API called LAX. It then uses the XLA compiler to opitmization computations, see #numpy-lax-xla-jax-api-layering\nThis tutorial is a non exhaustive but dense introduction to JAX, especially JIT compilation with JAX. We try to point the reader to the main concepts with a lot of redirections to external resources and to JAX documentation."
  },
  {
    "objectID": "jit-example-pln-jax.html#jit-with-jax",
    "href": "jit-example-pln-jax.html#jit-with-jax",
    "title": "JIT with JAX",
    "section": "JIT with JAX",
    "text": "JIT with JAX\nA practical definition of JIT compilation can be found in JAX documentation:\n\nWhen we jit-compile a function, we usually want to compile a version of the function that works for many different argument values, so that we can cache and reuse the compiled code. That way we don‚Äôt have to re-compile on each function evaluation.\n\n\nFor example, if we evaluate an @jit function on the array jnp.array([1., 2., 3.], jnp.float32), we might want to compile code that we can reuse to evaluate the function on jnp.array([4., 5., 6.], jnp.float32) to save on compile time.\n\n\nBy default JAX executes operations one at a time, in sequence. Using a just-in-time (JIT) compilation decorator, sequences of operations can be optimized together and run at once.\n\nIn this tutorial we explore JAX JIT compilation on the same algorithm of the PLN model as coded in the PLN in pytorch tutorial. Also, this tutorial is to be compared with JIT compilation in pytorch.\nFirst, we make the necessary imports\nimport os\n#os.environ['CUDA_VISIBLE_DEVICES'] = '' # uncomment to force CPU\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\nimport jax\nimport jax.numpy as jnp\nimport optax\njax.config.update(\"jax_enable_x64\", False)\nprint(jax.devices())\nmyfloat = np.float32\n[gpu(id=0)]\nNote: We use a GPU since JIT compilation is particularly efficient on GPU.\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 1000\nlr = 1e-4\n\nJAX without JIT\nThis section does not use any kind of jitting. This is our baseline.\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return jnp.log(jnp.sqrt(2 * jnp.pi * integer_)) + integer_ * jnp.log(integer_ / jnp.exp(1))\n\nclass PLN:\n    def __init__(self, Y, O, X): \n        self.Y = Y\n        self.O = O\n        self.X = X\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = jnp.full(Y.shape, 0.0)\n        self.S = jnp.full(Y.shape, 1.0)\n        ## Model parameters\n        self.B = jnp.zeros((self.d, self.p))\n        self.Sigma = jnp.eye(self.p)\n        self.Omega = jnp.eye(self.p)\n\n    def get_Sigma(self, n, M, S) :\n        return 1/n * (M.T @ M + jnp.diag(jnp.sum(S**2, axis=0)))\n    \n    def get_ELBO(self, optim_params):\n      B, M, S = optim_params\n      S2 = jnp.square(S)\n      XB = self.X @ B\n      A = jnp.exp(self.O + M + XB + S2/2)\n\n      elbo = self.n/2 * jnp.log(jnp.linalg.det(self.Omega))\n      elbo += jnp.sum(- A + self.Y * (self.O + M + XB) + .5 * jnp.log(S2))\n      elbo -= .5 * jnp.trace(M.T @ M + jnp.diag(jnp.sum(S2, axis=0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - jnp.sum(_log_stirling(self.Y))\n      return -elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n        ELBO = jnp.zeros(N_iter)\n        optimizer = optax.chain(\n            #adam(learning_rate=lr)\n            optax.scale_by_radam(),\n            optax.scale(-1.0),\n            optax.clip(0.1),\n        )\n        opt_state = optimizer.init((self.B, self.M, self.S))\n        \n        for i in range(N_iter):\n            loss_value, grads = jax.value_and_grad(\n                self.get_ELBO, 0\n            )((self.B, self.M, self.S))\n    \n            updates, opt_state = optimizer.update(grads, opt_state, (self.B, self.M, self.S))\n            optim_params = optax.apply_updates((self.B, self.M, self.S), updates)\n            self.B, self.M, self.S = optim_params\n    \n            ## update parameters with close form\n            self.Sigma = self.get_Sigma(self.n, self.M, self.S)\n            self.Omega = jnp.linalg.inv(self.Sigma)\n    \n            objective = loss_value\n            ELBO = ELBO.at[i].set(objective)\n        \n        return ELBO\nHave a look a the way we update the ELBO vector in the previous functions. This is because JAX arrays are immutable #in-place-updates\n%%time\npln = PLN(Y, O, X)\n\nwith jax.default_device(jax.devices('cpu')[0]): # as opposed to the subsequent jitted versions of the code, running this code do\n    jaxELBO_no_jit = jax.block_until_ready(\n        pln.fit(N_iter, lr, tol=1e-8)\n    )\nCPU times: user 10min 53s, sys: 21min 15s, total: 32min 8s\nWall time: 2min\n\n\nJIT with JAX level 1: jax.jit\nIn this section, we will jit the functions used in the optimization process. Since it is not straightforward to JIT compilation class methods (see subsequent section), we will not use a class anymore.\nThus, we first create an independant function to initialize variables.\ndef init_params(Y, O, X): \n    n, p = Y.shape\n    d = X.shape[1]\n    ## Variational parameters\n    M = jnp.full(Y.shape, 0.0)\n    S = jnp.full(Y.shape, 1.0)\n    ## Model parameters\n    B = jnp.zeros((d, p))\n    Sigma = jnp.eye(p)\n    Omega = jnp.eye(p)\n\n    return n, p, d, M, S, B, Sigma, Omega\nLet‚Äôs create the jitted functions. Note that _log_stirling will be automatically jitted when called the jitted get_ELBO. The actual Just In Time compilation will actually happen at the first execution of the jitted function. Note that the call jax.jit() is equivalent to using the decorator @jax.jit\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)\n    return jnp.log(jnp.sqrt(2 * jnp.pi * integer_)) + integer_ * jnp.log(integer_ / jnp.exp(1))\n    \ndef get_ELBO(optim_params, other_params): \n    B, M, S = optim_params['B'], optim_params['M'], optim_params['S']\n    X, O, n, Omega, Y, p = (other_params['X'], other_params['O'], \n        other_params['n'], other_params['Omega'], other_params['Y'],\n        other_params['p'])\n    S2 = jnp.square(S)\n    XB = X @ B\n    A = jnp.exp(O + M + XB + S2/2)\n\n    elbo = 0.\n    elbo = n / 2 * jnp.log(jnp.linalg.det(Omega))\n    elbo += jnp.sum(- A + Y * (O + M + XB) + .5 * jnp.log(S2))\n    elbo -= .5 * jnp.trace(M.T @ M + jnp.diag(jnp.sum(S2, axis = 0)) @ Omega)\n    elbo += .5 * n * p  - jnp.sum(_log_stirling(Y))\n    return -elbo\n\njit_loss_and_grad = jax.jit(jax.value_and_grad(get_ELBO, 0)) # JIT !\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + jnp.diag(jnp.sum(S**2, axis = 0)))\n\njit_getSigma = jax.jit(get_Sigma) # JIT !\n\njit_inv = jax.jit(jnp.linalg.inv) # JIT !\nIn the following, each function inside the for loop is jitted but the for loop is not jitted itself; it is inefficient to do so in JAX mostly due to the long compilation time it would induce, see #jit-decorated-function-is-very-slow-to-compile.\ndef jaxfit1(optim_params, other_params, N_iter, lr, tol = 1e-8) :\n    ELBO = jnp.zeros(N_iter)\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init(optim_params)\n    objective0 = jnp.inf\n\n    update = jax.jit(optimizer.update)\n    apply_updates = jax.jit(optax.apply_updates)\n\n    for i in range(N_iter):\n        loss_value, grads = jit_loss_and_grad(\n            optim_params,\n            other_params\n        )\n\n        updates, opt_state = update(grads, opt_state, optim_params)\n        optim_params = apply_updates(optim_params, updates)\n\n        ## update parameters with close form\n        other_params['Sigma'] = jit_getSigma(other_params['n'], optim_params['M'],\n        optim_params['S'])\n        other_params['Omega'] = jit_inv(other_params['Sigma'])\n\n        objective = loss_value\n        ELBO = ELBO.at[i].set(objective)\n\n    return ELBO\nInitialize the data for JAX\nY = jnp.asarray(Y)\nO = jnp.asarray(O)\nX = jnp.array(X)\nn, p, d, M, S, B, Sigma, Omega = init_params(Y, O, X)\noptim_params = {'B':B, 'M':M, 'S':S}\nother_params = {'X':X, 'O':O, 'n':n, 'Omega':Omega, 'Y':Y, 'p':p, 'Sigma':Sigma}\nand run the learning process:\n%%time\njaxELBO1 = jax.block_until_ready(\n    jaxfit1(optim_params, other_params, N_iter, lr=lr, tol=1e-8)\n)\nCPU times: user 3.87 s, sys: 500 ms, total: 4.37 s\nWall time: 4.13 s\nNote: Because of the complex JAX internal mechanics, benchmarking with JAX should be done with caution https://jax.readthedocs.io/en/latest/async_dispatch.html\n\n\nJIT with JAX level 2: jax.lax.scan\nIn this section, we add resort to jax.lax.scan, which is the standard way to write for loops in JAX. jax.lax.scan automatically JIT compiles its content, it‚Äôs not necessary to add the calls to jax.jit here.\nFor a complete tutorial on jax.lax.scan see https://ericmjl.github.io/dl-workshop/02-jax-idioms/02-loopy-carry.html\ndef jaxfit2(optim_params, other_params, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init(optim_params)\n    \n    def scan_fun(carry, _):\n        optim_params = carry['optim_params']\n        other_params = carry['other_params']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(optim_params,\n        other_params)\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        optim_params = optax.apply_updates(optim_params, updates)\n    \n        ## update parameters with close form\n        other_params['Sigma'] = get_Sigma(other_params['n'], optim_params['M'],\n        optim_params['S'])\n        other_params['Omega'] = jnp.linalg.inv(other_params['Sigma'])\n    \n        carry['optim_params'] = optim_params\n        carry['other_params'] = other_params\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n\n    \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"optim_params\":optim_params,\n            \"other_params\":other_params,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\nInitialize the data for JAX:\nY = jnp.asarray(Y)\nO = jnp.asarray(O)\nX = jnp.array(X)\nn, p, d, M, S, B, Sigma, Omega = init_params(Y, O, X)\noptim_params = {'B':B, 'M':M, 'S':S}\nother_params = {'X':X, 'O':O, 'n':n, 'Omega':Omega, 'Y':Y, 'p':p, 'Sigma':Sigma}\nNote: Let‚Äôs us try the Ahead Of Time (AOT) compilation where the compilation is done beforehand in a particular explicit step and not at the first execution of the function (as in classical JIT compilation). By doing so we can get an estimate of the compilation time, which is, in our case, not a bottleneck.\n%%time\nlowered = jax.jit(jaxfit2, static_argnums=(2,3,4)).lower(optim_params,\nother_params, N_iter, lr=lr, tol=1e-8)\ncompiled = lowered.compile()\nCPU times: user 708 ms, sys: 40.1 ms, total: 748 ms\nWall time: 502 ms\nLet‚Äôs run the complete fit (including compilation)\n%%time\njaxELBO2 = jax.block_until_ready(\n    jaxfit2(optim_params, other_params, N_iter, lr, tol=1e-8)\n)\nCPU times: user 1.97 s, sys: 1.08 s, total: 3.05 s\nWall time: 2.83 s\n\n\nJIT with JAX level 3: can we jit everything?\nNow we will dive into some of the sharp bits of JAX. Let‚Äôs try to reuse the above jitted functions with a simple PLN class which acts like a container as we did in the tutorial JIT compilation in pytorch.\nclass PLN_container:\n    def __init__(self, Y, O, X): \n        self.Y = Y\n        self.O = O\n        self.X = X\n        self.n, self.p = Y.shape\n        self.n = self.n\n        self.p = self.p\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = jnp.full(Y.shape, 0.0)\n        self.S = jnp.full(Y.shape, 1.0)\n        ## Model parameters\n        self.B = jnp.zeros((self.d, self.p))\n        self.Sigma = jnp.eye(self.p)\n        self.Omega = jnp.eye(self.p)\nThen we would like to adapt the scan_fun as:\ndef jaxfit3(pln, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init({'B':pln.B, 'M':pln.M, 'S':pln.S})\n\n    def scan_fun(carry, _):\n        pln = carry['PLN']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            {'X':pln.X, 'O':pln.O, 'n':pln.n, 'Omega':pln.Omega,\n             'Y':pln.Y, 'p':pln.p, 'Sigma':pln.Sigma}\n        )\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        updated_params = optax.apply_updates(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            updates)\n        pln.B = updated_params['B']\n        pln.M = updated_params['M']\n        pln.S = updated_params['S']\n    \n        ## update parameters with close form\n        pln.Sigma = get_Sigma(pln.N, pln.M, pln.S)\n        pln.Omega = jnp.linalg.inv(pln.Sigma)\n    \n        carry['PLN'] = pln\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n    \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"PLN\":pln,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\nAnd finally, we would like to start the optimization with:\npln_container = PLN_container(Y, O, X)\njaxELBO3 = jax.block_until_ready(\n    jaxfit3(pln_container, N_iter, lr, tol=1e-8)\n)\nIf we run the previous lines, we get an expected error: class PLN is not a valid JAX type. Recall that the scan loop automatically JIT compiles its content and we cannot JIT compile function whose arguments are custom classes without specific treatment that we will discover in the next subsection. But what is a valid JAX type? From the documentation of jax.jit we read:\n\nThe arguments and return value of fun [the jitted function] should be arrays, scalars, or (nested) standard Python containers (tuple/list/dict) [pytrees] thereof [which themselves contain arrays or scalars].\n\nThe variety of containers that JAX can handle are refered to with the term Pytrees.\nWe also read about pure function and static arguments, more on that below !\nFor the moment, as the class PLN acts as a simple container, a common work around can be to use a Python native and jittable namedtuple class, or a NamedTuple from typing library which improves the class creation. See this introduction to NamedTuple: https://www.geeksforgeeks.org/typing-namedtuple-improved-namedtuples/. NamedTuples are immutable class, so if we want to update one of its attributes we need to use the _replace() method which returns a new object! Note that we can use jax.typing to provide JAX related type hints #jax.typing.\nfrom typing import NamedTuple\nfrom jax.typing import ArrayLike\n\nclass PLN(NamedTuple):\n    Y: ArrayLike\n    O: ArrayLike\n    X: ArrayLike\n    n: int\n    p: int\n    d: int\n    M: ArrayLike\n    S: ArrayLike\n    B: ArrayLike\n    Sigma: ArrayLike\n    Omega: ArrayLike\n    \npln_namedtuple = PLN(\n    Y, O, X,\n    Y.shape[0], Y.shape[1], X.shape[1],\n    jnp.full(Y.shape, 0.0), jnp.full(Y.shape, 1.0),\n    jnp.zeros((X.shape[1], Y.shape[1])), jnp.eye(Y.shape[1]),\n    jnp.eye(Y.shape[1]))\nLet‚Äôs adapt the scan_fun function\ndef jaxfit3(pln, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init({'B':pln.B, 'M':pln.M, 'S':pln.S})\n\n    def scan_fun(carry, _):\n        pln = carry['PLN']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            {'X':pln.X, 'O':pln.O, 'n':pln.n, 'Omega':pln.Omega,\n             'Y':pln.Y, 'p':pln.p, 'Sigma':pln.Sigma}\n        )\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        updated_params = optax.apply_updates(\n            {'B':pln.B, 'M':pln.M, 'S':pln.S},\n            updates)\n        pln = pln._replace(B=updated_params['B'])\n        pln = pln._replace(M=updated_params['M'])\n        pln = pln._replace(S=updated_params['S'])\n    \n    \n        ## update parameters with close form\n        pln = pln._replace(Sigma=get_Sigma(pln.n, pln.M, pln.S))\n        pln = pln._replace(Omega=jnp.linalg.inv(pln.Sigma))\n    \n        carry['PLN'] = pln\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"PLN\":pln,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\n%%time\njaxELBO3 = jax.block_until_ready(\n    jaxfit3(pln_namedtuple, N_iter, lr, tol=1e-8)\n)\nCPU times: user 2.34 s, sys: 831 ms, total: 3.17 s\nWall time: 2.91 s\nOk, our code works but it is getting a little bit messy: we would like more than containers but real classes, with real methods! That‚Äôs what we will see in the next section.\nFirst, let‚Äôs try to summarize the main points of JIT compiling functions with JAX:\n\nNot all JAX code can be JIT compiled, as it requires array shapes to be static & known at compile time. #to-jit-or-not-to-jit\nJIT and other JAX transforms work by tracing a function to determine its effect on inputs of a specific shape and type. Variables that you don‚Äôt want [or that cannot be traced because they are not of valid JAX type] to be traced can be marked as static #jit-mechanics-tracing-and-static-variables\nRecall that JIT compilation in pytorch cannot handle dynamic shapes, control flows, etc. since it is lost when constructing the Intermediate Representation (IR) of the computational graph that is ued for jitting. The same behaviour happens in JAX when constructing the jaxpr which is the name of the IR in JAX, see #why-can-t-we-just-jit-everything. However, in JAX, there exists way to not lose all the control flows, to conserve conditional statements even inside the jaxpr, etc. Let‚Äôs mention the static_argnums decorator, the special jax.lax.cond function, etc. To find more about control flows and jit, see #python-control-flow-jit\nIn fact, JAX is asked to JIT compile a function, it will trace its arguments to create the jaxpr, more precisely #jitting.html:\n\n\nWhen tracing, JAX wraps each argument by a tracer object. These tracers then record all JAX operations performed on them during the function call (which happens in regular Python). Then, JAX uses the tracer records to reconstruct the entire function. The output of that reconstruction is the jaxpr\n\n\nThe more specific information about the values we use in the trace, the more we can use standard Python control flow to express ourselves. However, being too specific means we can‚Äôt reuse the same traced function for other values. JAX solves this by tracing at different levels of abstraction for different purposes. For jax.jit, the default level is ShapedArray We understand that the arguments of a jitted function should be traceable as ShapedArray class, or be a Pytree with either 1.Pytree nodes or 2.leaf nodes being either traceable as a ShapedArray object or leaf nodes treated as static arguments. We saw above that scalars and arrays were the valid JAX types, it makes sense since scalars or arrays can be traced with ShapedArray objects.\n\n\nNote on static arguments:\n\n\nWe can tell JAX to help itself to a less abstract tracer for a particular input by specifying static_argnums or static_argnames. The cost of this is that the resulting jaxpr is less flexible, so JAX will have to re-compile the function for every new value of the specified static input. It is only a good strategy if the function is guaranteed to get limited different values.\n\n\nLast but not least, JAX requires the jitted functions to be pure, they cannot have any side effect #pure-functions:\n\n\nJAX transformation and compilation are designed to work only on Python functions that are functionally pure: all the input data is passed through the function parameters, all the results are output through the function results. A pure function will always return the same result if invoked with the same inputs.\n\nJIT with JAX level 3.5: dataclasses and pytrees\nPython developpers also love to use dataclasses as simple data structures. However they are not supported by default in JAX. Many libraries offer ways to also add dataclasses to the Pytrees JAX can handle: simple-pytree, tjax, jax_dataclasses, chex dataclasses etc.\n\n\nJIT with JAX level 4: JIT on class methods\nIn this section, we study the canonical way to JIT compile class methods, a introduction to this technique can be found here: #how-to-use-jit-with-methods. Note that the recipe we give here should be seen from the viewpoint of Pytrees, since a class is always somehow a container. We therefore want to #extending-pytrees. The main elements of making custom class jittable are:\n\nDecorate the class with @register_pytree_node_class\nAdd the tree_flatten method\nAdd the tree_unflatten method\n\nWe here can draw a link with the elements we noted in the previous section: we make our custom class a Pytree, so that it can be jitted provided it contains attributes being 1.Pytree nodes or 2.leaf nodes being either inherited ShapedArray object or leaf nodes treated as static arguments!\nfrom jax.tree_util import register_pytree_node_class\nfrom jax.typing import ArrayLike\n\n@register_pytree_node_class\nclass PLN:\n    Y: ArrayLike\n    O: ArrayLike\n    X: ArrayLike\n    n: int\n    p: int\n    d: int\n    M: ArrayLike\n    S: ArrayLike\n    B: ArrayLike\n    Sigma: ArrayLike\n    Omega: ArrayLike\n    \n    def __init__(self, Y, O, X): \n        self.Y = Y\n        self.O = O\n        self.X = X\n        self.n, self.p = Y.shape\n        self.n = self.n\n        self.p = self.p\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = jnp.full(Y.shape, 0.0)\n        self.S = jnp.full(Y.shape, 1.0)\n        ## Model parameters\n        self.B = jnp.zeros((self.d, self.p))\n        self.Sigma = jnp.eye(self.p)\n        self.Omega = jnp.eye(self.p)\n\n    def get_optim_params(self):\n        return {'B':self.B, 'M':self.M, 'S':self.S}\n        \n    def set_optim_params(self, op):\n        for k, v in op.items():\n            vars(self)[k] = v\n\n    def get_other_params(self):\n        return {\n            'X':self.X, 'O':self.O, 'n':self.n, 'Omega':self.Omega,\n            'Y':self.Y, 'p':self.p, 'Sigma':self.Sigma\n        }\n        \n    def set_other_params(self, op):\n        for k, v in op.items():\n            vars(self)[k] = v\n\n    def update_Sigma(self):\n        pln.Sigma = 1 / self.n * (self.M.T @ self.M + jnp.diag(jnp.sum(self.S ** 2, axis = 0)))\n\n    def update_Omega(self):\n        pln.Omega = jnp.linalg.inv(self.Sigma)\n\n    def tree_flatten(self):\n        children = (\n            self.B, self.M, self.S, self.Sigma, self.Omega,\n        )  # arrays / dynamic values\n        aux_data = {\n            'Y':self.Y, 'O':self.O, 'X':self.X,\n            'n':self.n, 'p':self.p, 'd':self.d\n        }  # static values\n        return (children, aux_data)\n\n    @classmethod\n    def tree_unflatten(cls, aux_data, children):\n        (B, M, S, Sigma, Omega) = children\n        obj = cls(\n            aux_data['Y'], aux_data['O'], aux_data['X']\n        )\n        obj.B = B\n        obj.M = M\n        obj.S = S\n        return obj\nLet‚Äôs adapt the scan_fun function, we are now free to use our new class methods\ndef jaxfit4(pln, N_iter, lr, tol = 1e-8) :\n    optimizer = optax.chain(\n        #adam(learning_rate=lr)\n        optax.scale_by_radam(),\n        optax.scale(-1.0),\n        optax.clip(0.1),\n    )\n    opt_state = optimizer.init(pln.get_optim_params())\n\n    def scan_fun(carry, k):\n        pln = carry['PLN']\n        loss_value, grads = jax.value_and_grad(get_ELBO)(\n            pln.get_optim_params(),\n            pln.get_other_params()\n        )\n    \n        updates, opt_state = optimizer.update(grads, carry['opt_state'])\n        optim_params = optax.apply_updates(\n            pln.get_optim_params(),\n            updates\n        )\n        pln.set_optim_params(optim_params)\n    \n        ## update parameters with close form\n        pln.update_Sigma()\n        pln.update_Omega()\n    \n        carry['PLN'] = pln\n        carry['opt_state'] = opt_state\n        return carry, loss_value\n \n    carry, ELBO = jax.lax.scan(\n        scan_fun,\n        {\n            \"PLN\":pln,\n            'opt_state':opt_state\n        },\n        jnp.arange(N_iter)\n    )\n\n    return ELBO\n%%time\npln = PLN(Y, O, X)\njaxELBO4 = jax.block_until_ready(\n    jaxfit4(pln, N_iter, lr, tol=1e-8)\n)\nCPU times: user 6.29 s, sys: 901 ms, total: 7.2 s\nWall time: 4.34 s"
  },
  {
    "objectID": "jit-example-pln-jax.html#conclusion",
    "href": "jit-example-pln-jax.html#conclusion",
    "title": "JIT with JAX",
    "section": "Conclusion",
    "text": "Conclusion\nWe check the results\nplt.plot(np.log(jaxELBO_no_jit), label='no jit')\nplt.plot(np.log(jaxELBO1), label='jit level 1')\nplt.plot(np.log(jaxELBO2), label='jit level 2')\nplt.plot(np.log(jaxELBO3), label='jit level 3')\nplt.plot(np.log(jaxELBO4), label='jit level 4')\nplt.legend()\nplt.show()\n/tmp/ipykernel_54173/3050985271.py:1: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO_no_jit), label='no jit')\n/tmp/ipykernel_54173/3050985271.py:2: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO1), label='jit level 1')\n/tmp/ipykernel_54173/3050985271.py:3: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO2), label='jit level 2')\n/tmp/ipykernel_54173/3050985271.py:4: RuntimeWarning: invalid value encountered in log\n  plt.plot(np.log(jaxELBO3), label='jit level 3')\n\n\n\npng\n\n\n\nJitting is more involved in JAX than with pytorch, the best performances require some specific JAX knowledge that we exposed in each subsection of this document.\nWhen jitting with JAX we fall back on quite the same difficulties as when jitting with pytorch trace.\nHowever, JAX offers clear ways to overcome the difficulties that pytorch tracing does not offer (scan, static_argnums, pytrees, ‚Ä¶)\nIn this particular example on GPU, jitted JAX can perform twice as fast as jitted pytorch. But in this particular example on CPU, JAX is slower than pytorch; is it link with the points raised in #benchmarking-jax-code ? However, this also recalls what we can often read online: JAX is particularly suited for GPU optimization. We need to test JAX on other examples involving neural networks, mini-batches, etc. in order to understand JAX potential on CPU optimization too."
  },
  {
    "objectID": "jit-example-pln.html",
    "href": "jit-example-pln.html",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We study Just In Time (JIT) compilation with pytorch. This tutorial is to be compared with JIT compilation in pytorch where much more explanations are given.\n\n\n\nReferences to pytorch JIT compilation, by order of difficulty:\n\npytorch jit official documentation\npytorch jit trace documentation\nTorchScript official tutorial\npytorch jit intermediate guide\npytorch jit intermediate / advanced guide\npytorch jit advanced guide\n\nMake necessary imports\nimport torch\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\nUsing a GPU.\nNote: We use pytorch GPU ! JIT compilation is particularly efficient on GPU. On this particular example, we were not able to see any speed up on CPU between jitted code and non-jitted code. We suppose it might be possible to get a CPU speed up on other case study, considering neural networks for example..\ndevice =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\ntorch.set_default_dtype(torch.float32)\nmyfloat = np.float32\ncuda\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 5000\nlr = 1e-2\n\n\n\nWe reuse the code from PLN in pytorch.\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device:\n    torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol=1e-8) :\n      self.ELBO = np.zeros(N_iter, dtype=myfloat)\n      optimizer = torch.optim.Adam([self.B, self.M, self.S], lr=lr)\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\nLet‚Äôs create the PLN object:\n%%time\nmyPLN = PLN(Y, O, X, device)\nCPU times: user 523 ms, sys: 67 ms, total: 590 ms\nWall time: 134 ms\nand run the learning process:\n%%time\nmyPLN.fit(N_iter, lr = lr, tol=1e-8)\nCPU times: user 34.5 s, sys: 193 ms, total: 34.7 s\nWall time: 35.3 s\n\n\n\nThere are two ways to create the computational graph: eager execution and graph execution. The default mode in pytorch is eager, this means the computational graph is created at each forward pass in the graph. On the other hand, the graph mode adds an additional compilation step which builds the graph only once and lets the computations be done at a lower level.\nJIT (Just In Time) compilation is the process that builds an Intermediate Representation (IR) of the graph. This is the additional compilation step mentioned above.\nUsing graph mode, we gain:\n\nefficiency since the graph is precomputed and can be optimized to factorize redundant operations or delete useless operations.\nportability since this IR can be reused in another language.\n\nHowever, we lose:\n\nflexibility since we are tied to fixed array sizes, we cannot easily use control flows, ‚Ä¶\n\nThere are two ways in pytorch to JIT our code, hence, there are two ways to use require the graph mode. We study these two ways in the next sections.\n\n\n\nBy reading the above mentioned references, we get that we cannot jit the fit function. Some reasons are:\n\nN_iter is variable at compilation time (shape might change depending on input).\nthe pytorch optimizer‚Äôs operations cannot be jitted.\ntorch.jit.script cannot handle control flow or loops.\n\nclass jitPLN(torch.jit.ScriptModule) :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        super().__init__()\n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    @torch.jit.script_method\n    def _log_stirling(self, integer):\n        integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n        return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\n    @torch.jit.script_method\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    @torch.jit.script_method\n    def get_inv(self, S):\n      return torch.inverse(S)\n\n    @torch.jit.script_method\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(self._log_stirling(self.Y))\n      return elbo\n\ndef fit(pln, N_iter, lr, tol = 1e-8) :\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - pln.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = pln.get_Sigma()\n        pln.Omega = pln.get_inv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nLet‚Äôs create the jitted PLN object:\n%%time\nmyjitPLN = jitPLN(Y, O, X, device)\nCPU times: user 194 ms, sys: 4.8 ms, total: 199 ms\nWall time: 19.4 ms\nand run the learning process:\n%%time\nscriptELBO = fit(myjitPLN, N_iter, lr = lr, tol = 1e-8)\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: operator() profile_node %760 : int[] = prim::profile_ivalue(%dims.24)\n does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\n\nCPU times: user 27.3 s, sys: 164 ms, total: 27.4 s\nWall time: 28.2 s\n\n\n\nHere we use torch.jit.trace over each of the computational functions, the PLN class is just a container for the objects. The previous limitations from torch.jit.script are still present, notably, we cannot jit the main for loop.\nclass tracejitPLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : torch.Tensor\n    p : torch.Tensor\n    d : torch.Tensor\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.n = torch.tensor(self.n)\n        self.p = torch.tensor(self.p)\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n        self.device = device\nLet‚Äôs create the PLN object and the jitted functions:\n%%time\nmytracePLN = tracejitPLN(Y, O, X, device)\n\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\ntraced_logstirling = torch.jit.trace(_log_stirling, (mytracePLN.Y))\n\ndef get_ELBO(S, X, B, O, M, n, Omega, Y, p): \n    S2 = torch.square(S)\n    XB = X @ B\n    A = torch.exp(O + M + XB + S2/2)\n\n    elbo = n/2 * torch.logdet(Omega)\n    elbo += torch.sum(- A + Y * (O + M + XB) + .5 * torch.log(S2))\n    elbo -= .5 * torch.trace(M.T @ M + torch.diag(torch.sum(S2, dim = 0)) @ Omega)\n    elbo += .5 * n * p  - torch.sum(traced_logstirling(Y))\n    return elbo\n\ntraced_getELBO = torch.jit.trace(get_ELBO, (mytracePLN.S, mytracePLN.X, mytracePLN.B, mytracePLN.O, mytracePLN.M,\n    mytracePLN.n, mytracePLN.Omega, mytracePLN.Y, mytracePLN.p))\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + torch.diag(torch.sum(S**2, dim = 0)))\n\ntraced_getSigma = torch.jit.trace(get_Sigma, (mytracePLN.n, mytracePLN.M, mytracePLN.S))\n\ndef get_inv(S):\n    return torch.inverse(S)\n\ntraced_getInv = torch.jit.trace(get_inv, get_Sigma(mytracePLN.n, mytracePLN.M, mytracePLN.S))\nCPU times: user 401 ms, sys: 4.63 ms, total: 406 ms\nWall time: 56 ms\n\n\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n  if a.grad is not None:\ndef tracefit(pln, N_iter, lr, tol = 1e-8) :\n\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -traced_getELBO(pln.S, pln.X, pln.B, pln.O, pln.M,\n            pln.n, pln.Omega, pln.Y, pln.p)\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = traced_getSigma(pln.n, pln.M, pln.S)\n        pln.Omega = traced_getInv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nand run the learning process:\n%%time\ntraceELBO = tracefit(mytracePLN, N_iter, lr = lr, tol = 1e-8)\nCPU times: user 25.6 s, sys: 171 ms, total: 25.8 s\nWall time: 26.5 s\n\n\n\nWe check that we get the same results with each method:\nplt.plot(np.log(-myPLN.ELBO), label='NO jit')\nplt.plot(np.log(-scriptELBO), label='jit script')\nplt.plot(np.log(-traceELBO), label='jit trace')\nplt.legend()\nplt.show()\n\n\n\nelbo_graph.png\n\n\n\nWe see that jit script and jit trace reduce computation time by a few second over the non jitted code. Hence, jit compilation in pytorch can be interesting but induces strict limitations that the user must be aware of.\nWe should try to consider a more involved problem computationally speaking (bigger input data, computations involving neural networks, ‚Ä¶)"
  },
  {
    "objectID": "jit-example-pln.html#jit-compilation-with-pytorch",
    "href": "jit-example-pln.html#jit-compilation-with-pytorch",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We study Just In Time (JIT) compilation with pytorch. This tutorial is to be compared with JIT compilation in pytorch where much more explanations are given."
  },
  {
    "objectID": "jit-example-pln.html#set-up",
    "href": "jit-example-pln.html#set-up",
    "title": "JIT with pytorch",
    "section": "",
    "text": "References to pytorch JIT compilation, by order of difficulty:\n\npytorch jit official documentation\npytorch jit trace documentation\nTorchScript official tutorial\npytorch jit intermediate guide\npytorch jit intermediate / advanced guide\npytorch jit advanced guide\n\nMake necessary imports\nimport torch\nimport numpy as np\nimport math\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\nUsing a GPU.\nNote: We use pytorch GPU ! JIT compilation is particularly efficient on GPU. On this particular example, we were not able to see any speed up on CPU between jitted code and non-jitted code. We suppose it might be possible to get a CPU speed up on other case study, considering neural networks for example..\ndevice =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\ntorch.set_default_dtype(torch.float32)\nmyfloat = np.float32\ncuda\noaks = load_oaks()\nY = np.asarray(oaks['counts']).astype(myfloat)\nY = np.repeat(Y, 100, axis=0) # make data bigger to feel the speed up\nO = np.log(oaks['offsets']).astype(myfloat)\nO = np.repeat(O, 100, axis=0) # make data bigger to feel the speed up\nX = np.ones([Y.shape[0],1]).astype(myfloat)\n\nN_iter = 5000\nlr = 1e-2"
  },
  {
    "objectID": "jit-example-pln.html#original-non-jitted-version",
    "href": "jit-example-pln.html#original-non-jitted-version",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We reuse the code from PLN in pytorch.\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device:\n    torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol=1e-8) :\n      self.ELBO = np.zeros(N_iter, dtype=myfloat)\n      optimizer = torch.optim.Adam([self.B, self.M, self.S], lr=lr)\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\nLet‚Äôs create the PLN object:\n%%time\nmyPLN = PLN(Y, O, X, device)\nCPU times: user 523 ms, sys: 67 ms, total: 590 ms\nWall time: 134 ms\nand run the learning process:\n%%time\nmyPLN.fit(N_iter, lr = lr, tol=1e-8)\nCPU times: user 34.5 s, sys: 193 ms, total: 34.7 s\nWall time: 35.3 s"
  },
  {
    "objectID": "jit-example-pln.html#eager-graph-mode",
    "href": "jit-example-pln.html#eager-graph-mode",
    "title": "JIT with pytorch",
    "section": "",
    "text": "There are two ways to create the computational graph: eager execution and graph execution. The default mode in pytorch is eager, this means the computational graph is created at each forward pass in the graph. On the other hand, the graph mode adds an additional compilation step which builds the graph only once and lets the computations be done at a lower level.\nJIT (Just In Time) compilation is the process that builds an Intermediate Representation (IR) of the graph. This is the additional compilation step mentioned above.\nUsing graph mode, we gain:\n\nefficiency since the graph is precomputed and can be optimized to factorize redundant operations or delete useless operations.\nportability since this IR can be reused in another language.\n\nHowever, we lose:\n\nflexibility since we are tied to fixed array sizes, we cannot easily use control flows, ‚Ä¶\n\nThere are two ways in pytorch to JIT our code, hence, there are two ways to use require the graph mode. We study these two ways in the next sections."
  },
  {
    "objectID": "jit-example-pln.html#jit-with-torch.jit.script",
    "href": "jit-example-pln.html#jit-with-torch.jit.script",
    "title": "JIT with pytorch",
    "section": "",
    "text": "By reading the above mentioned references, we get that we cannot jit the fit function. Some reasons are:\n\nN_iter is variable at compilation time (shape might change depending on input).\nthe pytorch optimizer‚Äôs operations cannot be jitted.\ntorch.jit.script cannot handle control flow or loops.\n\nclass jitPLN(torch.jit.ScriptModule) :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        super().__init__()\n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n\n        self.device = device\n\n    @torch.jit.script_method\n    def _log_stirling(self, integer):\n        integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n        return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\n    @torch.jit.script_method\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    @torch.jit.script_method\n    def get_inv(self, S):\n      return torch.inverse(S)\n\n    @torch.jit.script_method\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega)\n      elbo += torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2))\n      elbo -= .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega)\n      elbo += .5 * self.n * self.p  - torch.sum(self._log_stirling(self.Y))\n      return elbo\n\ndef fit(pln, N_iter, lr, tol = 1e-8) :\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - pln.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = pln.get_Sigma()\n        pln.Omega = pln.get_inv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nLet‚Äôs create the jitted PLN object:\n%%time\nmyjitPLN = jitPLN(Y, O, X, device)\nCPU times: user 194 ms, sys: 4.8 ms, total: 199 ms\nWall time: 19.4 ms\nand run the learning process:\n%%time\nscriptELBO = fit(myjitPLN, N_iter, lr = lr, tol = 1e-8)\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: operator() profile_node %760 : int[] = prim::profile_ivalue(%dims.24)\n does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\n\nCPU times: user 27.3 s, sys: 164 ms, total: 27.4 s\nWall time: 28.2 s"
  },
  {
    "objectID": "jit-example-pln.html#jit-with-torch.jit.trace",
    "href": "jit-example-pln.html#jit-with-torch.jit.trace",
    "title": "JIT with pytorch",
    "section": "",
    "text": "Here we use torch.jit.trace over each of the computational functions, the PLN class is just a container for the objects. The previous limitations from torch.jit.script are still present, notably, we cannot jit the main for loop.\nclass tracejitPLN:\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : torch.Tensor\n    p : torch.Tensor\n    d : torch.Tensor\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    device : torch.device\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array, device: torch.device) : \n        self.Y = torch.tensor(Y)\n        self.Y = self.Y.to(device)\n        self.O = torch.tensor(O)\n        self.O = self.O.to(device)\n        self.X = torch.tensor(X)\n        self.X = self.X.to(device)\n        self.n, self.p = Y.shape\n        self.n = torch.tensor(self.n)\n        self.p = torch.tensor(self.p)\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad=True,\n            device=device)\n        self.S = torch.full(Y.shape, 1.0, requires_grad=True, device=device)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad=True, device=device)\n        self.Sigma = torch.eye(self.p, device=device)\n        self.Omega = torch.eye(self.p, device=device)\n        self.device = device\nLet‚Äôs create the PLN object and the jitted functions:\n%%time\nmytracePLN = tracejitPLN(Y, O, X, device)\n\ndef _log_stirling(integer):\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\ntraced_logstirling = torch.jit.trace(_log_stirling, (mytracePLN.Y))\n\ndef get_ELBO(S, X, B, O, M, n, Omega, Y, p): \n    S2 = torch.square(S)\n    XB = X @ B\n    A = torch.exp(O + M + XB + S2/2)\n\n    elbo = n/2 * torch.logdet(Omega)\n    elbo += torch.sum(- A + Y * (O + M + XB) + .5 * torch.log(S2))\n    elbo -= .5 * torch.trace(M.T @ M + torch.diag(torch.sum(S2, dim = 0)) @ Omega)\n    elbo += .5 * n * p  - torch.sum(traced_logstirling(Y))\n    return elbo\n\ntraced_getELBO = torch.jit.trace(get_ELBO, (mytracePLN.S, mytracePLN.X, mytracePLN.B, mytracePLN.O, mytracePLN.M,\n    mytracePLN.n, mytracePLN.Omega, mytracePLN.Y, mytracePLN.p))\n\ndef get_Sigma(n, M, S) :\n    return 1/n * (M.T @ M + torch.diag(torch.sum(S**2, dim = 0)))\n\ntraced_getSigma = torch.jit.trace(get_Sigma, (mytracePLN.n, mytracePLN.M, mytracePLN.S))\n\ndef get_inv(S):\n    return torch.inverse(S)\n\ntraced_getInv = torch.jit.trace(get_inv, get_Sigma(mytracePLN.n, mytracePLN.M, mytracePLN.S))\nCPU times: user 401 ms, sys: 4.63 ms, total: 406 ms\nWall time: 56 ms\n\n\n/home/hugo/anaconda3/envs/finistR2023/lib/python3.9/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n  if a.grad is not None:\ndef tracefit(pln, N_iter, lr, tol = 1e-8) :\n\n    ELBO = np.zeros(N_iter, dtype=myfloat)\n    optimizer = torch.optim.Adam([pln.B, pln.M, pln.S], lr = lr)\n\n    for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = -traced_getELBO(pln.S, pln.X, pln.B, pln.O, pln.M,\n            pln.n, pln.Omega, pln.Y, pln.p)\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        pln.Sigma = traced_getSigma(pln.n, pln.M, pln.S)\n        pln.Omega = traced_getInv(pln.Sigma)\n\n        objective = -loss.item()\n        ELBO[i] = objective\n        \n    return ELBO\nand run the learning process:\n%%time\ntraceELBO = tracefit(mytracePLN, N_iter, lr = lr, tol = 1e-8)\nCPU times: user 25.6 s, sys: 171 ms, total: 25.8 s\nWall time: 26.5 s"
  },
  {
    "objectID": "jit-example-pln.html#conclusion",
    "href": "jit-example-pln.html#conclusion",
    "title": "JIT with pytorch",
    "section": "",
    "text": "We check that we get the same results with each method:\nplt.plot(np.log(-myPLN.ELBO), label='NO jit')\nplt.plot(np.log(-scriptELBO), label='jit script')\nplt.plot(np.log(-traceELBO), label='jit trace')\nplt.legend()\nplt.show()\n\n\n\nelbo_graph.png\n\n\n\nWe see that jit script and jit trace reduce computation time by a few second over the non jitted code. Hence, jit compilation in pytorch can be interesting but induces strict limitations that the user must be aware of.\nWe should try to consider a more involved problem computationally speaking (bigger input data, computations involving neural networks, ‚Ä¶)"
  },
  {
    "objectID": "Intel_MKL.html",
    "href": "Intel_MKL.html",
    "title": "Intel MKL & Open Blas",
    "section": "",
    "text": "Nous allons d‚Äôabord installer les librairies Intel MKL (processeur Intel n√©cessaire) & Open Blas. Ces deux librairies d‚Äôalg√®bre lin√©aire permettent d‚Äôoptimiser et/ou de parall√©liser un certains nombre d‚Äôop√©rations alg√©briques, notamment le calcul matriciel.\nNous les testons avec un produit matriciel de 10000 x 10000.\n\nsize &lt;- 10000\nmat &lt;- matrix(rnorm(size**2), size, size)\n\ntic()\nget_res &lt;- mat %*% mat\ntoc()\n\nAvant l‚Äôinstallation les librairies utilis√©es pour du calcul matriciel en R sont libblas.so.3.10.0 et liblapack.so.3.10.0 (on peut les voir avec la ligne suivante)\n\nsessionInfo()\n\n\nInstallation sur Windows (seulement Intel MKL)\nLe plus simple est de t√©l√©charger les librairies Intel - MKL sur le seafile d‚ÄôAgroparistech.\n\n1 - Faire une copie de la version actuelle de BLAS et LAPACK:\nDans le dossier C:\\Program Files\\R\\Your_R_Version\\bin\\x64, copier Rblas.dll et Rlapack.dll dans un autre dossier √† conserver pour pouvoir revenir aux librairies de la base R.\n\n\n2 - T√©l√©charger les librairies Intel-MKL\nEn allant sur https://seafile.agroparistech.fr/d/696def33ceb848508cb0/ et en cliquant sur le boutton vert ZIP en haut √† droite, vous pouvez t√©l√©charger le dossier. Puis le d√©ziper.\n\n\n\n3 - Copier les biblioth√®ques\nLorsque le dossier est d√©compress√©, allez dans \\Intel-MKL-Libs\\Intel_MKL et copiez tous les fichiers dans votre C:\\Program Files\\R\\Your_R_Version\\bin\\x64.\n\n\n4 - R√©ouverture de R\nVous pouvez fermer votre session R et la rouvrir. Maintenant votre session R devrait fonctionner avec Intel-MKL. V√©rifiez si vous avez gagn√© en efficacit√© sur votre ordinateur. Attention, le code d√©j√† parall√©lis√© pourrait √™tre moins efficace car ces biblioth√®ques parall√©lisent d√©j√† l‚Äôalg√®bre lin√©aire.\nConcr√®tement on remplace les deux fichiers faisant appel aux librairies BLAS et LAPACK par des fichiers du m√™me nom mais qui en pratique font implicitement appel √† mkl. Pensez bien √† sauver une copie des fichiers initiaux.\nPour retourner √† la base R il suffit d‚Äôop√©rer √† l‚Äôop√©ration inverse, copie des fichiers Rblas.dll, Rlapack.dll et libiomp5md.dll du dossier C:\\Program Files\\R\\Your_R_Version\\bin\\x64. Les mettre en s√©curit√© puis copier les librairies des Rblas.dll et Rlapack.dll depuis votre sauvegarde ou https://seafile.agroparistech.fr/d/696def33ceb848508cb0/.\n\n\n\nInstallation sur Ubuntu 22.04 (Intel MKL et Open Blas)\n\nIntel MKL\nsudo apt install intel-mkl\n\n\nOpen Blas\nsudo apt install libopenblas-base\n\n\nChangement de librairie\nPour changer la librairie Blas\nsudo update-alternatives --config libblas.so.3-x86_64-linux-gnu\nPour changer la librairie Lapack\nsudo update-alternatives --config liblapack.so.3-x86_64-linux-gnu\nDans les deux cas cela ouvre un menu montrant les diff√©rentes librairies disponibles.\n\n\n\nComparaison produit matriciel (BLAS)\nUne fois install√©es, v√©rifier si les librairies sont bien r√©f√©renc√©es pour le calcul matriciel avec\n\nsessionInfo()\n\n\ntic()\nget_res &lt;- mat %*% mat\ntoc()\n\n\n\n\n\n\n\n\n\n\n\nSyst√®me d‚Äôexploitation\nLibrary\nCPU\nBase R\nIntel MKL\n\n\n\n\nWindows 10\nIntel MKL\nIntel Xeon - 16 processeur logiques\n15 min\n7 secondes\n\n\nUbuntu 22.04\nIntel MKL\nIntel i7 - 8 processeur logiques\n5 min\nMoins de 1 min\n\n\nUbuntu 22.04\nOpen Blas\nIntel i7 - 8 processeur logiques\n5 min\n9-14 secondes\n\n\n\n\n\nBenchmark approfondi\nNous allons comparer les performances de toutes ces librairies sur Ubuntu avec un ordinateur √† 8 c≈ìurs Intel I7. Pour effectuer ce benchmark nous devons r√©it√©rer les fermetures de sessions donc le m√™me code √† √©t√© lanc√© s√©quentiellement.\n\nSet-up\n\nPackages\n\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(furrr)\nlibrary(future)\nlibrary(tictoc)\n\n\n\nFonctions de test\n\ntest_type &lt;- function(seed, type = 'type'){\n  res &lt;- data.frame(seed = rep(0,2), \n                    time = rep(0,2), \n                    type = rep(0,2),\n                    matrix_size = rep(0,2))\n  matrix_size &lt;- c(200, 2000)\n  for(j in 1:2){\n      set.seed(seed)\n      mat = matrix(rnorm(matrix_size[[j]] ^ 2), ncol = matrix_size[[j]])\n      T1 = Sys.time()\n      res_tmp = mat %*% mat\n      T2 = Sys.time()\n      res$seed[[j]] &lt;- seed\n      res$time[[j]] &lt;- difftime(T2, T1)\n      res$type[[j]] &lt;- type\n      res$matrix_size[[j]] &lt;- matrix_size[[j]]\n  }\n  return(res)\n}\n\ncompare &lt;- function(seeds,type = 'type'){\n  if(type == \"base\"){\n    plan(multisession, workers = availableCores())\n    future_map_dfr(seeds,~test_type(.x,type = type))\n  }else{\n    map_dfr(seeds,~test_type(.x,type = type))\n  }\n}\n\nmy_multiplot &lt;- function(data){\n  ggplot(data = data,\n       aes(x = time, y = type, fill = type,col = type)) +\n  geom_boxplot(alpha = 0.5,show.legend = F) +  \n  facet_wrap(\"matrix_size\",scales = \"free_x\",labeller = label_both)\n}\n\n\n\nParam√®tres\n\ntypes &lt;- c(\"base\",\"openblas\",\"lasy_intel_mkl\",\"intel_mkl_high_perf\")\nseeds &lt;- 1:20\n\n\n\nS√©lection de la librarie active\n\ntype &lt;- types[[1]]\n\n\n\nCalculs et sauvegarde\n\nres &lt;- compare(seeds,type)\n\nsaveRDS(res, file = paste0('res_algebrica_calculations/res_',type,'.RDS'))\n\n\n\nChargement des r√©sultats\n\nlist_of_results &lt;- grep(\"^res_algebrica_calculations/res_.*.RDS$\",\n                        dir(recursive = T),\n                        value=T)\nres_table &lt;- map_dfr(list_of_results,readRDS)\n\n\n\nGraph des r√©sultats complets\nOn peut voir dans ces graphiques que dans l‚Äôensemble OpenBlas et Intel-MKL sont plus efficaces que la base de R. Cependant d‚Äôautres remarques sont √† faire :\n\nOpenBlas est utilise constamment l‚Äôensemble des c≈ìurs disponibles, ce comportement extr√™me peu devenir un probl√®me lors des longs calculs o√π lorsque l‚Äôon utilise des librairies plus complexes comme par exemple Rcpp avec laquelle il obtiens des performances largement plus faible que la base.\nNous avons aussi remarqu√© une certaine variations dans les performances de Intel-MKL sur Ubuntu seulement. Bien que toujours observ√©e plus efficace que la base. Il est fr√©quent que pour un m√™me calcul le temps soit jusqu‚Äô√† 4 fois plus long que le minimum. Cette variation semble √™tre fixe pour chaque session R ouverte. Dans ces graph nous appelons ‚Äúlasy intel mkl‚Äù les sessions de faible performances.\n\n\nmy_multiplot(res_table)\n\n\n\n\n\n\nSans la base R\n\nres_table %&gt;% \n  filter(type != \"base\") %&gt;% \n  my_multiplot()\n\n\n\n\n\n\n\n\nR√©f√©rences\n\nhttps://www.intel.com/content/www/us/en/docs/onemkl/get-started-guide/2023-0/overview.html\nhttps://www.openblas.net/\nhttps://github.com/xianyi/OpenBLAS/wiki/faq"
  },
  {
    "objectID": "Readme.html",
    "href": "Readme.html",
    "title": "Ateliers Finist‚ÄôR 2023",
    "section": "",
    "text": "Ateliers Finist‚ÄôR 2023\n\n\n\nwebsite\n\n\nL‚Äôatelier Finist‚ÄôR 2023 ‚Äì ou bootcamp R s‚Äôest d√©roul√© √† la station biologique de Roscoff du 21 au 25 ao√ªt 2023.\nIl s‚Äôagit de la septi√®me √©dition de l‚Äôatelier Finist‚ÄôR. Cet atelier r√©unit annuellement un groupe de chercheurs, ing√©nieurs, doctorants, tous utilisateurs avanc√©s de R et d√©velopeurs de paquets pour explorer les derni√®res fonctionalit√©s du logiciel et les nouvelles pratiques de d√©veloppement. A l‚Äôissu de l‚Äôatelier le collectif produit une synth√®se de cette veille logiciel de mani√®re √† progresser collectivement dans l‚Äôutilisation du logiciel mais surtout dans la production d‚Äôoutils statistiques √† destination de la communaut√©.\nLa restitution se fait sous forme de site web. Le site de l‚Äô√©dition 2023 sera disponible ici"
  },
  {
    "objectID": "learnr.html",
    "href": "learnr.html",
    "title": "Nouveaut√©s {learnr}",
    "section": "",
    "text": "Introduction\nNous allons ici pr√©senter les nouveaut√©s du package {learnr} qui permet de cr√©er des tutoriaux interactifs. {learnr} avait d√©j√† √©t√© discut√© durant la semaine Finist‚ÄôR 2020\n{learnr} repose sur {shiny}. Le tutoriel est construit √† partir d‚Äôun fichier Rmarkdown et peut √™tre soit execut√© en local via le bouton run app soit en d√©ployant le fichier sur un serveur Shiny.\nDepuis 2020 environ, il est possible d‚Äôint√©grer un tutoriel {learnr] dans un package, ce qui rend les classiques vignettes interactives. Les nouvelles versions de RStudio ont de plus inclus un bouton tutorial disponible dans le panel ‚ÄúEnvironnement, Git etc‚Ä¶‚Äù.\nL‚Äôid√©e est de partager un tutoriel facilement √† une large audience et pour cela il est maintenant possible de les int√©grer dans un package. Cela peut √™tre int√©ressant pour des tutoriaux √† destination d‚Äô√©tudiants mais √©galement pour des tutoriaux √† int√©grer dans les packages que vous d√©veloppez pour rendre l‚Äôinitiation aux m√©thodes d√©velopp√©es plus interactives qu‚Äôune vignette.\nL‚Äôavantage technique d‚Äôint√©grer un tutoriel {learnr} dans un package est qu‚Äôil est alors possible, apr√®s avoir install√© le package, d‚Äôex√©cuter le tutoriel en local sans avoir √† le d√©ployer sur un serveur Shiny. C‚Äôest donc gratuit et simple d‚Äôutilisation.\nA noter qu‚Äôil n‚Äôest pas n√©cessaire que le package contenant le tutoriel soit d√©pos√© sur le CRAN ou autre, qu‚Äôil contienne d‚Äôautres fichiers que le tutoriel. Tout est donc possible.\nLes √©tapes pour cr√©er un package contenant un tutoriel:\n\nSi le package n‚Äôest pas d√©j√† cr√©√©:\n\n\nusethis::create_package(\"&lt;path_to_folder/name_of_package&gt;\")\n\n\nPour cr√©er le fichier du tutoriel:\n\n\nusethis::use_tutorial(\"&lt;name-of-learnr-file&gt;\", \"&lt;Title You'd Like the User to See&gt;\")\n\n\nPuis dans RStudio, cliquer sur ‚ÄúBuild &gt; Install and Restart‚Äù.\nSi n√©cessaire, rajouter le package {gradethis} (noter la fonction de {usethis} sp√©cifique pour les install de package en d√©veloppement),\n\n\nusethis::use_dev_package(\"gradethis\")\n\n\nSi n√©cessaire, rajouter les packages pr√©sent sur le CRAN toujours avec {usethis}\n\n\nusethis::use_package(\"palmerpenguins\")\n\n\nSi n√©cessaire, √©diter le fichier DESCRIPTION\nEx√©cuter usethis::use_readme_rmd() pour rajouter un fichier README. puis compiler le tout.\nD√©poser le package sur gitlab ou github puis partager le repository qui peut √™tre install√© avec les lignes de code suivantes:\n\n\ndevtools::install_github(\"&lt;your-repo&gt;/&lt;package-name&gt;\")\ndevtools::install_gitlab(\"&lt;your-repo&gt;/&lt;package-name&gt;\")\n\n\nLorsque le package est install√©, aller dans le panel Tutorial dans RStudio et c‚Äôest parti‚Ä¶\nQuelques outils utiles.\n\nIl est possible de cha√Æner des chunks en utilisant la fonctionnalit√© exercise.setup dans les chunks. Par exemple, nous pouvons effectuer\n```{r exo1,exercise=TRUE}\n\n```\n```{r exo1-solution}\nx = 2+1\n```\n```{r exo2,exercise=TRUE,exercise.setup=\"exo1-solution\"}\n\n```\n```{r exo2-solution,exercise.setup=\"exo1-solution\"}\ny = x *3\n```\n```{r exo3,exercise=TRUE,exercise.setup=\"exo2-solution\"}\n\n```\netc.\nLe package {gradethis} permet de v√©rifier les solutions propos√©es √† un exercice. Par exemple,\nL‚Äôexercice consiste √† faire 2+3\n```{r exo3}\n\n```\n```{r exo3-solution}\n2+3\n```\non ajoute un chunk pour v√©rifier que le code est le bon (mais cela demande que la solution propos√©e contienne le m√™me code que dans la solution)\n```{r exo3-code-check}\ngrade_this_code()\n```\nsinon on peut simplement v√©rifier la sortie du code propos√© par l‚Äôutilisateur :\n```{r exo3-check}\ngrade_result(\n  pass_if(~identical(.result, 5))\n)\n```\n\n\nR√©f√©rences\n\nhttps://rstudio.github.io/learnr/\nhttps://education.rstudio.com/blog/2020/09/delivering-learnr-tutorials-in-a-package/"
  },
  {
    "objectID": "jax-getting-started.html",
    "href": "jax-getting-started.html",
    "title": "Premiers pas avec jax",
    "section": "",
    "text": "Le but de cette vignette est d‚Äôimpl√©menter une r√©gression logistique et/ou une r√©gression multivari√©e avec JAX."
  },
  {
    "objectID": "jax-getting-started.html#pr√©liminaires",
    "href": "jax-getting-started.html#pr√©liminaires",
    "title": "Premiers pas avec jax",
    "section": "Pr√©liminaires",
    "text": "Pr√©liminaires\n\nInstallation\n\nConda\nJax est disponible dans le channel conda-forge et peut donc s‚Äôinstaller dans un environnement conda\n#| eval: true\nconda create -n jax\nconda activate jax\n## Install the CPU version\nconda install jax -c conda-forge\n## Install packages necessary for the render\nconda install nbclient nbformat ipykernel\nPour des instruction d√©taill√©es pour l‚Äôinstallation en mode GPU ou TPU, se r√©f√©rer √† la documentation officielle.\nIl suffit alors d‚Äôactiver l‚Äôenvironnement jax pour produire le html √† partir du qmd\n#| eval: false\nconda activate jax\nquarto render my_document.qmd --to html\n\n\nPip\nSi vous pr√©f√©rez une installation via pip (pour une version cpu),\n#| eval: false\npip3 install jax jaxlib\nPour une installation GPU (avec cuda 12 par exemple, on vous laisse g√©rer la compatibilit√© de vos driver Nvidia and Cie),\n#| eval: false\npip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\nL‚Äôutilisation de venv est recommandable (mais non obligatoire).\nOn installe √©galement optax pour avoir acc√®s √† des optimiseurs.\n#| eval: false\npip3 install optax\nImportant Pour utiliser optax, il vaut mieux utiliser pip pour installer jax et jaxlib, les versions disponibles dans les d√©p√¥ts conda sont en effet trop anciennes pour optax."
  },
  {
    "objectID": "jax-getting-started.html#premiers-pas",
    "href": "jax-getting-started.html#premiers-pas",
    "title": "Premiers pas avec jax",
    "section": "Premiers pas",
    "text": "Premiers pas\n\nPhilosophie\nEn quelques mots, JAX est une biblioth√®que Python d√©velopp√©e par Google et initialement utilis√©e dans TensorFLow. Elle permet de faire de l‚Äôalg√®bre lin√©aire √† la numpy, avec 2 propri√©t√©s cl√©s la rendant extr√™mement performante:\n\nun autograd permettant la diff√©renciation automatique de calcul Python/Numpy\nun compileur pour GPU et autres (XLA), d√©di√© √† l‚Äôalg√®bre lin√©aire qui permet d‚Äôoptimiser les temps d‚Äôex√©cution gr√¢ce √† une approche JIT (Just-in Time, c‚Äôest-√†-dire une optimisation du code √† l‚Äôex√©cution et non pas avant l‚Äôappel comme avec un compileur classique).\n\nL‚Äôobjectif de la biblioth√®que est de proposer une exp√©rience utilisateur aussi proche que possible de calculs √† la Numpy, notamment √† l‚Äôaide de d√©corateurs Python. N√©anmoins, pour acc√©der pleinement aux capacit√©s de JAX, un certain nombre de contraintes d‚Äô√©criture des programmes s‚Äôappliquent, que nous allons essayer de pr√©senter pas √† pas.\n\n\nImport de la biblioth√®que\nL‚Äôimport complet/standard est le suivant:\n\nimport jax.numpy as jnp\nfrom jax import grad, jit, vmap\nfrom jax import random\nimport optax\nimport matplotlib.pyplot as plt\n\nOn peut d√©tailler les fonctionnalit√©s des modules comme suit:\n\nle module jax.numpy, aka jnp, porte les op√©rations matricielles usuelles de mani√®re quasi transparente\nle module random d√©finit les outils de g√©n√©ration de nombres al√©atoires, propres √† JAX et tr√®s diff√©rents de Numpy\nle module grad g√®re l‚Äôautodiff√©renciation\nle module jit g√®re la ‚Äújust-in time‚Äù compilation (acc√©l√©ration du code)\nle module vmap permet de vectoriser automatiquement certaines op√©rations\n\n\n\nJax.numpy: interface Alg√®bre lin√©aire haut-niveau\nOn commence par simuler des donn√©es al√©atoires via les outils de jax. Attention la gestion de la cl√© al√©atoire est explicite. Apr√®s avoir cr√©√© une cl√© et avant chaque appel √† une fonction al√©atoire, il faut faire √©voluer la graine √† la main\n\nkey,subkey = random.split(key, 2)\n\net utiliser subkey (les sous-cl√©s) dans l‚Äôappel √† la fonction al√©atoire (ou aux fonctions al√©atoire) comme √©crit ci-dessous.\n\nn = 10000\np = 100\nkey = random.PRNGKey(0)\nkey,sub1,sub2 = random.split(key, 3)\nones = jnp.ones((n, 1))\nx = random.normal(sub1, (n, p-1))\nx = jnp.concatenate([ones, x], axis = 1)\nbeta_true = random.normal(sub2, (p,1))\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\nAvant de les multiplier. On utilise ici la fonction block_until_ready() uniquement pour mesurer le temps effectif de calcul. En effet, JAX fait de l‚Äô√©valuation asynchrone (comme {future} en R) pour rendre la main √† l‚Äôutilisateur apr√®s l‚Äôenvoi de la commande.\n\n%timeit odds = jnp.dot(x, beta_true).block_until_ready()  # runs on the CPU\n\n196 ¬µs ¬± 5.51 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10,000 loops each)\n\n\nOn √©chantillonne ensuite des variables suivant une loi de Bernoulli.\n\nodds = jnp.dot(x, beta_true)\nkey,subkey = random.split(key, 2)\ny = random.bernoulli(subkey, odds)\n\net une perte logistique\n\\[\\ell(y, x, \\theta) = -\\log p(y; \\sigma(x^{\\top}\\theta)) = -y (x^\\top \\theta) + \\log(1 + e^{x^\\top \\theta})\\]\n\ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n\nQu‚Äôon peut tester sur un exemple simple\n\n## Should be log(2)\nlogistic_loss(True, 1.0, 0)\n\nArray(0.6931472, dtype=float32)\n\n\n\n\nJust-in-time compilation\nLa version normale de notre fonction logistique est d√©j√† rapide.\n\n%timeit logistic_loss(y, x, beta_true).block_until_ready()\n\n355 ¬µs ¬± 33.6 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n\n\nmais on peut l‚Äôacc√©lerer en compilant la fonction via le d√©corateur @jit ou la fonction jit() de fa√ßon compl√®tement transparente pour l‚Äôutilisateur.\n\n## Utilisation du d√©corateur @jit\n@jit \ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\n\n\n## Utilisation de jit()\nlogistic_loss_jit = jit(logistic_loss)\n%timeit logistic_loss_jit(y, x, beta_true).block_until_ready()\n\n270 ¬µs ¬± 3.38 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n\n\nLa diff√©rence n‚Äôest pas tr√®s importante dans cet exemple. jit() permet des gains d‚Äôautant plus importants qu‚Äôon travaille sur des fonctions complexes.\nAttention, il n‚Äôest pas toujours possible de jitter une fonction, en particulier, si cette fonction implique un branchement conditionnel:\n\ndef f(x):\n  if x &gt; 5:\n    return x\n  else:\n    return 2*x\n\nL‚Äôerreur provient du fait que la d√©finition de la fonction d√©pend de la valeur des entr√©es.\n\nf_jit = jit(f)\n## Renvoie une erreur\nf_jit(1)\n\nTracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function f at /tmp/ipykernel_1053/2514275982.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError\n\n\nComme l‚Äôindique le message d‚Äôerreur\nThis concrete value was not available in Python because it depends on the value of the argument x.\n\n\ngrad: auto-diff√©rentiation\nJAX permet de calculer le gradient d‚Äôune fonction via grad(). La syntaxe est diff√©rente de torch et plus proche de ce qu‚Äôon ferait dans une fonction math√©matique.\n\ndef loss(theta):\n  return logistic_loss(y, x, theta)\n\n\n## random start for theta\nkey,subkey = random.split(key, 2)\ntheta = random.normal(key, (p, 1))\ngrad_loss = grad(loss)\n\n\ngrad_loss = grad(loss)\n%timeit grad_loss(theta)\n\n11.7 ms ¬± 487 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\ngrad() peut-√™tre combin√© √† jit() dans tous les sens √† condition que les fonctions s‚Äôy pr√™tent.\n\ngrad_loss = jit(grad(loss))\n## Warmup to cache grad loss\ngrad_loss(theta).shape\n## Actual time recording\n%timeit grad_loss(theta)\n\n417 ¬µs ¬± 8.02 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n\n\nMais ce n‚Äôest pas toujours int√©ressant.\n\ngrad_loss = jit(grad(jit(loss)))\n## Warmup to cache grad loss\ngrad_loss(theta).shape\n## Actual time recording\n%timeit grad_loss(theta)\n\n423 ¬µs ¬± 12 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n\n\n\n\nVectorisation\nJAX permet enfin de vectoriser automatiquement des op√©rations de fa√ßon efficace (en faisant descendre la boucle √† l‚Äôint√©rieur de la fonction, au niveau des primitives utilis√©es pour le calcul).\nConsid√©rons un exemple simple o√π on veut calculer des logs-odds sur mesures r√©p√©t√©es.\n\n## Matrice de covariables, r√©p√©t√©es en temps \n## [temps, individu, variable]\nkey,subkey = random.split(key, 2)\nX = random.normal(key, (10, n, p))\ndef compute_odds(x, theta):\n  return jnp.dot(x, theta)\ndef compute_odds_batched(X,  theta):\n  return jnp.stack([compute_odds(x, theta) for x in X]) \n\nEt testons ce qui se passe. On appelle la fonction sur une tranche de X\n\n%timeit compute_odds(X[:1,:, :], beta_true)\n\n3.86 ms ¬± 80.8 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n\n\nPuis sur toutes les tranches de X avec notre fonction vectoris√©e manuellement.\n\n%timeit compute_odds_batched(X, beta_true)\n\n18 ms ¬± 438 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n\n\nPuis sur toutes les tranches de X avec notre fonction vectoris√©e via vmap().\n\ndef compute_odds_batched_vmap(X,  theta):\n  def f(x):\n    return compute_odds(x, theta)\n  return vmap(f)(X)\n\n\ncompute_odds_batched_vmap(X, beta_true).shape\n\n(10, 10000, 1)\n\n\n\n%timeit compute_odds_batched_vmap(X, beta_true)\n\n16.2 ms ¬± 585 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n\n\n√Ä comparer √† la version native jax qui est d√©j√† nativement vectoris√©e pour cette op√©ration\n\n%timeit compute_odds(X, beta_true)\n\n14.7 ms ¬± 694 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n\n\nLe gain n‚Äôest pas tr√®s important dans cette exemple pr√©cis mais on se rapproche quand m√™me de la performance de la version native, par rapport √† notre vectorisation manuelle."
  },
  {
    "objectID": "jax-getting-started.html#optimisation-de-la-fonction-objective",
    "href": "jax-getting-started.html#optimisation-de-la-fonction-objective",
    "title": "Premiers pas avec jax",
    "section": "Optimisation de la fonction objective",
    "text": "Optimisation de la fonction objective\n\n√Ä la main\nContrairement √† torch, on n‚Äôa pas d‚Äôoptimiseur d√©fini cl√© en main dans JAX. La d√©riv√©e est n√©anmoins une fonction comme les autres et on peut donc √©crire tr√®s simplement un algorithme simple de descente de gradient.\n\n%%time\nnum_iterations = 50\nloss_vector = []\n## Learning rate\nlr = 0.001\n## Initialisation de theta\ntheta = jnp.zeros(p)\n## Fonction de perte, en mode jit\n@jit\ndef loss(theta):\n  return logistic_loss(y, x, theta)\n## Gradient de la fonction de perte, en mode jit\ngrad_loss = jit(grad(loss))\n\n## Descente de gradient\nfor i in range(num_iterations):\n    # Suivi de la fonction de perte\n    loss_vector.append(loss(theta))\n    # Mise √† jour du param√®tre\n    theta = theta - lr * grad_loss(theta) \n\nCPU times: user 320 ms, sys: 21.9 ms, total: 342 ms\nWall time: 341 ms\n\n\nEt on peut v√©rifier que la fonction de perte d√©croit au cours du temps.\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\nEt que les param√®tres de r√©gression estim√©s se rapprochent des vraies valeurs\n\nplt.plot(beta_true, theta, marker='o', linestyle=\"none\")\nplt.plot([-3, 3], [-3, 3], color='r', linestyle='-', linewidth=2)\nplt.xlabel('True parameter')\nplt.ylabel('Estimated parameter')\nplt.title('Estimated versus true parameter')\nplt.show()\n\n\n\n\n\n\nAvec Optax\nOn peut n√©anmoins utiliser la librairie optax pour d√©finir des optimiseurs comme en torch. On va utiliser ici Adam.\n\nFonction objective\nOn commence par d√©finir la fonction objective avec un ordre pr√©cis pour les arguments:\n\nparam√®tres √† optimiser (typiquement \\(\\theta\\), les coefficients de r√©gression)\nparam√®tres additionels (p√©nalit√©s, etc)\ndonn√©es (avec le mot cl√© data)\n\n\ndef logistic_loss(y, x, theta):\n  odds = jnp.dot(x, theta)\n  return -jnp.vdot(y, odds) + jnp.sum(jnp.log(1.0 + jnp.exp(odds)))\ndef objective_and_grad(params, penalty, data):\n  x = data[:, :-1]\n  y = data[:, -1]\n  def loss(params):\n    return logistic_loss(y, x, params)\n  loss_value = loss(params)\n  loss_grad = grad(loss)(params)\n  return [loss_value, loss_grad]\n\n\n\nIt√©rateur de donn√©es\nAdam est un algorithme d‚Äôoptimisation stochastique. On d√©finit donc un it√©rateur qui va √©chantillonner les donn√©es.\n\nbatch_size = 100\nn_iter = 1000\n# key, subkey = random.split(key, 2)\ndef data_iterator(key, data):    \n    return random.choice(key, data, (batch_size, ), replace = False)\n\n\n\nOptimisation\nOn d√©finit enfin une fonction de fit qui travaille sur des batchs.\n\ndef fit(data, params, optimizer, key):\n  opt_state = optimizer.init(params)\n  loss_vector = []\n\n  @jit\n  def step(params, opt_state, batch):\n    loss_value, grads = objective_and_grad(params, 0, batch)\n    updates, opt_state = optimizer.update(grads, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, opt_state, loss_value\n\n  for i in range(n_iter):\n    key, subkey = random.split(key, 2)\n    batch = data_iterator(subkey, data)\n    params, opt_state, loss_value = step(params, opt_state, batch)\n    loss_vector.append(loss_value.item())\n    if i % 100 == 0:\n      print(f'step {i}, loss: {loss_value}')\n\n  return [params, loss_vector]\n\nFinalement, on peut ajuster notre fonction param√©tr√©e en utilisant l‚Äôoptimiseur Adam fourni par optax.\n\n%%time \ninitial_params = jnp.zeros((x.shape[1], ))\noptimizer = optax.adam(learning_rate=1e-2)\ndata = jnp.concatenate([x, y], axis = 1)\nparams,loss_vector = fit(data, initial_params, optimizer, key)\n\nstep 0, loss: 69.3147201538086\nstep 100, loss: 18.580368041992188\nstep 200, loss: 12.382568359375\nstep 300, loss: 11.707901000976562\nstep 400, loss: 8.840866088867188\nstep 500, loss: 10.6444091796875\nstep 600, loss: 8.130218505859375\nstep 700, loss: 8.6331787109375\nstep 800, loss: 8.014801025390625\nstep 900, loss: 5.246734619140625\nCPU times: user 10.4 s, sys: 375 ms, total: 10.8 s\nWall time: 10.3 s\n\n\nOn peut v√©rifier que la fonction objective converge sans d√©cro√Ætre syst√©matiquement,\n\nplt.plot(range(1, n_iter+1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\net que les param√®tres sont proches des bonnes valeurs.\n\nplt.plot(beta_true, params, marker='o', linestyle=\"none\")\nplt.plot([-3, 3], [-3, 3], color='r', linestyle='-', linewidth=2)\nplt.xlabel('True parameter')\nplt.ylabel('Estimated parameter')\nplt.title('Estimated versus true parameter')\nplt.show()"
  },
  {
    "objectID": "issue_reprex.html",
    "href": "issue_reprex.html",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "",
    "text": "L‚Äôobjectif de ce billet est de pr√©senter des conseils pour √©crire une issue pour demander des am√©liorations ou soumettre des bugs dans un code d√©pos√© sur GitHub."
  },
  {
    "objectID": "issue_reprex.html#objectif",
    "href": "issue_reprex.html#objectif",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "",
    "text": "L‚Äôobjectif de ce billet est de pr√©senter des conseils pour √©crire une issue pour demander des am√©liorations ou soumettre des bugs dans un code d√©pos√© sur GitHub."
  },
  {
    "objectID": "issue_reprex.html#recommandations",
    "href": "issue_reprex.html#recommandations",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Recommandations",
    "text": "Recommandations\nLes recommandations propos√©es sur les d√©p√¥ts des packages du tidyverse :\n\nInclure un exemple minimal reproductible, dit reprex.\n\nLire What is a reprex pour plus de d√©tails.\n\nSi les donn√©es sont confidentielles, utiliser des donn√©es disponibles dans modeldata, simuler des donn√©es ou anonymiser les donn√©es.\nUtiliser des graines set.seed()\nV√©rifier sur les blogs ou forums que le probl√®me n‚Äôa pas d√©j√† √©t√© signal√© ou r√©gl√©.\n\nD‚Äôautres recommandations sont propos√©es dans le cas d‚Äôutilisation de calculs parall√®les."
  },
  {
    "objectID": "issue_reprex.html#structure-de-lissue",
    "href": "issue_reprex.html#structure-de-lissue",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Structure de l‚Äôissue",
    "text": "Structure de l‚Äôissue\n\nPr√©senter en premier le probl√®me (‚ÄúI‚Äôm having trouble with ‚Ä¶‚Äù)\nDonner un exemple reproductible dans un format adapt√©.\n\nUn bon exemple de report de bug #46."
  },
  {
    "objectID": "issue_reprex.html#exemple-reproductible-avec-le-package-reprex",
    "href": "issue_reprex.html#exemple-reproductible-avec-le-package-reprex",
    "title": "Partager un exemple reproductible dans une issue GitHub",
    "section": "Exemple reproductible avec le package {reprex}",
    "text": "Exemple reproductible avec le package {reprex}\nIl est possible de cr√©er un exemple reproductible avec le package {reprex} qui produit une sortie bien format√©e notamment pour GitHub, et que l‚Äôon peut ensuite faciler copier/coller.\nSi le code est un peu long, faire un script, par exemple mon_probleme.R\nIl suffit ensuite d‚Äôutiliser la fonction reprex du package du m√™me nom avec les options de son choix. Par exemple reprex(input = 'mon_probleme.R', session_info = TRUE).\nL‚Äôoption session_info = TRUE permet de r√©cuperer les informations sur notre session R.\nLa fonction g√©n√®re un fichier markdown (mon_probleme.md) dans le cas de l‚Äôutilisation d‚Äôun script directement int√©grable dans l‚Äôissue et ouvre √©galement par d√©faut le rendu dans le viewer de RStudio ou un navigateur (peut se modifier avec l‚Äôargument html_preview = FALSE).\nPetit exemple plus court (sans utilisation de script ext√©rieur) issu du package {reprex} :\n\nlibrary(reprex)\nreprex(rbinom(3, size = 10, prob = 0.5), session_info = TRUE, html_preview = FALSE)"
  },
  {
    "objectID": "R_INLA.html",
    "href": "R_INLA.html",
    "title": "R INLA",
    "section": "",
    "text": "Pr√©sentation de la m√©thodologie INLA (integrated nested Laplace approximation) en utilisant les packages {INLA} et sa surcouche {inlabru}.\nL‚Äôapproximation de Laplace int√©gr√©e et imbriqu√©e (INLA) est une approche de l‚Äôinf√©rence statistique pour les mod√®les de champs al√©atoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et d√©terministe au MCMC qui √©tait l‚Äôoutil standard pour l‚Äôinf√©rence de tels mod√®les. Le principal avantage de l‚Äôapproche INLA par rapport √† la MCMC est qu‚Äôelle est beaucoup plus rapide √† calculer.\n{inlabru} est une surcouche du package INLA, qui facilite l‚Äôutilisation du package R {INLA} en simplifiant la syntaxe. Ce package int√®gre deux extensions :\n\nMod√®les de type GAM (pour int√©grer des pr√©dicteurs non lin√©aires)\nProcessus de Cox log-Gaussien pour mod√©liser des processus univari√©s et spatiaux bas√©s sur des donn√©es de comptages.\n\nSources :\n\nhttps://www.r-inla.org/home\nhttps://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf\nhttps://sites.google.com/inlabru.org/inlabru/home\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "R_INLA.html#introduction",
    "href": "R_INLA.html#introduction",
    "title": "R INLA",
    "section": "",
    "text": "Pr√©sentation de la m√©thodologie INLA (integrated nested Laplace approximation) en utilisant les packages {INLA} et sa surcouche {inlabru}.\nL‚Äôapproximation de Laplace int√©gr√©e et imbriqu√©e (INLA) est une approche de l‚Äôinf√©rence statistique pour les mod√®les de champs al√©atoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et d√©terministe au MCMC qui √©tait l‚Äôoutil standard pour l‚Äôinf√©rence de tels mod√®les. Le principal avantage de l‚Äôapproche INLA par rapport √† la MCMC est qu‚Äôelle est beaucoup plus rapide √† calculer.\n{inlabru} est une surcouche du package INLA, qui facilite l‚Äôutilisation du package R {INLA} en simplifiant la syntaxe. Ce package int√®gre deux extensions :\n\nMod√®les de type GAM (pour int√©grer des pr√©dicteurs non lin√©aires)\nProcessus de Cox log-Gaussien pour mod√©liser des processus univari√©s et spatiaux bas√©s sur des donn√©es de comptages.\n\nSources :\n\nhttps://www.r-inla.org/home\nhttps://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf\nhttps://sites.google.com/inlabru.org/inlabru/home\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "R_INLA.html#installation-de-inla",
    "href": "R_INLA.html#installation-de-inla",
    "title": "R INLA",
    "section": "Installation de INLA",
    "text": "Installation de INLA\n\n# Base de R INLA\ninstall.packages(\"INLA\",repos=c(getOption(\"repos\"),INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE)\n# inlabru wrapper\ninstall.packages(\"inlabru\")"
  },
  {
    "objectID": "R_INLA.html#utilisation",
    "href": "R_INLA.html#utilisation",
    "title": "R INLA",
    "section": "Utilisation",
    "text": "Utilisation\n\nExemple 1\n\nSetup\n\n# Chargement des packages\nlibrary(INLA)\nlibrary(inlabru)\nlibrary(lme4) # pour comparer avec l'approche frequentiste \nlibrary(ggplot2)\nlibrary(ggpolypath)\nlibrary(RColorBrewer)\nlibrary(geoR)\nlibrary(tidyverse)\n\nLe dataset awards contient le nombre de r√©ussites (num_awards) en math (math) pour une classe de 200 √©l√®ves. La r√©ponse mesur√©e √©tant un comptage, nous devons sp√©cifier un mod√®le g√©n√©ralis√© avec fonction de lien Poisson.\n\n# Chargement des donnees\nload(\"data/awards.RData\")\nhead(awards)\n\n  num_awards       prog math id\n1          0 Vocational   41  1\n2          0    General   41  2\n3          0 Vocational   44  3\n4          0 Vocational   42  4\n5          0 Vocational   40  5\n6          0    General   42  6\n\n\nLa fonction bru_options_set permet de fixer des options sur des param√®tres sp√©cifiques √† INLA.\n\nbru_options_set(bru_verbose = TRUE,\n                control.compute = list(dic = TRUE, waic = TRUE))\n\nOn peut r√©cup√©rer ces param√®tres avec :\n\nbru_options_get()\n\n\n\nApplication\nNous expliquons le nombre de r√©compenses obtenues en fonction de la note en math suivant le mod√®le \\[Y_i\\overset{ind}{\\sim}\\mathcal{P}(\\exp(\\mu+\\alpha\\cdot x_i))\\,.\\]\n\n# Formulation du modele\ncmp1 &lt;- num_awards ~ math + 1\n# Application de la formule avec un mod√®le de Poisson\nfit.glm.bru &lt;- bru(cmp1, family = \"poisson\", data = awards)\n\niinla: Iteration 1 [max:1]\n\nsummary(fit.glm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.895, Running = 0.299, Post = 0.0329, Total = 1.23 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.086 0.010      0.067    0.086      0.105  0.086   0\nIntercept -5.349 0.591     -6.508   -5.349     -4.191 -5.349   0\n\nDeviance Information Criterion (DIC) ...............: 384.07\nDeviance Information Criterion (DIC, saturated) ....: 208.02\nEffective number of parameters .....................: 1.99\n\nWatanabe-Akaike information criterion (WAIC) ...: 384.48\nEffective number of parameters .................: 2.35\n\nMarginal log-Likelihood:  -204.02 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nComparaison avec un GLM\n\ncmp2 &lt;- num_awards ~ math\nfit2.glm &lt;- glm(cmp2, family=\"poisson\", data = awards)\nsummary(fit2.glm)\n\n\nCall:\nglm(formula = cmp2, family = \"poisson\", data = awards)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.333532   0.591261  -9.021   &lt;2e-16 ***\nmath         0.086166   0.009679   8.902   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 204.02  on 198  degrees of freedom\nAIC: 384.08\n\nNumber of Fisher Scoring iterations: 6\n\n\nLes r√©ponses sont proches.\n\n\nInt√©gration d‚Äôun effet al√©atoire\nPour prendre en compte le probl√®me classique de surdispersion dans les donn√©es de comptages, il peut √™tre int√©ressant de rajouter un effet al√©atoire de la mani√®re suivante.\n\\[Y_i\\overset{ind}{\\sim}\\mathcal{P}(\\exp(\\mu+\\alpha\\cdot x_i+E_i)) \\quad \\text{avec}\\quad E_i\\overset{ind}{\\sim}\\mathcal{N}(0,\\sigma^2).\\]\n\ncmp3 &lt;- num_awards ~ math + 1 + rand.eff(map = 1:200, model = \"iid\", n = 200)\n\nfit3.glmm.bru &lt;- bru(cmp3, family = \"poisson\", data = awards)\n\nWarning in inlabru:::component.character(\"rand.eff\", map = 1:200, model =\n\"iid\", : Use of 'map' is deprecated and may be disabled; use 'main' instead.\n\n\niinla: Iteration 1 [max:1]\n\nsummary(fit3.glmm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nrand.eff: main = iid(1:200), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.501, Running = 0.242, Post = 0.0684, Total = 0.811 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.086 0.010      0.067    0.086      0.105  0.086   0\nIntercept -5.349 0.591     -6.509   -5.349     -4.190 -5.349   0\n\nRandom effects:\n  Name    Model\n    rand.eff IID model\n\nModel hyperparameters:\n                           mean       sd 0.025quant 0.5quant 0.975quant   mode\nPrecision for rand.eff 19903.65 19900.90     563.99 13861.13   74196.19 187.82\n\nDeviance Information Criterion (DIC) ...............: 384.03\nDeviance Information Criterion (DIC, saturated) ....: 207.97\nEffective number of parameters .....................: 2.00\n\nWatanabe-Akaike information criterion (WAIC) ...: 384.47\nEffective number of parameters .................: 2.38\n\nMarginal log-Likelihood:  -204.09 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nComparaison avec l‚Äôapproche fr√©quentiste\n\ncmp4&lt;- num_awards ~ math + (1|id)\nfit4.glmm&lt;-glmer(cmp4, family = poisson, data = awards)\nsummary(fit4.glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: num_awards ~ math + (1 | id)\n   Data: awards\n\n     AIC      BIC   logLik deviance df.resid \n   381.2    391.1   -187.6    375.2      197 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.1653 -0.5518 -0.3760  0.3900  2.9242 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.3257   0.5707  \nNumber of obs: 200, groups:  id, 200\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.63163    0.70476  -7.991 1.34e-15 ***\nmath         0.08861    0.01161   7.634 2.28e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nmath -0.982\n\n\nOn remarque que les r√©sultats sont un peu moins comparables. Pour se rapprocher de glmer(), on peut modifier la loi a priori sur l‚Äôeffet al√©atoire.\n\ncmp5 &lt;- num_awards ~ math + 1 + rand.eff(map = 1:200, model = \"iid\", n = 200,\n                                                 hyper=list(prec=list(param=c(10,0.1),\n                                                                      prior=\"pc.prec\")))\nfit5.glmm.bru &lt;- bru(cmp5, family = \"poisson\", data = awards )\n\nWarning in inlabru:::component.character(\"rand.eff\", map = 1:200, model =\n\"iid\", : Use of 'map' is deprecated and may be disabled; use 'main' instead.\n\n\niinla: Iteration 1 [max:1]\n\nsummary(fit5.glmm.bru)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nmath: main = linear(math), group = exchangeable(1L), replicate = iid(1L)\nrand.eff: main = iid(1:200), group = exchangeable(1L), replicate = iid(1L)\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'poisson'\n    Data class: 'data.frame'\n    Predictor: num_awards ~ .\nTime used:\n    Pre = 0.451, Running = 0.243, Post = 0.0793, Total = 0.774 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nmath       0.090 0.012      0.067    0.089      0.113  0.089   0\nIntercept -5.651 0.692     -7.039   -5.641     -4.321 -5.621   0\n\nRandom effects:\n  Name    Model\n    rand.eff IID model\n\nModel hyperparameters:\n                       mean   sd 0.025quant 0.5quant 0.975quant mode\nPrecision for rand.eff 6.97 8.93       1.58     4.10      27.95 2.69\n\nDeviance Information Criterion (DIC) ...............: 380.37\nDeviance Information Criterion (DIC, saturated) ....: 204.31\nEffective number of parameters .....................: 29.47\n\nWatanabe-Akaike information criterion (WAIC) ...: 381.65\nEffective number of parameters .................: 26.02\n\nMarginal log-Likelihood:  -204.62 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\n\nExemple 2\nDans le jeu de donn√©es gorillas, on cherche √† comprendre la r√©partition de communaut√©s de gorilles dans une r√©gion donn√©e en fonction de facteurs (v√©g√©tations) ou de variable continue (altitude).\n\ndata(gorillas, package = \"inlabru\")\n\nOn importe l‚Äôobjet liste gorillas qui contient 4 sous-listes contenant les localisations d‚Äôhabitats de gorilles (nests), le maillage de la zone d‚Äôint√©r√™t (mesh), la fronti√®re du domaine (boundary) et les variables explicatives (gcov).\n\nnests &lt;- gorillas$nests\nmesh &lt;- gorillas$mesh\nboundary &lt;- gorillas$boundary\ngcov &lt;- gorillas$gcov\n\nsummary(gcov$vegetation)\n\nObject of class SpatialPixelsDataFrame\nCoordinates:\n       min      max\nx 580.1599 586.2320\ny 673.8742 679.0378\nIs projected: TRUE \nproj4string :\n[+proj=utm +zone=32 +datum=WGS84 +units=km +no_defs]\nNumber of points: 39600\nGrid attributes:\n  cellcentre.offset   cellsize cells.dim\nx          580.1737 0.02760054       220\ny          673.8885 0.02868664       180\nData attributes:\n      vegetation   \n Colonising:   48  \n Disturbed :23606  \n Grassland : 7001  \n Primary   : 7725  \n Secondary :  788  \n Transition:  432  \n\n\nLa construction du maillage peut se faire avec les fonctions de {INLA}:\n\ninla.mesh.2d(),\ninla.mesh.create(),\ninla.mesh.1d(),\ninla.mesh.basis(),\ninla.spde2.pcmatern().\n\nvoir la vignette suivante pour quelques exemples: https://inlabru-org.github.io/inlabru/articles/random_fields_2d.html.\n\nVisualisation des donn√©es gorilles\n\nggplot() +\n  gg(gcov$vegetation) +\n  gg(boundary) +\n  gg(nests, color = \"white\", cex = 0.5) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\n\nggplot() +\n  gg(gcov$vegetation) +\n  gg(mesh) +\n  gg(boundary) +\n  gg(nests, color = \"white\", cex = 0.5) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\nLes graphiques ci-dessus permettent de visualiser les diff√©rents types de v√©g√©tations ainsi que les localisations d‚Äôhabitat de gorilles dans la zone d‚Äô√©tude. Il est √©galement possible de rajouter le maillage construit sur la zone. {inlabru} propose la fonction gg() permettant avac la grammaire ggplot2 de rajouter les diff√©rentes couches d‚Äôinformations.\n\n\nMod√®le 1\nOn peut supposer un processus ponctuel spatial d‚Äôintensit√© \\[\\lambda(x,y)=\\exp(\\alpha_i(x,y))\\] o√π \\(\\alpha\\) est un param√®tre correspondant √† un type de v√©g√©tation (mod√©lisation factor full sans intercept donc).\n\ncomp1 &lt;- coordinates ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1\ncomp1alt &lt;- coordinates ~ vegetation(gcov$vegetation, model = \"factor_contrast\") + 1\n\nPour construire un mod√®le expliquant les comptages de gorilles avec leurs r√©partitions dans la zone d‚Äô√©tude et prenant en compte les types de v√©g√©tations, nous d√©finissons la formule avec:\n\ncoordinates() la fonction de {sp} de r√©cup√©ration des coordonn√©es des habitats dans l‚Äôobjet nests\nvegetation sera le mot utilis√© dans les sorties du mod√®le faisant r√©f√©rence √† la variable explicative gcov$vegetation (possible d‚Äô√©crire le mot que l‚Äôon veut‚Ä¶)\nmodel = \"factor_full\" est pour indiquer que la variable explicative est un facteur. Il est possible d‚Äôutiliser ‚Äúfactor_full‚Äù, ‚Äúfactor_contrast‚Äù etc‚Ä¶ suivant les types de contraintes que l‚Äôon souhaite appliquer au mod√®le. ‚Äúfactor_full‚Äù indique estimations de toutes les modalit√©s mais il faut alors supprimer l‚Äôintercept afin d‚Äô√™tre dans un cas identifiable.\n\nApr√®s avoir d√©fini la formule du mod√®le, on estime les param√®tres en utilisant la fonction lgcp() qui permet de mod√©liser un processus log-normalis√© de Cox. Cette fonction est une surcouche de la fonction de base bru().\nLe LGCP est un mod√®le probabiliste de processus ponctuel observ√© dans un tissu spatial ou temporel.\n\nfit1 &lt;- lgcp(components = comp1, # formule du mod√®le\n             data = nests,       # data set\n             samplers = boundary,  # fronti√®re de la zone d'√©tude\n             domain = list(coordinates = mesh) # maillage de la zone\n             )\n\niinla: Iteration 1 [max:1]\n\n\nfit1 estime l‚Äôintensit√© des pr√©sences de gorilles dans la zone d‚Äô√©tude. Il est alors possible de repr√©senter l‚Äôintensit√© moyenne de ces habitats:\n\npred.df &lt;- fm_pixels(mesh, mask = boundary, format = \"sp\")\nint1 &lt;- predict(fit1, pred.df, ~ exp(vegetation))\n\nggplot() +\n  gg(int1) +\n  gg(boundary, alpha = 0, lwd = 2) +\n  gg(nests, color = \"DarkGreen\") +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\nPour visualiser les r√©sultats du mod√®le, nous utilisons la fonction predict() (sans oublier de passer √† l‚Äôexponentielle) et fm_pixels() qui en prenant la zone d‚Äô√©tude (mesh + fronti√®re) cr√©e l‚Äôobjet spatial ad√©quat.\nNous remarquons que les intensit√©s sont les plus fortes dans la v√©g√©tation Primaire, ce qui est logique. Ici, l‚Äôintensit√© repr√©sente le nombre d‚Äôhabitats de gorilles par unit√© de surface. Attention donc √† comment vous d√©finissez les coordonn√©es de vos zones d‚Äô√©tudes.\nEn utilisant les fonctions fm_int()et predict() nous allons tenter d‚Äôestimer les abondances moyennes sachant que nous savons qu‚Äôil y a 647 habitats en r√©alit√©:\n\nips &lt;- fm_int(mesh, boundary)\nLambda1 &lt;- predict(fit1, ips, ~ sum(weight * exp(vegetation)))\nLambda1\n\n      mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err\n1 646.9817 26.31883 596.5334 646.8636 700.7959 646.8636        2.631883\n  sd.mc_std_err\n1      1.930196\n\n\n\n# Calcul de la surface de la zone\nsum(ips$weight) # some des surfaces de chaque triangle du mesh\n\n[1] 19.87366\n\nsf::st_area(sf::st_as_sf(boundary)) # surface totale \n\n19.87366 [km^2]\n\n\n\n\nMod√®le avec utilisation SPDE\nDans cette section, nous allons essayer d‚Äôexpliquer la r√©partition des habitats en rajoutant au facteur vegetation une mod√©lisation SPDE (Stochastic partial differential equations). Il faut pour cela compl√©ter la d√©finition du maillage par l‚Äôajout d‚Äôune structure de Mat√©rn en utilisant la fonction {INLA} inla.spde2.pcmatern() puis r√©√©crire la d√©finition de la formule du mod√®le INLA. Le mod√®le int√®gre alors un champ gaussien avec covariance de Mat√©rn. \\[\\lambda(x,y)=\\exp(\\alpha_i(x,y)+\\xi(x,y))\\] avec \\(\\xi\\) suivant un champ gaussien.\n\npcmatern &lt;- inla.spde2.pcmatern(mesh,\n  prior.sigma = c(0.1, 0.01),\n  prior.range = c(0.1, 0.01)\n)\n\ncomp2 &lt;- coordinates ~\n            -1 +\n            vegetation(gcov$vegetation, model = \"factor_full\") +\n            elevation(gcov$elevation) +\n            mySmooth(coordinates, model = pcmatern)\n\nfit2 &lt;- lgcp(components = comp2, \n             data = nests, \n             samplers = boundary, \n             domain = list(coordinates = mesh))\n\niinla: Iteration 1 [max:1]\n\n\nOn repr√©sente l‚Äôintensit√© m√©diane de la surface:\n\nint2 &lt;- predict(fit2, pred.df, ~ exp(mySmooth + vegetation), n.samples = 1000)\n\nggplot() +\n  gg(int2, aes(fill = q0.025)) +\n  gg(boundary, alpha = 0, lwd = 2) +\n  gg(nests) +\n  coord_equal()\n\nRegions defined for each Polygons\n\n\n\n\n\net l‚Äôintensit√© int√©gr√©e attendue (moyenne des abondances):\n\nLambda2 &lt;- predict(fit2,\n                   fm_int(mesh, boundary),\n                   ~ sum(weight * exp(mySmooth + vegetation)))\n\nLambda2\n\n       mean       sd     q0.025      q0.5   q0.975    median mean.mc_std_err\n1 0.7023356 1.328071 0.01070441 0.1432543 4.535278 0.1432543       0.1328071\n  sd.mc_std_err\n1     0.2729947\n\n\nExaminons les contributions au pr√©dicteur lin√©aire de la partie SPDE et de celle due √† la v√©gatation.\nLa fonction scale_fill_gradientn() d√©finit l‚Äô√©chelle pour la l√©gende du graphique. Dans cet exemple, on la d√©finit telle que cela prenne en compte toute la gamme de valeurs des 3 pr√©dicteurs lin√©aires. Par d√©faut, ce sont les m√©dianes qui sont repr√©sent√©es.\n\nlp2 &lt;- predict(fit2, \n               pred.df, ~ list(\n                        smooth_veg = (mySmooth + vegetation + elevation),\n                        not_smooth = (vegetation + elevation),\n                        smooth = (mySmooth),\n                        veg = (vegetation),\n                        ele = (elevation)\n              ))\n\nlprange &lt;- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median, lp2$ele$median, lp2$not_smooth$median)\n\nplot.lp2 &lt;- ggplot() +\n  gg(lp2$not_smooth) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"vegetation + elevation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.spde &lt;- ggplot() +\n  gg(lp2$smooth) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"mySmooth\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.veg &lt;- ggplot() +\n  gg(lp2$veg) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"vegetation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nplot.lp2.ele &lt;- ggplot() +\n  gg(lp2$ele) +\n  theme(legend.position = \"bottom\") +\n  gg(boundary, alpha = 0) +\n  ggtitle(\"elevation\") +\n  gg(nests, color = \"firebrick\") +\n  scale_fill_viridis_c(limits = lprange) +\n  coord_equal()\n\nRegions defined for each Polygons\n\nmultiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, plot.lp2.ele, cols = 2)\n\n\n\n\n\n\n\nExemple 3\nNous nous int√©ressons √† un jeu de donn√©es concernant la pr√©valence de la malaria en Gambie (disponible dans le package {geoR}). Cet exemple est repris du livre ‚ÄúSpatial and Spatio-temporal Bayesian Models with R-INLA‚Äù.\n\ndata(gambia, package = \"geoR\")\n# les coordonn√©es correspondent au village o√π se trouve les enfants\n# create one index for each of the 65 villages\nvillage_index &lt;- unite(gambia, col = \"lon_lat\", sep = \"_\", \"x\", \"y\") %&gt;% \n  pull(\"lon_lat\") %&gt;% \n  factor(labels = 1:65)\ngambia &lt;- gambia %&gt;%\n  add_column(village_index) \n\nOn transforme le jeu de donn√©es en type {SpatialPointsDataFrame}.\n\ngambia &lt;- gambia %&gt;%\n  mutate(x = x * 0.001, # to km\n         y = y * 0.001, # to km\n         age = age / 365) \ncoordinates(gambia) &lt;- c(\"x\", \"y\") \nclass(gambia)\n\n[1] \"SpatialPointsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nOn d√©finit ensuite un maillage pour le champ spatial avec un maillage plus fin dans la zone o√π il y a des observations et qui ‚Äúd√©borde‚Äù avec un maillage plus grossier.\n\nhull = inla.nonconvex.hull(gambia,convex = -0.1)\ngambia_mesh &lt;- inla.mesh.2d(boundary = hull,\n                            offset = c(30, 60), max.edge = c(20,40))\n\nplot(gambia_mesh,main=\"\",asp=1)\npoints(gambia,pch=21,bg=\"white\",cex=1.5,lwd=1.5)\n\n\n\n\nOn d√©finit √† partir du maillage le champ spatial spde qui correspond √† un champ spatial gaussien avec une covariance Mat√©rn. Nous consid√©rons les lois a priori par d√©faut sur les param√®tres de variance et de port√©e du champ spatial.\n\ngambia_spde &lt;- inla.spde2.matern(mesh = gambia_mesh, alpha=2)\n\nTout est pr√™t pour d√©finir le mod√®le √† ajuster et son estimation : Pour l‚Äôenfant \\(j\\) du village \\(i\\), nous supposons \\[Y_{ij}|V_i\\overset{ind}{\\sim}b(p_{ij})\\] avec \\[S_i\\sim GRF, \\quad V_i\\overset{ind}{\\sim}\\mathcal{N}(0,\\sigma^2_V)\\] et \\[p_{ij}=\\mu+\\beta_1 \\cdot treated_{ij}+\\beta_2 \\cdot netuse_{ij}+\\beta_3 \\cdot age_{ij}+\\beta_4 \\cdot green_{ij}+\\beta_5\\cdot phc_{ij}+S_i+V_i.\\]\n\nformula = pos ~ -1 +\n  Intercept(1) +\n  treated +\n  netuse +\n  age +\n  green +\n  phc +\n   spatial_field(coordinates, model=gambia_spde) +\n  village(village_index, model=\"iid\")\n\nfit &lt;- bru(components = formula,\n           data = gambia,\n           family= \"binomial\"\n)\n\niinla: Iteration 1 [max:1]\n\nsummary(fit)\n\ninlabru version: 2.8.0\nINLA version: 23.04.24\nComponents:\nIntercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L)\ntreated: main = linear(treated), group = exchangeable(1L), replicate = iid(1L)\nnetuse: main = linear(netuse), group = exchangeable(1L), replicate = iid(1L)\nage: main = linear(age), group = exchangeable(1L), replicate = iid(1L)\ngreen: main = linear(green), group = exchangeable(1L), replicate = iid(1L)\nphc: main = linear(phc), group = exchangeable(1L), replicate = iid(1L)\nspatial_field: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L)\nvillage: main = iid(village_index), group = exchangeable(1L), replicate = iid(1L)\nLikelihoods:\n  Family: 'binomial'\n    Data class: 'SpatialPointsDataFrame'\n    Predictor: pos ~ .\nTime used:\n    Pre = 1.25, Running = 1.98, Post = 0.131, Total = 3.36 \nFixed effects:\n            mean    sd 0.025quant 0.5quant 0.975quant   mode kld\nIntercept -1.295 1.282     -3.733   -1.327      1.312 -1.398   0\ntreated   -0.387 0.201     -0.782   -0.387      0.006 -0.387   0\nnetuse    -0.347 0.157     -0.655   -0.347     -0.039 -0.347   0\nage        0.246 0.044      0.159    0.246      0.332  0.246   0\ngreen      0.012 0.025     -0.038    0.012      0.060  0.014   0\nphc       -0.323 0.227     -0.772   -0.322      0.122 -0.321   0\n\nRandom effects:\n  Name    Model\n    spatial_field SPDE2 model\n   village IID model\n\nModel hyperparameters:\n                          mean    sd 0.025quant 0.5quant 0.975quant  mode\nTheta1 for spatial_field  1.32 0.836     -0.172     1.26       3.10  1.04\nTheta2 for spatial_field -2.50 0.708     -4.006    -2.45      -1.24 -2.27\nPrecision for village     4.83 2.423      1.683     4.32      10.97  3.45\n\nDeviance Information Criterion (DIC) ...............: 2326.24\nDeviance Information Criterion (DIC, saturated) ....: 2326.24\nEffective number of parameters .....................: 48.46\n\nWatanabe-Akaike information criterion (WAIC) ...: 2325.39\nEffective number of parameters .................: 46.41\n\nMarginal log-Likelihood:  -1227.34 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\nOn peut acc√©der aux distributions marginales des effets al√©atoires et des hyperparam√®tres :\n\nfit$summary.random \nfit$summary.hyperpar\n\nNous pouvons tracer les distributions a posteriori marginales des effets, par exemple :\n\nage &lt;- fit$marginals.fixed[[4]]\nggplot(data.frame(inla.smarginal(age)), aes(x, y)) +\n  geom_line() +\n  theme_bw()\n\n\n\nrfprecision &lt;- fit$marginals.hyperpar$`Precision for village`\nggplot(data.frame(inla.smarginal(rfprecision)), aes(x, y)) +\n  geom_line() +\n  theme_bw()\n\n\n\n\nNous essayons de repr√©senter le champs gaussien latent\n\ndomain_lims &lt;- apply(hull$loc, 2, range)\ngrd_dims &lt;- round(c(x = diff(domain_lims[, 1]), \n                    y = diff(domain_lims[, 2])) / 1)\nmesh_proj &lt;- fm_evaluator(\n  gambia_mesh,\n  xlim = domain_lims[, 1], ylim = domain_lims[, 2], dims = grd_dims\n)\n\nspatial_field &lt;- data.frame(\n  median = inla.link.invlogit(fit$summary.random$spatial_field$\"0.5quant\"),\n  range95 = (inla.link.invlogit(fit$summary.random$spatial_field$\"0.975quant\") -\n               inla.link.invlogit(fit$summary.random$spatial_field$\"0.025quant\"))\n)\n\npredicted_field &lt;- fm_evaluate(mesh_proj, spatial_field) %&gt;%\n  as.matrix() %&gt;%\n  as.data.frame() %&gt;%\n  bind_cols(expand.grid(x = mesh_proj$x, y = mesh_proj$y), .) %&gt;%\n  pivot_longer(cols = -c(\"x\", \"y\"),\n               names_to = \"metric\",\n               values_to = \"value\")\n# Median\nggplot(filter(predicted_field, metric == \"median\")) +\n  aes(x = x, y = y, fill = value) +\n  geom_raster() +\n  scale_fill_viridis_c()\n\n\n\n# 95% range\nggplot(filter(predicted_field, metric == \"range95\")) +\n  aes(x = x, y = y, fill = value) +\n  geom_raster() +\n  scale_fill_viridis_c()"
  },
  {
    "objectID": "R_INLA.html#references",
    "href": "R_INLA.html#references",
    "title": "R INLA",
    "section": "References",
    "text": "References\n\nhttps://www.pymc.io/projects/examples/en/latest/gaussian_processes/log-gaussian-cox-process.html\nFabian E. Bachl, Finn Lindgren, David L. Borchers, and Janine B. Illian (2019), inlabru: an R package for Bayesian spatial modelling from ecological survey data, Methods in Ecology and Evolution, British Ecological Society, 10, 760‚Äì766, doi:10.1111/2041-210X.13168\nFunwi-Gabga, N. and Mateu, J. (2012) Understanding the nesting spatial behaviour of gorillas in the Kagwene Sanctuary, Cameroon. Stochastic Environmental Research and Risk Assessment 26 (6), 793-811.\nhttps://www.muscardinus.be/2018/07/inlabru-bru/\nhttps://inlabru-org.github.io/inlabru/index.html"
  },
  {
    "objectID": "tidymodels_build_new_model.html",
    "href": "tidymodels_build_new_model.html",
    "title": "Construire un mod√®le parsnip",
    "section": "",
    "text": "Notre objectif ici est de construire un nouveau mod√®le {parsnip} √† partir d‚Äôune impl√©mentation existante dans un package R.\nInt√©r√™ts : √©liminer des d√©pendances, du code dupliqu√©, pouvoir profiter du cadre {tidymodels}.\n\n\n\nhttps://www.tidymodels.org/learn/develop/models/\nTuto tidymodels - Rencontres R 2023\n\n\n\n\nIl se d√©finit par\n\nun mode (r√©gression lin√©aire, logistique, ‚Ä¶),\nun type (r√©gression, classification),\nun moteur de calcul engine (lm, stan, ‚Ä¶).\n\nQunad on ajoute un mod√®le, on doit donc sp√©cifier son mode et son engine. On peut aussi ajouter un nouveau mod√®le diff√©rent d‚Äôun pr√©-existant seulement par son type (ie m√™me combinaison engine et mode).\nIl est possible de voir l‚Äôensemble des mod√®les d√©j√† disponibles ici."
  },
  {
    "objectID": "tidymodels_build_new_model.html#introduction",
    "href": "tidymodels_build_new_model.html#introduction",
    "title": "Construire un mod√®le parsnip",
    "section": "",
    "text": "Notre objectif ici est de construire un nouveau mod√®le {parsnip} √† partir d‚Äôune impl√©mentation existante dans un package R.\nInt√©r√™ts : √©liminer des d√©pendances, du code dupliqu√©, pouvoir profiter du cadre {tidymodels}.\n\n\n\nhttps://www.tidymodels.org/learn/develop/models/\nTuto tidymodels - Rencontres R 2023\n\n\n\n\nIl se d√©finit par\n\nun mode (r√©gression lin√©aire, logistique, ‚Ä¶),\nun type (r√©gression, classification),\nun moteur de calcul engine (lm, stan, ‚Ä¶).\n\nQunad on ajoute un mod√®le, on doit donc sp√©cifier son mode et son engine. On peut aussi ajouter un nouveau mod√®le diff√©rent d‚Äôun pr√©-existant seulement par son type (ie m√™me combinaison engine et mode).\nIl est possible de voir l‚Äôensemble des mod√®les d√©j√† disponibles ici."
  },
  {
    "objectID": "tidymodels_build_new_model.html#int√©gration-de-la-r√©gression-pln",
    "href": "tidymodels_build_new_model.html#int√©gration-de-la-r√©gression-pln",
    "title": "Construire un mod√®le parsnip",
    "section": "Int√©gration de la r√©gression PLN",
    "text": "Int√©gration de la r√©gression PLN\n\nlibrary(PLNmodels)\nlibrary(tidymodels)\nlibrary(poissonreg)\n\n\nDonn√©es\nNous utiliserons le jeu de donn√©es de la vignette de PLN.\n\ndata(trichoptera)\n\n\n\n\n\n\n\nRemarque\n\n\n\nIl existe une fonction prepare_data dans {parsnip} √©galement.\n\n\n\n\nDiff√©rentes √©tapes pour int√©grer PLNmodels::PLN dans parsnip\n\nEtape 1 : Sp√©cification du mod√®le et de ses arguments\nOn va ajouter la fonction PLNmodels::PLN √† la liste des fonctions utilisables pour faire de la r√©gression de Poisson.\n\nshow_model_info(\"poisson_reg\")\n\nInformation for `poisson_reg`\n modes: unknown, regression \n\n engines: \n   regression: glm¬π, glmnet¬π, hurdle¬π, stan¬π, zeroinfl¬π\n\n¬πThe model can use case weights.\n\n arguments: \n   glmnet: \n      penalty --&gt; lambda\n      mixture --&gt; alpha\n\n fit modules:\n     engine       mode\n        glm regression\n     hurdle regression\n   zeroinfl regression\n     glmnet regression\n       stan regression\n\n prediction modules:\n         mode   engine                          methods\n   regression      glm                     numeric, raw\n   regression   glmnet                     numeric, raw\n   regression   hurdle                     numeric, raw\n   regression     stan conf_int, numeric, pred_int, raw\n   regression zeroinfl                     numeric, raw\n\n\n\nset_model_mode(model = \"poisson_reg\", mode = \"regression\")\nset_model_engine(\n  \"poisson_reg\", \n  mode = \"regression\", \n  eng = \"PLN\"\n)\nset_dependency(\"poisson_reg\", eng = \"PLN\", pkg = \"PLNmodels\")\n\nOn peut v√©rifier ce qu‚Äôon a ajout√©.\n\nshow_model_info(\"poisson_reg\")\n\nInformation for `poisson_reg`\n modes: unknown, regression \n\n engines: \n   regression: glm¬π, glmnet¬π, hurdle¬π, PLNNA, stan¬π, zeroinfl¬π\n\n¬πThe model can use case weights.\n\n arguments: \n   glmnet: \n      penalty --&gt; lambda\n      mixture --&gt; alpha\n\n fit modules:\n     engine       mode\n        glm regression\n     hurdle regression\n   zeroinfl regression\n     glmnet regression\n       stan regression\n\n prediction modules:\n         mode   engine                          methods\n   regression      glm                     numeric, raw\n   regression   glmnet                     numeric, raw\n   regression   hurdle                     numeric, raw\n   regression     stan conf_int, numeric, pred_int, raw\n   regression zeroinfl                     numeric, raw\n\n\nSi notre mod√®le a des arguments suppl√©mentaires que ceux existants, on peut les ajouter.\n\n\nEtape 2 : Cr√©er la fonction principale associ√©e au mod√®le le cas √©ch√©ant\nIci comme nous avons seulement ajout√© un moteur √† un mod√®le pr√©existant ce n‚Äôest pas n√©cessaire.\ntodo: regarder comment ajouter l‚Äôinformation possible d‚Äôutilisation de poids\n\n\nEtape 3 : Pr√©ciser le module d‚Äôajustement (fit)\n\nL‚Äôargument interface, peut prendre les valeurs formula, data ou matrices.\nprotect est une liste optionnelle d‚Äôarguments qui ne devraient pas √™tre modifi√© par l‚Äôutilisateur.\nfunc est un vecteur pr√©cisant le package et la fonction qui sera appel√© pour l‚Äôajustement.\ndefaults est une liste optionnelle d‚Äôarguments que l‚Äôutilisateur peut modifier mais pour laquelle on peut sp√©cifier des valeurs par d√©faut.\n\n\nset_fit(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  value = list(\n    interface = \"formula\",\n    protect = c(\"formula\", \"data\"),\n    func = c(pkg = \"PLNmodels\", fun = \"PLN\"),\n    defaults = list(control = PLN_param(), weights = NULL, subset = NULL)\n  )\n)\n\nOn peut ajouter des traitements par d√©faut pour les variables explicatives, tels que calculs de variables indicatrices, calcul d‚Äôune constante etc‚Ä¶\n\nset_encoding(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  options = list(\n    predictor_indicators = \"traditional\",\n    compute_intercept = TRUE,\n    remove_intercept = TRUE,\n    allow_sparse_x = FALSE\n  )\n)\n\n\n\nEtape 4 : Ajouter un module pour la pr√©diction (predict)\n\nset_pred(\n  model = \"poisson_reg\",\n  eng = \"PLN\",\n  mode = \"regression\",\n  type = \"numeric\",\n  value = list(\n    pre = NULL,\n    post = NULL,\n    func = c(fun = \"predict\"),\n    args =\n      list(\n        object = expr(object$fit),\n        newdata = expr(new_data),\n        type = \"response\"\n      )\n  )\n)\n\n\n\n\nApplication sur les donn√©es trichoptera\n\nPLN dans PLNmodelsPLN dans parsnip\n\n\n\nprep_trichoptera &lt;- PLNmodels::prepare_data(trichoptera$Abundance, trichoptera$Covariate)\nmyPLN &lt;- PLN(Abundance ~ 1 , data = prep_trichoptera)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nmyPLN\n\nA multivariate Poisson Lognormal fit with full covariance model.\n==================================================================\n nb_param    loglik       BIC       ICL\n      170 -1130.047 -1460.852 -2229.083\n==================================================================\n* Useful fields\n    $model_par, $latent, $latent_pos, $var_par, $optim_par\n    $loglik, $BIC, $ICL, $loglik_vec, $nb_param, $criteria\n* Useful S3 methods\n    print(), coef(), sigma(), vcov(), fitted()\n    predict(), predict_cond(), standard_error()\n\n\n\n\n\nresPLN &lt;- poisson_reg() %&gt;% \n  set_engine(\"PLN\") %&gt;% \n  fit(Abundance ~ 1 , data = prep_trichoptera)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nresPLN\n\nparsnip model object\n\nA multivariate Poisson Lognormal fit with full covariance model.\n==================================================================\n nb_param    loglik       BIC       ICL\n      170 -1130.047 -1460.852 -2229.083\n==================================================================\n* Useful fields\n    $model_par, $latent, $latent_pos, $var_par, $optim_par\n    $loglik, $BIC, $ICL, $loglik_vec, $nb_param, $criteria\n* Useful S3 methods\n    print(), coef(), sigma(), vcov(), fitted()\n    predict(), predict_cond(), standard_error()\n\n\n\n\n\n\nsummary(resPLN)\n\n             Length Class       Mode       \nlvl           0     -none-      NULL       \nspec          8     poisson_reg list       \nfit          32     PLNfit      environment\npreproc       1     -none-      list       \nelapsed       1     -none-      list       \ncensor_probs  0     -none-      list       \n\nresPLN$spec\n\nPoisson Regression Model Specification (regression)\n\nComputational engine: PLN \n\nModel fit template:\nPLNmodels::PLN(formula = missing_arg(), data = missing_arg(), \n    control = list(backend = \"nlopt\", trace = 1, covariance = \"full\", \n        Omega = NULL, config_post = list(jackknife = FALSE, bootstrap = 0L, \n            rsquared = TRUE, variational_var = FALSE, sandwich_var = FALSE, \n            trace = 1), config_optim = list(algorithm = \"CCSAQ\", \n            maxeval = 10000, ftol_rel = 1e-08, xtol_rel = 1e-06, \n            ftol_abs = 0, xtol_abs = 0, maxtime = -1, trace = 1), \n        inception = NULL), weights = NULL, subset = NULL)\n\n# Pour recuperer les coefficients\ncoef(resPLN$fit)\n\n                  Che       Hyc      Hym       Hys      Psy        Aga\n(Intercept) -2.833542 -4.023858 1.056175 -2.176389 3.305965 -0.3468842\n                  Glo       Ath       Cea       Ced        Set        All\n(Intercept) -2.205421 -1.657137 -3.343267 0.3683657 -0.5991094 -0.8440133\n                  Han       Hfo        Hsp       Hve       Sta\n(Intercept) -1.233492 -2.123357 -0.2549654 -2.750357 0.9776199\n\nall.equal(coef(myPLN), coef(resPLN$fit))\n\n[1] TRUE\n\n# Pour faire de la prediction\npred_pln &lt;- predict(myPLN, newdata  = prep_trichoptera, type = \"response\")\npred_pln %&gt;% head(n=3)\n\n         Che        Hyc      Hym       Hys     Psy     Aga       Glo       Ath\n1 0.06171337 0.05998778 3.831122 0.1225325 91.0535 2.91355 0.2540807 0.2926166\n2 0.06171337 0.05998778 3.831122 0.1225325 91.0535 2.91355 0.2540807 0.2926166\n3 0.06171337 0.05998778 3.831122 0.1225325 91.0535 2.91355 0.2540807 0.2926166\n        Cea      Ced      Set      All     Han      Hfo      Hsp       Hve\n1 0.1071243 2.570283 3.703422 1.080023 11.0092 1.054269 5.761769 0.1990118\n2 0.1071243 2.570283 3.703422 1.080023 11.0092 1.054269 5.761769 0.1990118\n3 0.1071243 2.570283 3.703422 1.080023 11.0092 1.054269 5.761769 0.1990118\n       Sta\n1 7.495402\n2 7.495402\n3 7.495402\n\n# On peut appliquer les methodes \n#pred_parsnipfit &lt;- predict(resPLN$fit, newdata  = prep_trichoptera)\npred_parsnip &lt;- predict(resPLN, new_data  = trichoptera$Abundance)\npred_parsnip %&gt;% head(n=3)\n\n# A tibble: 3 √ó 17\n  .pred_Che .pred_Hyc .pred_Hym .pred_Hys .pred_Psy .pred_Aga .pred_Glo\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1    0.0617    0.0600      3.83     0.123      91.1      2.91     0.254\n2    0.0617    0.0600      3.83     0.123      91.1      2.91     0.254\n3    0.0617    0.0600      3.83     0.123      91.1      2.91     0.254\n# ‚Ñπ 10 more variables: .pred_Ath &lt;dbl&gt;, .pred_Cea &lt;dbl&gt;, .pred_Ced &lt;dbl&gt;,\n#   .pred_Set &lt;dbl&gt;, .pred_All &lt;dbl&gt;, .pred_Han &lt;dbl&gt;, .pred_Hfo &lt;dbl&gt;,\n#   .pred_Hsp &lt;dbl&gt;, .pred_Hve &lt;dbl&gt;, .pred_Sta &lt;dbl&gt;\n\n\n\n\nTest d‚Äôun workflow\n\n# separation du jeu de donnees en test et apprentissage\nset.seed(123)\ntri_split &lt;- initial_split(data = prep_trichoptera, prop = 0.9)\n#tri_train &lt;- training(tri_split)\n#tri_test &lt;- testing(tri_split)\np_recipe &lt;- \n  recipe(Abundance ~ 1 + Temperature, data = training(tri_split))\n\npln_model &lt;- \n  poisson_reg()%&gt;%\n  set_engine(\"PLN\") %&gt;%\n  set_mode(\"regression\")\n\npln_workflow &lt;- workflow() %&gt;%\n  add_recipe(p_recipe) %&gt;%\n  add_model(pln_model)\n\nfitted_workflow &lt;-  pln_workflow %&gt;%\n  fit(training(tri_split)) \n\n# Predicition sur le jeu d'entrainement\ntest_pred &lt;- fitted_workflow %&gt;% predict(new_data = testing(tri_split))\n\nPour la suite du workflow, calcul de performance sur un r√©√©chantillonnage etc., ce serait possible mais n√©cessite un peu de code. Il faudrait ici que la sortie de pr√©diction soit en format plus ‚Äòtidy‚Äô ou r√©√©crire le calcul de m√©trique sur des matrices.\n\n\nAutre jeu de donn√©es, exemple en r√©gression univari√©e\n\np &lt;- read.csv(\"https://stats.idre.ucla.edu/stat/data/poisson_sim.csv\")\np &lt;- within(p, {\n  prog &lt;- factor(prog, levels=1:3, labels=c(\"General\", \"Academic\", \n                                            \"Vocational\"))\n  id &lt;- factor(id)\n})\n\nOn essaie maintenant en utilisant {parsnip}.\n\nglm de baseglm dans parsnipplnPLN dans parsnip\n\n\n\nsummary(m1 &lt;- glm(num_awards ~ prog + math, family=\"poisson\", data=p))\n\n\nCall:\nglm(formula = num_awards ~ prog + math, family = \"poisson\", data = p)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -5.24712    0.65845  -7.969 1.60e-15 ***\nprogAcademic    1.08386    0.35825   3.025  0.00248 ** \nprogVocational  0.36981    0.44107   0.838  0.40179    \nmath            0.07015    0.01060   6.619 3.63e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 189.45  on 196  degrees of freedom\nAIC: 373.5\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\npoisson_reg() %&gt;% \n     set_engine(\"glm\") %&gt;%\n     set_mode(\"regression\") %&gt;%\n     fit(num_awards ~ prog + math, data = p)  %&gt;%\n     predict(p)\n\n# A tibble: 200 √ó 1\n    .pred\n    &lt;dbl&gt;\n 1 0.135 \n 2 0.0934\n 3 0.167 \n 4 0.145 \n 5 0.126 \n 6 0.100 \n 7 0.192 \n 8 0.126 \n 9 0.0771\n10 0.192 \n# ‚Ñπ 190 more rows\n\n\n\n\n\nmod_pln &lt;- PLN(as.matrix(num_awards) ~ prog + math, data = p)  \n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\nmod_pln %&gt;%\n     predict(p, type = \"response\") %&gt;%\n     head(n = 10)\n\n            Y\n1  0.13402450\n2  0.09294198\n3  0.16581305\n4  0.14387844\n5  0.12484545\n6  0.09977539\n7  0.19109165\n8  0.12484545\n9  0.07597876\n10 0.19109165\n\n\n\n\n\npoisson_reg() %&gt;% \n     set_engine(\"PLN\") %&gt;%\n     set_mode(\"regression\") %&gt;%\n     fit(as.matrix(num_awards) ~ prog + math, data = p) %&gt;% \n     predict(p)\n\n\n Initialization...\n Adjusting a full covariance PLN model with nlopt optimizer\n Post-treatments...\n DONE!\n\n\n# A tibble: 200 √ó 1\n   .pred_Y\n     &lt;dbl&gt;\n 1  0.134 \n 2  0.0929\n 3  0.166 \n 4  0.144 \n 5  0.125 \n 6  0.0998\n 7  0.191 \n 8  0.125 \n 9  0.0760\n10  0.191 \n# ‚Ñπ 190 more rows\n\n\n\n\n\nOn peut v√©rifier la commande associ√©e au mod√®le programm√©.\n\npoisson_reg() %&gt;% translate(engine = \"PLN\")\n\nPoisson Regression Model Specification (regression)\n\nComputational engine: PLN \n\nModel fit template:\nPLNmodels::PLN(formula = missing_arg(), data = missing_arg(), \n    control = list(backend = \"nlopt\", trace = 1, covariance = \"full\", \n        Omega = NULL, config_post = list(jackknife = FALSE, bootstrap = 0L, \n            rsquared = TRUE, variational_var = FALSE, sandwich_var = FALSE, \n            trace = 1), config_optim = list(algorithm = \"CCSAQ\", \n            maxeval = 10000, ftol_rel = 1e-08, xtol_rel = 1e-06, \n            ftol_abs = 0, xtol_abs = 0, maxtime = -1, trace = 1), \n        inception = NULL), weights = NULL, subset = NULL)"
  },
  {
    "objectID": "tidymodels_build_new_model.html#pour-aller-plus-loin",
    "href": "tidymodels_build_new_model.html#pour-aller-plus-loin",
    "title": "Construire un mod√®le parsnip",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nDans le cadre tidymodels, tout est assez modulaire et personnalisable : on peut ajouter de nouvelles recettes de pr√©-traitement, personnaliser son r√©√©chantillonnage, le calcul de m√©trique etc.\nUn peu de documentation sur le site de {tidymodels] dans la section Develop custom modeling tools."
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Instructions pour le d√©pot sur le site web",
    "section": "",
    "text": "Cr√©er une branche propre √† l‚Äôatelier nomm√©e explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCr√©er un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs √©ventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir √† mettre √† jour l‚Äôimage docker"
  },
  {
    "objectID": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "href": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "title": "Instructions pour le d√©pot sur le site web",
    "section": "",
    "text": "Cr√©er une branche propre √† l‚Äôatelier nomm√©e explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCr√©er un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs √©ventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir √† mettre √† jour l‚Äôimage docker"
  },
  {
    "objectID": "instructions.html#d√©tails-du-fonctionnement",
    "href": "instructions.html#d√©tails-du-fonctionnement",
    "title": "Instructions pour le d√©pot sur le site web",
    "section": "D√©tails du fonctionnement",
    "text": "D√©tails du fonctionnement\n\nLe docker\n(Lien vers la fiche pense-b√™te)[https://www.docker.com/sites/default/files/d8/2019-09/docker-cheat-sheet.pdf]\nPour cr√©er des images Docker en local sur sa machine, voici une liste de commandes utiles\n\nPour construire une image docker, il faut cr√©er un fichier Dockerfile qui contient la recette du Docker. Pour ce site le ficher Dockerfile a la forme suivante\n\n\n\n\nFROM rocker/geospatial:4\nRUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\\n && apt-get install -y pandoc \\\n    pandoc-citeproc\nRUN R -e \"install.packages('remotes')\"\nRUN R -e \"install.packages('microbenchmark')\"\nRUN R -e \"install.packages('purrr')\" # map function\nRUN R -e \"install.packages('BiocManager')\" # map function\nRUN R -e \"BiocManager::install('BiocPkgTools')\"\nRUN R -e \"install.packages('httr')\" # GET function\nENV R_CRAN_WEB=\"https://cran.rstudio.com/\"\nRUN R -e \"install.packages('cowplot')\" # GET function\nRUN R -e \"install.packages('torch')\"\nRUN R -e \"torch::install_torch(type = 'cpu')\"\nRUN R -e \"install.packages('PLNmodels')\"\nRUN R -e \"install.packages('torchvision')\"\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n  jags \\\n  mercurial gdal-bin libgdal-dev gsl-bin libgsl-dev \\\n  libc6-i386\n\n\nRUN R -e \"install.packages('INLA',repos=c(getOption('repos'),INLA='https://inla.r-inla-download.org/R/stable'), dep=TRUE)\"\nRUN R -e \"install.packages('reticulate')\"\nRUN R -e \"install.packages(c('inlabru', 'lme4', 'ggpolypath', 'RColorBrewer', 'geoR'))\"\nRUN R -e \"install.packages(c('tidymodels', 'brulee', 'reprex'))\"\nRUN R -e \"install.packages(c('poissonreg'))\"\nRUN apt-get install -y --no-install-recommends unzip python3-pip dvipng pandoc wget git make python3-venv && \\\n    pip3 install jupyter jupyter-cache flatlatex matplotlib && \\\n    apt-get --purge -y remove texlive.\\*-doc$ && \\\n    apt-get clean\n\nRUN pip3 install jax jaxlib torch numpy matplotlib pandas scikit-learn torchvision torchaudio\nRUN pip3 install pyplnmodels\nRUN pip3 install optax\n\n\npuis demander la construction de l‚Äôimage √† l‚Äôaide de la commande\n\n docker build -t nom_depot_dockerhub/nom_du_repo:version  . ## avec un nom\n\net enfin pousser sur Dockerhub\n\n docker push nom_depot_dockerhub/nom_du_repo:version\n\n\n\nLes actions\nDans les action de Github, on peut sp√©cifier un container docker √† utiliser, c‚Äôest ce que fait la ligne container du fichier d‚Äôaction suivant, utiliser pour cr√©er ce site web\n\n\nname: website\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    name: Build website with rmarkdown\n    runs-on: ubuntu-latest\n    container: stateofther/r-finistr2023:0.5\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Additional Packages\n        run: Rscript -e \"install.packages(c('ggbeeswarm', 'tictoc', 'bench', 'circlize', 'JuliaCall', 'GeoModels'))\"\n      - name: erase R-Julia-Geostats.qmd and fixing version\n        run: rm \"R-Julia-Geostats.qmd\" \"R-Julia-Geostats-v-fixing.qmd\"\n      - name: Generate slides\n        run: \"quarto render\"\n      - name: GitHub Pages action\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./_site"
  },
  {
    "objectID": "torch_Python_regression.html",
    "href": "torch_Python_regression.html",
    "title": "Introduction √† Pytorch",
    "section": "",
    "text": "Cette page constitue une traduction en Python avec pytorch de la page √©quivalente produite avec {torch} lors de FinistR 2022."
  },
  {
    "objectID": "torch_Python_regression.html#installation",
    "href": "torch_Python_regression.html#installation",
    "title": "Introduction √† Pytorch",
    "section": "Installation",
    "text": "Installation\nUne fa√ßon (parmi d‚Äôautres) d‚Äôavoir une installation fonctionnelle de torch consiste √† l‚Äôinstaller via conda. La page officielle est tr√®s bien document√©e et fournit toutes les instructions n√©cessaires. La solution adopt√©e ici consiste √† cr√©er un environnement conda (nomm√© torch) pour y installer torch (en version CPU).\n#| eval: false\nconda create -n torch\nconda install pytorch torchvision torchaudio cpuonly -c pytorch\nconda install pandas matplotlib scikit-learn jupyter\nIl suffit alors d‚Äôactiver l‚Äôenvironnement torch pour produire le html √† partir du qmd\n#| eval: false\nconda activate torch\nquarto render my_document.qmd --to html"
  },
  {
    "objectID": "torch_Python_regression.html#exploration-de-torch-pour-la-diff√©rentiation-automatique",
    "href": "torch_Python_regression.html#exploration-de-torch-pour-la-diff√©rentiation-automatique",
    "title": "Introduction √† Pytorch",
    "section": "Exploration de {torch} pour la diff√©rentiation automatique",
    "text": "Exploration de {torch} pour la diff√©rentiation automatique\n\nimport torch\nimport torch.distributions as dist\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression"
  },
  {
    "objectID": "torch_Python_regression.html#principe-du-calcul-de-gradient",
    "href": "torch_Python_regression.html#principe-du-calcul-de-gradient",
    "title": "Introduction √† Pytorch",
    "section": "Principe du calcul de gradient",
    "text": "Principe du calcul de gradient\n{torch} fonctionne avec ses propres types num√©riques, qu‚Äôil faut cr√©er avec la fonction torch.tensor() et ses propres fonctions torch.*(). Consid√©rons un exemple tr√®s simple: \\(x \\mapsto x^2\\)\n\nx = torch.tensor(3)\ny = torch.square(x)\n\n\ny\n\ntensor(9)\n\n\nOn va pouvoir calculer \\(\\frac{dy}{dx}\\) en d√©finissant x avec l‚Äôargument require_grad = True. Cet argument va sp√©cifier que ‚Äòx‚Äô est entrainable et va d√©marrer l‚Äôenregistrement par autograd des op√©rations sur ce tenseur.\nAutograd est un module de torch qui permet de collecter les gradients. Il le fait en enregistrant des donn√©es (tenseurs) et toutes les op√©rations ex√©cut√©es dans un graphe acyclique dirig√© dont les feuilles sont les tenseurs d‚Äôentr√©e et les racines les tenseurs de sorties. Ces op√©rations sont stock√©es comme des fonctions et au moment du calcul des gradients, sont appliqu√©es depuis le noeud de sortie en ‚Äòbackpropagation‚Äô le long du r√©seau.\nAttention, torch ne peut stocker un gradient que pour des valeurs num√©riques (float), pas pour des entiers.\n\nx = torch.tensor(2.0, requires_grad = True)\nx\n\ntensor(2., requires_grad=True)\n\n\nOn remarque que x poss√®de d√©sormais un champ grad (m√™me si ce dernier n‚Äôest pas encore d√©fini).\n\nx.grad\n\nLorsqu‚Äôon calcule \\(y = x^2\\), ce dernier va √©galement h√©riter d‚Äôun nouveau champ $grad_fn:\n\ny = torch.log(torch.square(x))\ny\ny.grad_fn\n\n&lt;LogBackward0 at 0x7ff8a8d724d0&gt;\n\n\nqui indique comment calculer le gradient en utilisant la d√©riv√©e des fonctions compos√©es:\n\\[\n(g\\circ f)'(x) = f'(x) \\times g'(f(x))\n\\]\net les fonctions\n\\[\n\\frac{dx^2}{dx} = 2x \\quad \\frac{d \\log(x)}{dx} = \\frac{1}{x}\n\\]\nLe calcul effectif du gradient est d√©clench√© lors de l‚Äôappel √† la m√©thode .backward() de y et est stock√© dans le champ .grad de x.\n\nx.grad ## gradient non d√©fini\ny.backward() \nx.grad ## gradient d√©fini = 1\n\ntensor(1.)\n\n\nOn a bien:\n\\[\n\\frac{dy}{dx} = \\underbrace{\\frac{dy}{dz}}_{\\log}(z) \\times \\underbrace{\\frac{dz}{dx}}_{\\text{power}}(x) = \\frac{1}{4} \\times 2*2 = 1\n\\]\nIntuitivement au moment du calcul de y, torch construit un graphe computationnel qui lui permet d‚Äô√©valuer num√©riquement \\(y\\) et qui va √©galement servir pour calculer \\(\\frac{dy}{dz}\\) au moment de l‚Äôappel √† la fonction .backward() issue du module autograd.\nEssayons de reproduire le calcul dans notre exemple. Le calcul forward donne\n\\[\nx = 2 \\xrightarrow{x \\mapsto x^2} z = 4 \\mapsto \\xrightarrow{x \\mapsto \\log(x)} y = \\log(4)\n\\]\nPour le calcul backward, il faut donc construire le graphe formel suivant. La premi√®re √©tape du graphe est accessible via $grad_fn\n\ny.grad_fn\n\n&lt;LogBackward0 at 0x7ff8a8d724d0&gt;\n\n\net les fonctions suivantes via $next_functions\n\ny.grad_fn.next_functions\n\n((&lt;PowBackward0 at 0x7ff8a4bcfaf0&gt;, 0),)\n\n\nDans notre exemple, on a donc:\n\\[\n\\frac{dy}{dy} = 1 \\xrightarrow{x \\mapsto \\text{logBackward}(x)} \\frac{dy}{dz} = \\frac{dy}{dy} \\times \\text{logBackward}(z) \\xrightarrow{x \\mapsto \\text{powerBackward}(x)} \\frac{dy}{dx} = \\frac{dy}{dz} \\times \\text{logBackward}(x)\n\\]\nDans cet exemple:\n\n\\(\\text{logBackward}(x) = \\frac{1}{x}\\)\n\\(\\text{powBackward}(x) = 2x\\)\n\nEt la propagation des d√©riv√©es donne donc\n\\[\n\\frac{dy}{dy} = 1 \\to \\frac{dy}{dz} = 1 \\times \\frac{1}{4} = \\frac{1}{4} \\to \\frac{dy}{dx} = \\frac{1}{4} \\times 4 = 1\n\\]\nCe graphe est illustr√© ci-dessous pour la fonction \\((x_1, x_2) \\mapsto z = sin(x_2) log(x_1 x_2)\\)\n\nPour (beaucoup) plus de d√©tails sur le graphe computationnel, on peut consulter la documentation officielle de PyTorch.\nIl faut juste noter que dans torch, le graphe computationnel est construit de fa√ßon dynamique, au moment du calcul de y."
  },
  {
    "objectID": "torch_Python_regression.html#r√©gression-logistique-avec-torch",
    "href": "torch_Python_regression.html#r√©gression-logistique-avec-torch",
    "title": "Introduction √† Pytorch",
    "section": "R√©gression logistique avec torch",
    "text": "R√©gression logistique avec torch\nOn va adopter un simple mod√®le de r√©gression logistique:\n\\[\nY_i \\sim \\mathcal{B}(\\sigma(\\theta^T x_i)) \\quad \\text{avec} \\quad \\sigma(x) = \\frac{1}{1 + e^{x}}\n\\]\nLe but est d‚Äôestimer \\(\\theta\\) et √©ventuellement les erreurs associ√©es. On commence par g√©n√©rer des donn√©es.\n\n# G√©n√©rer les param√®tres\ntorch.manual_seed(45)\nn = 100\np = 3\n# G√©n√©rer la matrice X\nX = torch.randn(n, p)\n# G√©n√©rer le vecteur theta\ntheta = torch.randn(3)\n# Calculer les probabilit√©s\nprobs = 1 / (1 + torch.exp(torch.mv(X, theta)))\n# G√©n√©rer les observations Y en utilisant une distribution Bernoulli\nbernoulli_dist = dist.Bernoulli(probs=probs)\nY = bernoulli_dist.sample()\n\ntorch fonctionne avec ses propres types num√©riques, qu‚Äôil faut cr√©er avec la fonction torch.tensor(). C‚Äôest ce qu‚Äôon a fait avec les fonctions torch.randn() et bernoulli_dist.sample() mais on pourrait forcer la conversion avec torch.tensor().\n\nx = X.clone()\ny = Y.clone()\n\nOn √©crit ensuite la fonction de vraisemblance\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta) = \\sum_{i=1}^n y_i (\\theta^Tx_i) - \\sum_{i=1}^n log(1 + e^{\\theta^T x_i})\n\\]\n\ndef logistic_loss(theta, x, y):\n    odds = torch.mv(x, theta)\n    log_lik = torch.dot(y, odds) - torch.sum(torch.log(1 + torch.exp(odds)))\n    return -log_lik\n\navant de v√©rifier qu‚Äôelle fonctionne:\n\nlogistic_loss(theta = theta, x = x, y = y)\n\ntensor(80.1576)\n\n\nOn veut ensuite d√©finir une fonction objective √† maximiser (qui ne d√©pend que de theta):\n\ndef eval_loss(theta, verbose=True):\n    loss = logistic_loss(theta, x, y)\n    if verbose:\n        print(\"Theta:\", theta, \": Loss:\", float(loss))\n    return loss\n\net v√©rifier qu‚Äôelle fonctionne\n\neval_loss(theta, verbose = True)\n\nTheta: tensor([-0.2633, -0.2123,  0.5694]) : Loss: 80.15764617919922\n\n\ntensor(80.1576)\n\n\navant de proc√©der √† l‚Äôoptimisation √† proprement parler. Pour cette derni√®re, on commence par d√©finir notre param√®tre sous forme d‚Äôun tenseur qui va √™tre mis √† jour\n\ntheta_current = torch.zeros(len(theta), requires_grad=True)\n\net d‚Äôun optimiseur:\n\noptimizer = optim.Rprop([theta_current])\n\nOn consid√®re ici l‚Äôoptimiseur Rprop (resilient backpropagation) qui ne prend pas en compte l‚Äôamplitude du gradient mais uniquement le signe de ses coordonn√©es (voir ici pour une introduction p√©dagogique √† Rprop).\nIntuitivement, l‚Äôoptimiseur a juste besoin de la valeur de \\(\\theta\\) et de son gradient pour le mettre √† jour. Mais √† ce stade on ne conna√Æt pas encore le gradient \\(\\nabla_\\theta \\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta)\\)\n\ntheta_current.grad\n\net il faut donc le calculer:\n\nloss = eval_loss(theta_current, verbose = False)\nloss.backward()\n\nOn peut v√©rifier que le gradient est stock√© dans theta\n\ntheta_current.grad\n\ntensor([-5.4452, -9.6232,  5.0331])\n\n\net effectuer la mise √† jour avec une √©tape d‚Äôoptimisation\n\noptimizer.step()\n\nOn peut v√©rifier que le param√®tre courant a √©t√© mis √† jour.\n\ntheta_current\n\ntensor([ 0.0100,  0.0100, -0.0100], requires_grad=True)\n\n\nIl ne reste plus qu‚Äô√† recommencer pour un nombre d‚Äôit√©rations donn√©. Attention, il faut r√©initialiser le gradient avant de le mettre √† jour, le comportement par d√©faut de mise √† jour √©tant l‚Äôaccumulation plut√¥t que le remplacement.\n\nnum_iterations = 100\nloss_vector = []\n\nfor i in range(num_iterations):\n    optimizer.zero_grad()\n    loss = eval_loss(theta_current, verbose=False)\n    loss.backward()\n    optimizer.step()\n    loss_vector.append(loss.item())\n\nOn v√©rifie que la perte diminue au cours du temps.\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n\n\n\nOn constate que notre optimiseur aboutit √† peu pr√®s au m√™me r√©sultat que glm()\n\n# Ajustement du mod√®le GLM\nmodel = LogisticRegression(fit_intercept=False, penalty = None)\nmodel.fit(X, Y)\nsklearn_coeffs = model.coef_.tolist()[0]\n\n# Comparer les valeurs obtenues avec torch et glm\ndf = pd.DataFrame({\n    'torch': theta_current.detach().numpy().tolist(),\n    'sklearn': sklearn_coeffs\n})\nprint(df)\n\n      torch   sklearn\n0  0.125890  0.125891\n1  0.423913  0.423912\n2 -0.341100 -0.341100\n\n\nAttention la m√©canique pr√©sent√©e ci-dessus avec .step() ne fonctionne pas pour certaines routines d‚Äôoptimisation (BFGS, gradient conjugu√©) qui n√©cessite de calculer plusieurs fois la fonction objective. Dans ce cas, il faut d√©finir une closure, qui renvoie la fonction objective, et la passer en argument √† .step().\n\n%%time\n# Remise √† z√©ro du param√®tre courant\ntheta_current = torch.zeros(len(theta), requires_grad=True)\noptimizer = optim.Rprop([theta_current], lr=0.01)\n\n# D√©finition de la closure\ndef calc_loss():\n    optimizer.zero_grad()\n    loss = eval_loss(theta_current, verbose=False)\n    loss.backward()\n    return loss\n\n# Optimisation avec la closure\nnum_iterations = 100\nloss_vector = []\n\nfor i in range(num_iterations):\n    loss = optimizer.step(calc_loss).item()\n    loss_vector.append(loss)\n\nCPU times: user 63 ms, sys: 0 ns, total: 63 ms\nWall time: 62.6 ms\n\n\nOn peut v√©rifier qu‚Äôon obtient des r√©sultats identiques dans les deux cas d‚Äôutilisation:\n\ntheta_current\n\ntensor([ 0.1259,  0.4239, -0.3411], requires_grad=True)\n\n\n\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()"
  },
  {
    "objectID": "torch_Python_regression.html#exemple-de-r√©gression-multivari√©e",
    "href": "torch_Python_regression.html#exemple-de-r√©gression-multivari√©e",
    "title": "Introduction √† Pytorch",
    "section": "Exemple de r√©gression multivari√©e",
    "text": "Exemple de r√©gression multivari√©e\nOn consid√®re un exemple de r√©gression multiple, r√©alis√© √† partir du blog torch for optimization, o√π l‚Äôon cherche √† estimer les param√®tres de moyenne ainsi que la variance par maximisation de la vraisemblance.\nOn g√©n√®re les donn√©es\n\n# D√©finir la graine al√©atoire pour la reproductibilit√©\ntorch.manual_seed(45)\n# G√©n√©rer la matrice X\nn = 100\nX = torch.cat((torch.ones(n, 1), torch.randn(n, 10)), dim=1)\n# G√©n√©rer le vecteur Beta.true\nBeta_true = torch.randn(11)\n# G√©n√©rer la variable d√©pendante Y\nY = torch.matmul(X, Beta_true) + torch.randn(n)\n\nLa fonction de perte √† optimiser (ici la log-vraisemblance) va d√©pendre d‚Äôinputs d√©finis comme des ‚Äútenseurs torch‚Äù:\n\n## Declare the parameter for the loss function\n## 11 parameters for Beta, 1 for sigma\nTheta = torch.ones(12, requires_grad = True)\n\nQuelques remarques :\n\nle param√®tre \\(\\theta\\) √† optimiser est ici d√©fini comme un tenseur, i.e.¬†un objet qui va notamment stocker la valeur courante de \\(\\theta\\). Avec l‚Äôoption requires_grad=True la valeur courante du gradient de la derni√®re fonction appel√©e d√©pendant de \\(\\theta\\) va aussi √™tre stock√©e.\nla matrice \\(X\\) est aussi d√©finie comme un tenseur, mais l‚Äôoption ‚Äúrequires_grad=TRUE‚Äù n‚Äôa pas √©t√© sp√©cifi√©e, le gradient ne sera donc pas stock√© pour cet objet. Cette distinction est explicit√©e lorsque l‚Äôon affiche les deux objets:\n\n\nTheta[:3]\nX[:3, :3]\n\ntensor([[ 1.0000,  0.1371,  1.5252],\n        [ 1.0000,  0.3665,  1.2984],\n        [ 1.0000, -0.1322,  0.0068]])\n\n\nLa fonction de perte est ici la log-vraisemblance, elle-m√™me d√©finie √† partir d‚Äôop√©rateurs torch √©l√©mentaires :\n\ndef LogLik():\n    n = X.shape[0]  \n    # Last term of Theta is the std\n    sigma = Theta[11]\n    log_sigma = torch.log(sigma)\n    squared_residuals = torch.norm(Y - torch.matmul(X, Theta[:11])) ** 2\n    term1 = n * log_sigma\n    term2 = squared_residuals / (2 * (sigma ** 2))\n    return term1 + term2\n\nLa fonction LogLik peut √™tre appliqu√©e comme une fonction R qui prendra directement en argument les valeurs courantes de X.tensor et \\(\\theta\\), et produira en sortie un tenseur\n\nLogLik()\n\ntensor(736.3355, grad_fn=&lt;AddBackward0&gt;)\n\n\nOutre la valeur courante de la fonction, ce tenseur contient la ‚Äúrecette‚Äù du graphe computationnel utilis√© dans calcul backward du gradient de la fonction LogLik par rapport √† \\(\\theta\\). On peut ainsi afficher la derni√®re op√©ration de ce graphe\n\ntoto = LogLik()\ntoto.grad_fn\n\n&lt;AddBackward0 at 0x7ff7cb45c280&gt;\n\n\ncorrespondant √† l‚Äôaddition (AddBackward) des deux termes \\[  n\\times \\log(\\theta[11]) \\quad \\text{et} \\quad ||Y-X\\theta[0:10]||^2/(2*\\theta[11]^2)\\] dans le calcul de la perte. On peut afficher les op√©rations suivantes dans le graphe comme suit:\n\ntoto.grad_fn.next_functions\n\n((&lt;MulBackward0 at 0x7ff8a4bcd4b0&gt;, 0), (&lt;DivBackward0 at 0x7ff8a4bcd570&gt;, 0))\n\n\nL‚Äô√©tape suivante consiste √† choisir la m√©thode d‚Äôoptimisation √† appliquer. L‚Äôint√©r√™t d‚Äôutiliser le package {torch} est d‚Äôavoir acc√®s √† une large gamme de m√©thodes d‚Äôoptimisation, on consid√®re ici la m√©thode rprop qui r√©alise une descente de gradient √† pas adaptatif et sp√©cifique √† chaque coordonn√©e:\n\n## Specify the optimization parameters\nlr = 0.01\noptimizer = optim.Rprop([Theta],lr)\n\nOn d√©crit maintenant un pas de calcul du gradient, contenant les √©tapes suivantes : - r√©initialisation du gradient de \\(\\theta\\),\n- √©valuation de la fonction de perte (avec la valeur courante de \\(\\theta\\)),\n- calcul backward du gradient. On inclut tout cela dans une fonction:\n\n## Optimization step description\ndef calc_loss():\n    optimizer.zero_grad()\n    value = LogLik()\n    value.backward()\n    return value\n\nCommen√ßons par regarder ce que fait concr√®tement cette fonction. L‚Äô√©tat courant du param√®tre est le suivant:\n\nTheta\nTheta.grad\n\nOn applique une premi√®re fois la fonction, et on obtient la mise √† jour suivante :\n\ncalc_loss()\nTheta\nTheta.grad\n\ntensor([  -73.6607,   133.4165,  -100.1567,   134.5971,    38.0697,   123.4896,\n           49.8657,    82.5681,   -27.1204,   185.5123,   176.2979, -1372.6710])\n\n\nComme on le voit la valeur courante du param√®tre n‚Äôa pas chang√©e, en revanche Theta.grad contient maintenant le gradient de la fonction de perte calcul√© en \\(\\theta\\). Dans le cas o√π la m√©thode d‚Äôoptimisation consid√©r√©e n‚Äôa besoin que de la valeur courante du gradient et du param√®tre, on peut directement faire la mise √† jour de \\(\\theta\\) :\n\noptimizer.step()\nTheta\nTheta.grad\n\ntensor([  -73.6607,   133.4165,  -100.1567,   134.5971,    38.0697,   123.4896,\n           49.8657,    82.5681,   -27.1204,   185.5123,   176.2979, -1372.6710])\n\n\nIl n‚Äôy a plus qu‚Äô√† it√©rer !\n\n%%time\n## Run the optimization\nnum_iterations = 100\nloss_vector = torch.empty(num_iterations)\n\nfor i in range(num_iterations):\n    loss_vector[i] = calc_loss().item()\n    optimizer.step()\n\nCPU times: user 85.4 ms, sys: 0 ns, total: 85.4 ms\nWall time: 85.2 ms\n\n\nOn v√©rifie que l‚Äôoptimisation s‚Äôest bien pass√©e (ie que l‚Äôon a minimis√© la fonction de perte)\n\n## How does the loss function behave ?\nplt.plot(range(1, num_iterations + 1), loss_vector)\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iterations')\nplt.show()\n\n## Are the gradients at 0 ?\nTheta.grad\n\n\n\n\ntensor([ 3.7193e-05,  4.4323e-05, -2.5496e-05, -6.4963e-05, -6.7316e-05,\n         9.8318e-05,  6.5755e-06, -2.4864e-05,  2.1660e-05, -5.0762e-05,\n         5.5040e-06,  5.3406e-05])\n\n\net que le r√©sultat est comparable √† la solution classique obtenue par OLS :\n\n# Ajuster un mod√®le de r√©gression lin√©aire avec scikit-learn\nregressor = LinearRegression(fit_intercept=False)\nregressor.fit(X, Y)\n\n# Obtenir les coefficients du mod√®le\nbeta_hat = regressor.coef_\n\n# Afficher les coefficients et tracer une ligne y = x\nprint(\"Coefficients du mod√®le de r√©gression lin√©aire :\\n\", beta_hat)\nprint(\"Coefficients de Theta :\\n\", Theta[:11].detach().numpy().tolist())\n\n# Tracer la ligne y = x pour la comparaison\nplt.scatter(beta_hat, Theta[:11].detach().numpy().tolist())\nplt.plot([beta_hat.min(), beta_hat.max()], [beta_hat.min(), beta_hat.max()], color='red', linestyle='--')\nplt.xlabel('Coefficients du mod√®le de r√©gression lin√©aire')\nplt.ylabel('Coefficients de Theta')\nplt.title('Comparaison des coefficients')\nplt.show()\n\n# Calculer la variance des r√©sidus\nresiduals = Y - torch.matmul(X, torch.tensor(beta_hat).t())\nsigma_squared_lm = np.var(residuals.detach().numpy())\nsigma_squared_theta = Theta[11]\n\nprint(\"Variance du mod√®le de r√©gression lin√©aire :\", sigma_squared_lm)\nprint(\"Variance de Theta[12] :\", sigma_squared_theta.item())\n\nCoefficients du mod√®le de r√©gression lin√©aire :\n [ 1.7637296  -0.32114202  1.4978627  -0.11171199  0.4011397  -0.06434376\n  0.20324951 -0.2590317   0.98098207 -0.7663114  -0.64790714]\nCoefficients de Theta :\n [1.7637280225753784, -0.32114285230636597, 1.4978631734848022, -0.1117125004529953, 0.40113937854766846, -0.06434360891580582, 0.20324911177158356, -0.25903084874153137, 0.9809806942939758, -0.7663116455078125, -0.6479087471961975]\nVariance du mod√®le de r√©gression lin√©aire : 1.2505516\nVariance de Theta[12] : 1.1182799339294434"
  },
  {
    "objectID": "exams.html",
    "href": "exams.html",
    "title": "Nouveaut√©s {learnr} et {exams}",
    "section": "",
    "text": "Introduction\nNous allons ici discuter du package {exams} qui permet de cr√©er des feuilles d‚Äôexamens (papier ou en ligne).\n\n\nexams\n{exams} est un package R disponible sur le CRAN. Il permet de construire des examens de mani√®re automatique au format markdown ou LaTeX, incluant des chunks de code R dynamiques. Comme pour {learnr} les exercices peuvent √™tre √† choix multiples ou simples, des probl√®mes arithm√©tiques, du code‚Ä¶\nhttps://www.r-exams.org/\nUn examen exams a plusieurs sorties possibles:\n\nfichiers autonomes : PDF, HTML, Docx, ODT, ‚Ä¶\nfichiers dynamiques: Moodle XML, QTI 1.2, QTI 2.1, Blackboard, Canvas, OpenOLAT, ARSnova, and TCExam\n\nIl est possible de scanner les feuilles d‚Äôexamens imprim√©es et de les √©valuer automatiquement avec l‚Äôoutil NOPS.\nUne autre option int√©ressante, pour r√©duire le risque de triche, {exams} propose un m√©canisme de variations al√©atoires des exercices:\n\nm√©lange de l‚Äôordre des questions\nm√©lange des r√©ponses possibles pour les QCMs\nm√©lange des donn√©es des exercices\n\nIl est √©galement possible de combiner {exams} avec un tutoriel {learnr}: https://www.r-exams.org/tutorials/exams2learnr/.\n\n\nR√©f√©rences\n\nhttps://www.r-exams.org/\nhttps://www.r-exams.org/tutorials/\nhttps://www.r-exams.org/intro/dynamic/"
  },
  {
    "objectID": "torch_Python-PLN.html",
    "href": "torch_Python-PLN.html",
    "title": "PLN version Python",
    "section": "",
    "text": "Comme vous pourrez le constater, les syntaxtes {torch} et Pytorch sont tr√®s proches.\n\n\nOn charge le jeu de donn√©es oaks contenu dans le package python pyPLNmodels\n\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\noaks = load_oaks()\nY = oaks['counts']\nO = np.log(oaks['offsets'])\nX = np.ones([Y.shape[0],1])\n\nPour r√©f√©rence, on optimise avec le package d√©di√© (qui utilise pytorch et l‚Äôoptimiseur Rprop.\n\npln = Pln.from_formula(\"counts ~ 1 \", data = oaks, take_log_offsets = True)\n%timeit pln.fit()\n\nFitting a Pln model with full covariance model.\nInitialization ...\nInitialization finished\nTolerance 0.001 reached in 264 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 265 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 299 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 300 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 332 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 347 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 362 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 371 iterations\nThe slowest run took 38.27 times longer than the fastest. This could mean that an intermediate result is being cached.\n60.8 ms ¬± 50.5 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n\nimport torch\nimport numpy as np\nimport math\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN() :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    ELBO_list : list\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array) : \n        self.Y = torch.tensor(Y)\n        self.O = torch.tensor(O)\n        self.X = torch.tensor(X)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad = True)\n        self.S = torch.full(Y.shape, 1.0, requires_grad = True)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad = True)\n        self.Sigma = torch.eye(self.p)\n        self.Omega = torch.eye(self.p)\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega) +  torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2)) - .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega) + .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n      self.ELBO = np.zeros(N_iter)\n      optimizer = torch.optim.Rprop([self.B, self.M, self.S], lr = lr)\n      objective0 = np.infty\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n        \n        if (abs(objective0 - objective)/abs(objective) &lt; tol):\n          self.ELBO = self.ELBO[0:i]\n          break\n        else:\n          objective0 = objective\n\n\n\n\nTestons notre impl√©mentation simple de PLN utilisant:\n\nmyPLN = PLN(Y, O, X)\n%timeit myPLN.fit(50, lr = 0.1, tol = 1e-8)\nplt.plot(np.log(-myPLN.ELBO))\n\n283 ms ¬± 5.41 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n```"
  },
  {
    "objectID": "torch_Python-PLN.html#pln-with-pytorch",
    "href": "torch_Python-PLN.html#pln-with-pytorch",
    "title": "PLN version Python",
    "section": "",
    "text": "Comme vous pourrez le constater, les syntaxtes {torch} et Pytorch sont tr√®s proches.\n\n\nOn charge le jeu de donn√©es oaks contenu dans le package python pyPLNmodels\n\nimport pyPLNmodels\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyPLNmodels.models import PlnPCAcollection, Pln\nfrom pyPLNmodels.oaks import load_oaks\noaks = load_oaks()\nY = oaks['counts']\nO = np.log(oaks['offsets'])\nX = np.ones([Y.shape[0],1])\n\nPour r√©f√©rence, on optimise avec le package d√©di√© (qui utilise pytorch et l‚Äôoptimiseur Rprop.\n\npln = Pln.from_formula(\"counts ~ 1 \", data = oaks, take_log_offsets = True)\n%timeit pln.fit()\n\nFitting a Pln model with full covariance model.\nInitialization ...\nInitialization finished\nTolerance 0.001 reached in 264 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 265 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 299 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 300 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 332 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 347 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 362 iterations\nFitting a Pln model with full covariance model.\nTolerance 0.001 reached in 371 iterations\nThe slowest run took 38.27 times longer than the fastest. This could mean that an intermediate result is being cached.\n60.8 ms ¬± 50.5 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n\nimport torch\nimport numpy as np\nimport math\n\ndef _log_stirling(integer: torch.Tensor) -&gt; torch.Tensor:\n    integer_ = integer + (integer == 0)  # Replace 0 with 1 since 0! = 1!\n    return torch.log(torch.sqrt(2 * np.pi * integer_)) + integer_ * torch.log(integer_ / math.exp(1))\n\nclass PLN() :\n    Y : torch.Tensor\n    O : torch.Tensor\n    X : torch.Tensor\n    n : int\n    p : int\n    d : int\n    M : torch.Tensor\n    S : torch.Tensor\n    B : torch.Tensor\n    Sigma : torch.Tensor\n    Omega : torch.Tensor\n    ELBO_list : list\n\n      ## Constructor\n    def __init__(self, Y: np.array, O: np.array, X: np.array) : \n        self.Y = torch.tensor(Y)\n        self.O = torch.tensor(O)\n        self.X = torch.tensor(X)\n        self.n, self.p = Y.shape\n        self.d = X.shape[1]\n        ## Variational parameters\n        self.M = torch.full(Y.shape, 0.0, requires_grad = True)\n        self.S = torch.full(Y.shape, 1.0, requires_grad = True)\n        ## Model parameters\n        self.B = torch.zeros(self.d, self.p, requires_grad = True)\n        self.Sigma = torch.eye(self.p)\n        self.Omega = torch.eye(self.p)\n\n    def get_Sigma(self) :\n      return 1/self.n * (self.M.T @ self.M + torch.diag(torch.sum(self.S**2, dim = 0)))\n\n    def get_ELBO(self): \n      S2 = torch.square(self.S)\n      XB = self.X @ self.B\n      A = torch.exp(self.O + self.M + XB + S2/2)\n\n      elbo = self.n/2 * torch.logdet(self.Omega) +  torch.sum(- A + self.Y * (self.O + self.M + XB) + .5 * torch.log(S2)) - .5 * torch.trace(self.M.T @ self.M + torch.diag(torch.sum(S2, dim = 0)) @ self.Omega) + .5 * self.n * self.p  - torch.sum(_log_stirling(self.Y))\n      return elbo\n\n    def fit(self, N_iter, lr, tol = 1e-8) :\n      self.ELBO = np.zeros(N_iter)\n      optimizer = torch.optim.Rprop([self.B, self.M, self.S], lr = lr)\n      objective0 = np.infty\n      for i in range(N_iter):\n        ## reinitialize gradients\n        optimizer.zero_grad()\n\n        ## compute current ELBO\n        loss = - self.get_ELBO()\n\n        ## backward propagation and optimization\n        loss.backward()\n        optimizer.step()\n\n        ## update parameters with close form\n        self.Sigma = self.get_Sigma()\n        self.Omega = torch.inverse(self.Sigma)\n\n        objective = -loss.item()\n        self.ELBO[i] = objective\n        \n        if (abs(objective0 - objective)/abs(objective) &lt; tol):\n          self.ELBO = self.ELBO[0:i]\n          break\n        else:\n          objective0 = objective\n\n\n\n\nTestons notre impl√©mentation simple de PLN utilisant:\n\nmyPLN = PLN(Y, O, X)\n%timeit myPLN.fit(50, lr = 0.1, tol = 1e-8)\nplt.plot(np.log(-myPLN.ELBO))\n\n283 ms ¬± 5.41 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\n\n\n\n```"
  },
  {
    "objectID": "torch_Python_R_ResNet.html",
    "href": "torch_Python_R_ResNet.html",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "",
    "text": "Le but est de comparer la syntaxe utilis√©e par les deux langages, seuls les exemples en R sont ex√©cut√©s (difficult√©s de faire un quarto avec deux langages, voir issue ici ou de faire tourner pytorch avec {reticulate}). L‚Äôexemple d‚Äôapplication est un ResNet.\nPour charger installer la biblioth√®que, en python, plusieurs possibilit√©s sont donn√©es sur le site web officiel. Vous pouvez utiliser pip ou conda, avec ou sans cuda. Pour R, cela a d√©j√† √©t√© fait √† la session 2022 de finistR.\n\ninstall.packages(torch)\ntorch::install_torch() ## si vous avez un GPU compatible avec CUDA\n## torch::install_torch(type = \"cpu\") ## sinon\n\nUn bon ouvrage pour d√©marrer : Deep Learning and Scientific Computing with R torch."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#intro",
    "href": "torch_Python_R_ResNet.html#intro",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "",
    "text": "Le but est de comparer la syntaxe utilis√©e par les deux langages, seuls les exemples en R sont ex√©cut√©s (difficult√©s de faire un quarto avec deux langages, voir issue ici ou de faire tourner pytorch avec {reticulate}). L‚Äôexemple d‚Äôapplication est un ResNet.\nPour charger installer la biblioth√®que, en python, plusieurs possibilit√©s sont donn√©es sur le site web officiel. Vous pouvez utiliser pip ou conda, avec ou sans cuda. Pour R, cela a d√©j√† √©t√© fait √† la session 2022 de finistR.\n\ninstall.packages(torch)\ntorch::install_torch() ## si vous avez un GPU compatible avec CUDA\n## torch::install_torch(type = \"cpu\") ## sinon\n\nUn bon ouvrage pour d√©marrer : Deep Learning and Scientific Computing with R torch."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#appel-des-fonctions",
    "href": "torch_Python_R_ResNet.html#appel-des-fonctions",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "Appel des fonctions",
    "text": "Appel des fonctions\nEn python, un premier exemple serait d√©j√† d‚Äôimporter la biblioth√®que et de cr√©er un tensor :\nimport torch\nt1 = torch.tensor(1)\nt1\nDonnera en R :\n\nlibrary(torch)\nt1 &lt;- torch_tensor(1)\nt1\n\ntorch_tensor\n 1\n[ CPUFloatType{1} ]\n\n\nOn comprend que la convention de nommage garde torch_ en pr√©fix de toutes les fonctions impl√©ment√©es."
  },
  {
    "objectID": "torch_Python_R_ResNet.html#construction-dun-r√©seau-de-neurone-exemple-dun-resnet",
    "href": "torch_Python_R_ResNet.html#construction-dun-r√©seau-de-neurone-exemple-dun-resnet",
    "title": "ResNet : comparaison {torch} et pytorch",
    "section": "Construction d‚Äôun r√©seau de neurone, exemple d‚Äôun ResNet",
    "text": "Construction d‚Äôun r√©seau de neurone, exemple d‚Äôun ResNet\n\nChargement des donn√©es\nOn va utiliser torchvision pour importer un jeu de donn√©es connu (des images annot√©es). On veut appliquer des transformations sur le jeu de test, mais h√©las tout n‚Äôest pas encore impl√©ment√©. On commente les transformations pas encore implement√©es.\ntransform = transforms.Compose([\n    #transforms.Pad(4),\n    #transforms.RandomHorizontalFlip(),\n    #transforms.RandomCrop(32),\n    transforms.ToTensor()])\n\ntransform &lt;- function(img) {\n  # img &lt;- torchvision::transform_pad(img, 4) # pas impl√©ment√©\n  # img &lt;- torchvision::transform_random_horizontal_flip(img) # pas impl√©ment√©\n  # img &lt;- torchvision::transform_random_crop(img, 32) # bug sur la taille des images\n  img &lt;- torchvision::transform_to_tensor(img)\n  return(img)\n}\n\nVoici le code pour charger les donn√©es en python et R :\nnum_samples = 1000\n\ntrainData = torchvision.datasets.CIFAR10(root=\"./data\",\n                                         train=True,\n                                         transform=transform,\n                                         download=True)\n\ntestData = torchvision.datasets.CIFAR10(root=\"./data\",\n                                        train=False,\n                                        transform=transforms.ToTensor())\n\ntrainLoader = torch.utils.data.DataLoader(\n    dataset=Subset(trainData, range(num_samples)),\n    batch_size=256,\n    shuffle=True)\n\ntestLoader = torch.utils.data.DataLoader(\n    dataset=Subset(testData, range(num_samples)),\n    batch_size=256,\n    shuffle=False)\n\nnum_samples = 1000\n\ntrain_data &lt;- torchvision::cifar10_dataset(\n  root = \"./data\",\n  train = TRUE,\n  transform = transform,\n  download = TRUE\n)\n\ntest_data &lt;- torchvision::cifar10_dataset(\n  root = \"./data\",\n  train = FALSE,\n  transform = torchvision::transform_to_tensor\n)\n\ntrain_loader &lt;- dataloader(\n  dataset = dataset_subset(train_data, 1:num_samples),\n  batch_size = 256,\n  shuffle = TRUE\n)\n\ntest_loader &lt;- dataloader(\n  dataset = dataset_subset(test_data, 1:num_samples),\n  batch_size = 256,\n  shuffle = FALSE\n)\n\n\n\nConstruction d‚Äôun block residual\nPour d√©finir notre block residual, on cr√©e une classe torch.nn.Module et on y d√©finit deux m√©thodes : __init__ et forward : qui h√©rite de torch.nn.Module.\ndef align(num_in, num_out, stride):\n    if num_in != num_out or stride &gt; 1:\n        return nn.Sequential(\n            nn.Conv2d(\n                num_in, num_out, kernel_size=3, stride=stride, padding=1, bias=False\n                ),\n            nn.BatchNorm2d(num_out)\n            )\n    else:\n        return lambda x: x\n\nclass ResBlock(nn.Module):\n    def __init__(self, num_in, num_out, stride):\n        super(ResBlock, self).__init__()\n        self.align = align(num_in, num_out, stride)\n        self.conv1 = nn.Conv2d(num_in, num_out, kernel_size=3,\n                            stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(num_out)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(num_out, num_out, kernel_size=3,\n                            stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(num_out)\n\n    def forward(self, x):\n        o = self.conv1(x)\n        o = self.bn1(o)\n        o = self.relu(o)\n        o = self.conv2(o)\n        o = self.bn2(o)\n        o = o + self.align(x)\n        o = self.relu(o)\n        return o\nDe la m√™me mani√®re, on peut cr√©er un objet nn_module en R et y sp√©cifier init et forward :\n\nalign &lt;- function(num_in, num_out, stride) {\n  if (num_in != num_out || stride &gt; 1) {\n    return(nn_sequential(\n      nn_conv2d(\n        num_in, num_out,\n        kernel_size = 3, stride = stride, padding = 1,\n        bias = FALSE\n      ),\n      nn_batch_norm2d(num_out)\n    ))\n  } else {\n    return(function(x) x)\n  }\n}\n\nres_block &lt;- nn_module(\n  initialize = function(num_in, num_out, stride) {\n    self$align &lt;- align(num_in, num_out, stride)\n    self$conv1 &lt;- nn_conv2d(num_in, num_out,\n      kernel_size = 3,\n      stride = stride, padding = 1, bias = FALSE\n    )\n    self$bn1 &lt;- nn_batch_norm2d(num_out)\n    self$relu &lt;- nn_relu(inplace = TRUE)\n    self$conv2 &lt;- nn_conv2d(num_out, num_out,\n      kernel_size = 3,\n      stride = 1, padding = 1, bias = FALSE\n    )\n    self$bn2 &lt;- nn_batch_norm2d(num_out)\n  },\n  forward = function(x) {\n    o &lt;- self$conv1(x)\n    o &lt;- self$bn1(o)\n    o &lt;- self$relu(o)\n    o &lt;- self$conv2(o)\n    o &lt;- self$bn2(o)\n    o &lt;- o + self$align(x)\n    o &lt;- self$relu(o)\n    return(o)\n  }\n)\n\n\n\nConstructeur ResNet\nPour construire notre ResNet, on veut cr√©er des block residuals en cha√Æne. En python, on le fait de la mani√®re suivante (toujours en utilisant torch.nn.Module) :\ndef buildResBlocks(num_in, num_out, stride, num_blocks):\n    blocks = [ResBlock(num_in, num_out, stride)]\n    for _ in range(1, num_blocks):\n        blocks.append(ResBlock(num_out, num_out, 1))\n    return nn.Sequential(*blocks)\n\nclass ResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet, self).__init__()\n        self.blocks0 = nn.Sequential(\n            nn.Conv2d(\n                3, 16, kernel_size=3,\n                stride=1, padding=1, bias=False\n                ),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True)\n            )\n        self.blocks1 = buildResBlocks(16, 16, 1, 2)\n        self.blocks2 = buildResBlocks(16, 32, 2, 2)\n        self.blocks3 = buildResBlocks(32, 64, 2, 2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        n = x.shape[0]\n        o = self.blocks0(x)\n        o = self.blocks1(o)\n        o = self.blocks2(o)\n        o = self.blocks3(o)\n        o = self.avgpool(o)\n        o = self.fc(o.reshape(n, -1))\n        return o\nEn R, cela donne :\n\nbuild_res_blocks &lt;- function(num_in, num_out, stride, num_blocks) {\n  blocks &lt;- list(res_block(num_in, num_out, stride))\n  for (i in 2:num_blocks) {\n    blocks[[i]] &lt;- res_block(num_out, num_out, 1)\n  }\n  return(do.call(nn_sequential, blocks))\n}\n\nres_net &lt;- nn_module(\n  initialize = function(num_classes) {\n    self$blocks0 &lt;- nn_sequential(\n      nn_conv2d(\n        3,\n        16,\n        kernel_size = 3,\n        stride = 1,\n        padding = 1,\n        bias = FALSE\n      ),\n      nn_batch_norm2d(16),\n      nn_relu(inplace = TRUE)\n    )\n    self$blocks1 &lt;- build_res_blocks(16, 16, 1, 2)\n    self$blocks2 &lt;- build_res_blocks(16, 32, 2, 2)\n    self$blocks3 &lt;- build_res_blocks(32, 64, 2, 2)\n    self$avgpool &lt;- nn_avg_pool2d(kernel_size = 8)\n    self$fc &lt;- nn_linear(64, num_classes)\n  },\n  forward = function(x) {\n    n &lt;- dim(x)[1]\n    o &lt;- self$blocks0(x)\n    o &lt;- self$blocks1(o)\n    o &lt;- self$blocks2(o)\n    o &lt;- self$blocks3(o)\n    o &lt;- self$avgpool(o)\n    o &lt;- torch_flatten(o, start_dim = 2)\n    o &lt;- self$fc(o)\n    return(o)\n  }\n)\n\n\n\nInstanciation mod√®le et optimiseurs\nPartie un peu plus rapide et simple, quasi identique dans les deux cas :\ndevice = \"cpu\"\nmodel = ResNet(10).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ndevice = \"cpu\"\nmodel &lt;- res_net$new(10)$to(device = device)\nmodel\n\nAn `nn_module` containing 195,738 parameters.\n\n‚îÄ‚îÄ Modules ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚Ä¢ blocks0: &lt;nn_sequential&gt; #464 parameters\n‚Ä¢ blocks1: &lt;nn_sequential&gt; #9,344 parameters\n‚Ä¢ blocks2: &lt;nn_sequential&gt; #37,184 parameters\n‚Ä¢ blocks3: &lt;nn_sequential&gt; #148,096 parameters\n‚Ä¢ avgpool: &lt;nn_avg_pool2d&gt; #0 parameters\n‚Ä¢ fc: &lt;nn_linear&gt; #650 parameters\n\n\n\noptimizer &lt;- optim_adam(model$parameters, lr = 0.001)\noptimizer\n\n&lt;optim_adam&gt;\n  Inherits from: &lt;torch_optimizer&gt;\n  Public:\n    add_param_group: function (param_group) \n    clone: function (deep = FALSE) \n    defaults: list\n    initialize: function (params, lr = 0.001, betas = c(0.9, 0.999), eps = 1e-08, \n    load_state_dict: function (state_dict, ..., .refer_to_state_dict = FALSE) \n    param_groups: list\n    state: State, R6\n    state_dict: function () \n    step: function (closure = NULL) \n    zero_grad: function () \n  Private:\n    step_helper: function (closure, loop_fun) \n\n\n\n\nApprentissage\ndef train():\n    for epoch in range(1, 11):\n        for i, (x, y) in enumerate(trainLoader):\n            (x, y) = x.to(device), y.to(device)\n            o = model(x)\n            loss = F.cross_entropy(o, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if i % 100 == 0:\n                 print(\"Epoch: {}\\tLoss: {}\".format(epoch, loss.item()))\n\ntrain &lt;- function() {\n  for (epoch in 1:10) {\n    i &lt;- 0\n    coro::loop(for (batch in train_loader) {\n      x &lt;- batch[[1]]\n      y &lt;- batch[[2]]\n      o &lt;- model(x)\n      loss &lt;- nnf_cross_entropy(o, y)\n\n      optimizer$zero_grad()\n      loss$backward()\n      optimizer$step()\n      if (i %% 100 == 0) {\n        cat(sprintf(\"Epoch: %d\\tLoss: %.4f\\n\", epoch, loss$item()))\n      }\n      i &lt;- i + 1\n    })\n  }\n}\n\n\n\nComparaison temps de calcul\ntic = time.time()\ntrain()\nprint(time.time()-tic, \"s\")\n\ntic &lt;- system.time(\n  train()\n)\n\nEpoch: 1    Loss: 2.4415\nEpoch: 2    Loss: 1.9300\nEpoch: 3    Loss: 1.8064\nEpoch: 4    Loss: 1.7098\nEpoch: 5    Loss: 1.5846\nEpoch: 6    Loss: 1.4819\nEpoch: 7    Loss: 1.4359\nEpoch: 8    Loss: 1.2887\nEpoch: 9    Loss: 1.2151\nEpoch: 10   Loss: 1.1323\n\ntic\n\n   user  system elapsed \n 74.253   4.946  52.626 \n\n\nSur mon ordinateur : - python : 27.6s (elapsed) - R : 33.1s\nDes temps de calcul tr√®s comparables !\n\n\nPr√©cision\nPour tester la pr√©cision :\nn, N = 0, 0\nwith torch.no_grad():\n    for (x, y) in testLoader:\n        (x, y) = x.to(device), y.to(device)\n        o = model(x)\n        _, yÃÇ = torch.max(o, 1)\n        N += y.size(0)\n        n += torch.sum(yÃÇ == y).item()\n    print(\"Accuracy: {}\".format(n/N))\n\nwith_no_grad({\n  n_tests_ok &lt;- 0\n  n_tests &lt;- 0\n  coro::loop(for (batch in test_loader) {\n    x &lt;- batch[[1]]\n    y &lt;- batch[[2]]\n    o &lt;- model(x)\n    yest &lt;- torch_max(o, dim = 2)[[2]]\n    n_tests &lt;- n_tests + y$shape\n    n_tests_ok &lt;- n_tests_ok + torch_sum(y == yest)$item()\n  })\n  cat(\"Accuracy\", n_tests_ok / n_tests, \"\\n\")\n})\n\nAccuracy 0.414 \n\n\nLes deux codes donnent des r√©sultats semblables !"
  }
]