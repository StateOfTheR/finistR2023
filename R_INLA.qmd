---
title: "R INLA"
format: html
toc: true
author: 
  - Pierre Barbillon
  - Isabelle Sanchez
  - Jérémy Lamouroux
  - Félix Cheysson
  - Théodore Vanrenterghem
---

## Introduction

Présentation de la methodologie INLA (integrated nested Laplace approximation) en utilisant les package {INLA} et sa surcouche {inlabru}.

L'approximation de Laplace intégrée et imbriquée (INLA) est une approche de l'inférence statistique pour les modèles de champs aléatoires gaussiens latents (GMRF) introduite par Rue et Martino (2006). Elle fournit une alternative rapide et déterministe au MCMC qui était l'outil standard pour l'inférence de tels modèles. Le principal avantage de l'approche INLA par rapport à la MCMC est qu'elle est beaucoup plus rapide à calculer.


{inlabru} est une surcouche du package INLA, qui facilite l'utilisation du package R {INLA} en simplifiant la syntaxe. Ce package intègre deux extensions : 
- Modèles de type GAM (pour intégrer des prédicteurs non linéaires)
- Processus de Cox log-Gaussien  pour modéliser des processus univariés et spatiaux basés sur des données de comptages.


Sources : 

-   <https://www.r-inla.org/home>

-   <https://inla.r-inla-download.org/r-inla.org/doc/inla-manual/inla-manual.pdf>

-   <https://sites.google.com/inlabru.org/inlabru/home>

-   <https://inlabru-org.github.io/inlabru/index.html>

## Installation de INLA

```{r}
#| eval: false
# Base de R INLA
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
# inlabru wrapper
install.packages("inlabru")
```


## Utilisation

### Exemple 1

#### Setup

```{r loading}
#| warning: false
#| message: false
# Chargement des packages
library(inlabru)
library(lme4) # pour comparer avec l'approche frequentiste 
```

Le dataset `awards` contient le nombre de réussites (`num_awards`) en math (`math`) pour une classe de 200 élèves. La réponse mesurée étant un comptage, nous devons spécifier un modèle généralisé avec fonction de lien Poisson. 

```{r data-set}
# Chargement des donnees
load("data/awards.RData")
head(awards)
```

La fonction `bru_options_set` permet de fixer des options sur des paramètres spécifiques à INLA.

```{r set-options}
bru_options_set(bru_verbose = TRUE,
                control.compute = list(dic = TRUE, waic = TRUE))
```

On peut récupérer ces paramètres avec :

```{r get-options}
#| eval: false
bru_options_get()
```

#### Application

```{r first-apply}
# Formulation du modele
cmp1 <- num_awards ~ math + 1
# Application de la formule avec un modèle de Poisson
fit.glm.bru <- bru(cmp1, family = "poisson", data = awards)
summary(fit.glm.bru)
```

#### Comparaison avec un GLM

```{r glm1}
cmp2 <- num_awards ~ math
fit2.glm <- glm(cmp2, family="poisson", data = awards)
summary(fit2.glm)
```

Les réponses sont proches. 

#### Intégration d'un effet aléatoire

Pour prendre en compte le problème classique de surdispersion dans les données de comptages, il peut être intéréssant de rajouter un effet aléatoire de la manière suivante.

```{r effet-aleatoire}
cmp3 <- num_awards ~ math + 1 + rand.eff(map = 1:200, model = "iid", n = 200)

fit3.glmm.bru <- bru(cmp3, family = "poisson", data = awards)
summary(fit3.glmm.bru)
```

#### Comparaison avec l'approche fréquentiste 

```{r freq2}
cmp4<- num_awards ~ math + (1|id)
fit4.glmm<-glmer(cmp4, family = poisson, data = awards)
summary(fit4.glmm)
```

On remarque que les résultats sont un peu moins comparables. Pour rendre les résultats comparable, il suffit de modifier les options de modélisation de l'effet aléatoire. 

```{r effet-aleatoire-2}
cmp5 <- num_awards ~ math + 1 + rand.eff(map = 1:200, model = "iid", n = 200,
                                                 hyper=list(prec=list(param=c(10,0.1),
                                                                      prior="pc.prec")))
fit5.glmm.bru <- bru(cmp5, family = "poisson", data = awards )
summary(fit5.glmm.bru)
```

### Exemple 2


