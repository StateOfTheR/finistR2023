{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"FinistR : bootcamp R à Roscoff\"\n",
        "subtitle: \"Différentiation automatique: pytorch\"\n",
        "date: \"du 21 au 25 août 2023\"\n",
        "execute: \n",
        "    freeze: auto\n",
        "output: \n",
        "  html_document:\n",
        "   toc: true\n",
        "   toc_float: true\n",
        "---"
      ],
      "id": "14759405"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cette page constitue une traduction en Python avec pytorch de la [page équivalente](https://stateofther.github.io/finistR2022/autodiff.html) produite avec {{torch}} lors de FinistR 2022 \n",
        "\n",
        "## Installation \n",
        "\n",
        "Une façon (parmi d'autres) d'avoir une installation fonctionnelle de torch consiste à l'installer via conda. La [page officielle](https://pytorch.org/get-started/locally/) est très bien documentée et fournit toutes les instructions nécessaires. La solution adoptée ici consiste à créer un environnement conda (nommé torch) pour y installer torch (en version CPU). \n",
        "\n",
        "\n",
        "```{bash}\n",
        "#| eval: false\n",
        "conda create -n torch\n",
        "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
        "conda install pandas matplotlib scikit-learn jupyter\n",
        "```\n",
        "\n",
        "\n",
        "Il suffit alors d'activer l'environnement torch pour produire le html à partir du qmd\n",
        "\n",
        "\n",
        "```{bash}\n",
        "#| eval: false\n",
        "conda activate torch\n",
        "quarto render my_document.qmd --to html\n",
        "```\n",
        "\n",
        "\n",
        "## Exploration de {{torch}} pour la différentiation automatique\n"
      ],
      "id": "ed1c8f73"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "id": "e8072820",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principe du calcul de gradient\n",
        "\n",
        "{{torch}} fonctionne avec ses propres types numériques, qu’il faut créer avec la fonction `torch.tensor()` et ses propres fonctions `torch.*()`. Considérons un exemple très simple: $x \\mapsto x^2$\n"
      ],
      "id": "48283010"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = torch.tensor(3)\n",
        "y = torch.square(x)"
      ],
      "id": "c2804bb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y"
      ],
      "id": "7ceac078",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On va pouvoir calculer $\\frac{dy}{dx}$ en définissant `x` avec l'argument `require_grad = True`. Cet argument va spécifier que 'x' est entrainable et va démarrer l'enregistrement par autograd des opérations sur ce tenseur.\n",
        "\n",
        "Autograd est un module de `torch` qui permet de collecter les gradients. Il le fait en enregistrant des données (tenseurs) et toutes les opérations exécutées dans un graphe acyclique dirigé dont les feuilles sont les tenseurs d'entrée et les racines les tenseurs de sorties. Ces opérations sont stockées comme des fonctions et au moment du calcul des gradients, sont appliquées depuis le noeud de sortie en 'backpropagation' le long du réseau.\n",
        "\n",
        "**Attention**, torch ne peut stocker un gradient que pour des valeurs numériques (`float`), pas pour des entiers. \n"
      ],
      "id": "2410ed6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = torch.tensor(2.0, requires_grad = True)\n",
        "x"
      ],
      "id": "a74e30d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On remarque que `x` possède désormais un champ `grad` (même si ce dernier n'est pas encore défini).\n"
      ],
      "id": "21506570"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.grad"
      ],
      "id": "7b12ee4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsqu'on calcule $y = x^2$, ce dernier va également hériter d'un nouveau champ `$grad_fn`:\n"
      ],
      "id": "0d11f809"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = torch.log(torch.square(x))\n",
        "y\n",
        "y.grad_fn"
      ],
      "id": "fd7a64e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "qui indique comment calculer le gradient en utilisant la dérivée des fonctions composées:\n",
        "\n",
        "$$\n",
        "(g\\circ f)'(x) = f'(x) \\times g'(f(x))\n",
        "$$\n",
        "\n",
        "et les fonctions\n",
        "\n",
        "$$\n",
        "\\frac{dx^2}{dx} = 2x \\quad \\frac{d \\log(x)}{dx} = \\frac{1}{x}\n",
        "$$\n",
        "\n",
        "Le calcul effectif du gradient est déclenché lors de l'appel à la méthode `.backward()` de `y` et est stocké dans le champ `.grad` de `x`.\n"
      ],
      "id": "d17d3494"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.grad ## gradient non défini\n",
        "y.backward() \n",
        "x.grad ## gradient défini = 1"
      ],
      "id": "bdc97130",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On a bien:\n",
        "\n",
        "$$\n",
        "\\frac{dy}{dx} = \\underbrace{\\frac{dy}{dz}}_{\\log}(z) \\times \\underbrace{\\frac{dz}{dx}}_{\\text{power}}(x) = \\frac{1}{4} \\times 2*2 = 1\n",
        "$$ \n",
        "\n",
        "Intuitivement au moment du calcul de `y`, `torch` construit un graphe computationnel qui lui permet d'évaluer **numériquement** $y$ et qui va **également** servir pour calculer $\\frac{dy}{dz}$ au moment de l'appel à la fonction `.backward()` issue du module autograd.\n",
        "\n",
        "Essayons de reproduire le calcul dans notre exemple. Le calcul **forward** donne\n",
        "\n",
        "$$\n",
        "x = 2 \\xrightarrow{x \\mapsto x^2} z = 4 \\mapsto \\xrightarrow{x \\mapsto \\log(x)} y = \\log(4)\n",
        "$$\n",
        "\n",
        "Pour le calcul **backward**, il faut donc construire le graphe formel suivant. La première étape du graphe est accessible via `$grad_fn`\n"
      ],
      "id": "99c550f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y.grad_fn"
      ],
      "id": "146185bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "et les fonctions suivantes via `$next_functions`\n"
      ],
      "id": "b1cd84c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y.grad_fn.next_functions"
      ],
      "id": "cc96ea87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dans notre exemple, on a donc:\n",
        "\n",
        "$$\n",
        "\\frac{dy}{dy} = 1 \\xrightarrow{x \\mapsto \\text{logBackward}(x)} \\frac{dy}{dz} = \\frac{dy}{dy} \\times \\text{logBackward}(z) \\xrightarrow{x \\mapsto \\text{powerBackward}(x)} \\frac{dy}{dx} = \\frac{dy}{dz} \\times \\text{logBackward}(x)\n",
        "$$\n",
        "\n",
        "Dans cet exemple:\n",
        "\n",
        "-   $\\text{logBackward}(x) = \\frac{1}{x}$\n",
        "-   $\\text{powBackward}(x) = 2x$\n",
        "\n",
        "Et la propagation des dérivées donne donc\n",
        "\n",
        "$$\n",
        "\\frac{dy}{dy} = 1 \\to \\frac{dy}{dz} = 1 \\times \\frac{1}{4} = \\frac{1}{4} \\to \\frac{dy}{dx} = \\frac{1}{4} \\times 4 = 1\n",
        "$$\n",
        "\n",
        "Ce graphe est illustré ci-dessous pour la fonction $(x_1, x_2) \\mapsto z = sin(x_2) log(x_1 x_2)$\n",
        "\n",
        "![](https://pytorch.org/assets/images/augmented_computational_graph.png)\n",
        "\n",
        "Pour (beaucoup) plus de détails sur le graphe computationnel, on peut consulter la [documentation officielle de PyTorch](https://pytorch.org/blog/how-computational-graphs-are-executed-in-pytorch/).\n",
        "\n",
        "Il faut juste noter que dans `torch`, le graphe computationnel est construit de **façon dynamique**, au moment du calcul de `y`.\n",
        "\n",
        "## Régression logistique avec `torch`\n",
        "\n",
        "On va adopter un simple modèle de régression logistique:\n",
        "\n",
        "$$\n",
        "Y_i \\sim \\mathcal{B}(\\sigma(\\theta^T x_i)) \\quad \\text{avec} \\quad \\sigma(x) = \\frac{1}{1 + e^{x}}\n",
        "$$\n",
        "\n",
        "Le but est d'estimer $\\theta$ et éventuellement les erreurs associées. On commence par générer des données.\n"
      ],
      "id": "4f96ca4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Générer les paramètres\n",
        "torch.manual_seed(45)\n",
        "n = 100\n",
        "p = 3\n",
        "# Générer la matrice X\n",
        "X = torch.randn(n, p)\n",
        "# Générer le vecteur theta\n",
        "theta = torch.randn(3)\n",
        "# Calculer les probabilités\n",
        "probs = 1 / (1 + torch.exp(torch.mv(X, theta)))\n",
        "# Générer les observations Y en utilisant une distribution Bernoulli\n",
        "bernoulli_dist = dist.Bernoulli(probs=probs)\n",
        "Y = bernoulli_dist.sample()"
      ],
      "id": "586876a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`torch` fonctionne avec ses propres types numériques, qu'il faut créer avec la fonction `torch.tensor()`. C'est ce qu'on a fait avec les fonctions `torch.randn()` et `bernoulli_dist.sample()` mais on pourrait forcer la conversion avec `torch.tensor()`. \n"
      ],
      "id": "404cb9ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = X.clone()\n",
        "y = Y.clone()"
      ],
      "id": "a8c3a813",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On écrit ensuite la fonction de vraisemblance\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta) = \\sum_{i=1}^n y_i (\\theta^Tx_i) - \\sum_{i=1}^n log(1 + e^{\\theta^T x_i})\n",
        "$$\n"
      ],
      "id": "190a038d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def logistic_loss(theta, x, y):\n",
        "    odds = torch.mv(x, theta)\n",
        "    log_lik = torch.dot(y, odds) - torch.sum(torch.log(1 + torch.exp(odds)))\n",
        "    return -log_lik"
      ],
      "id": "20878ce3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "avant de vérifier qu'elle fonctionne:\n"
      ],
      "id": "ee30a2ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "logistic_loss(theta = theta, x = x, y = y)"
      ],
      "id": "479b16a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On veut ensuite définir une fonction objective à maximiser (qui ne dépend que de `theta`):\n"
      ],
      "id": "b7f2b9a3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def eval_loss(theta, verbose=True):\n",
        "    loss = logistic_loss(theta, x, y)\n",
        "    if verbose:\n",
        "        print(\"Theta:\", theta, \": Loss:\", float(loss))\n",
        "    return loss"
      ],
      "id": "825b6da7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "et vérifier qu'elle fonctionne\n"
      ],
      "id": "c4ab03f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "eval_loss(theta, verbose = True)"
      ],
      "id": "e37eda20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "avant de procéder à l'optimisation à proprement parler. Pour cette dernière, on commence par définir notre paramètre sous forme d'un tenseur qui va être mis à jour\n"
      ],
      "id": "e12340f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "theta_current = torch.zeros(len(theta), requires_grad=True)"
      ],
      "id": "b1b17080",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "et d'un optimiseur:\n"
      ],
      "id": "be2ce8c0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = optim.Rprop([theta_current])"
      ],
      "id": "0c214b95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On considère ici l'optimiseur Rprop (resilient backpropagation) qui ne prend pas en compte l'amplitude du gradient mais uniquement le signe de ses coordonnées (voir [ici pour une introduction pédagogique à Rprop](https://florian.github.io/rprop/)). \n",
        "\n",
        "Intuitivement, l'optimiseur a juste besoin de la valeur de $\\theta$ et de son gradient pour le mettre à jour. Mais à ce stade on ne connaît pas encore le gradient $\\nabla_\\theta \\mathcal{L}(\\mathbf{X}, \\mathbf{y}; \\theta)$\n"
      ],
      "id": "adf4f0c7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "theta_current.grad"
      ],
      "id": "bc9809e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "et il faut donc le calculer:\n"
      ],
      "id": "101c7d63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loss = eval_loss(theta_current, verbose = False)\n",
        "loss.backward()"
      ],
      "id": "7a54b141",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut vérifier que le gradient est stocké dans `theta`\n"
      ],
      "id": "9cb43660"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "theta_current.grad"
      ],
      "id": "b574fd74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "et effectuer la mise à jour avec une étape d'optimisation\n"
      ],
      "id": "3a1f079d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer.step()"
      ],
      "id": "e46c97d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut vérifier que le paramètre courant a été mis à jour.\n"
      ],
      "id": "2608a788"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "theta_current"
      ],
      "id": "1c242b51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il ne reste plus qu'à recommencer pour un nombre d'itérations donné. **Attention,** il faut réinitialiser le gradient avant de le mettre à jour, le comportement par défaut de mise à jour étant l'*accumulation* plutôt que le *remplacement*.\n"
      ],
      "id": "2177e2b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_iterations = 100\n",
        "loss_vector = []\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    optimizer.zero_grad()\n",
        "    loss = eval_loss(theta_current, verbose=False)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_vector.append(loss.item())"
      ],
      "id": "59767da9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On vérifie que la perte diminue au cours du temps.\n"
      ],
      "id": "e4f9142b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(range(1, num_iterations + 1), loss_vector)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Iterations')\n",
        "plt.show()"
      ],
      "id": "c2455ba8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On constate que notre optimiseur aboutit à peu près au même résultat que `glm()`\n"
      ],
      "id": "bfb5f87a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ajustement du modèle GLM\n",
        "model = LogisticRegression(fit_intercept=False, penalty = None)\n",
        "model.fit(X, Y)\n",
        "sklearn_coeffs = model.coef_.tolist()[0]\n",
        "\n",
        "# Comparer les valeurs obtenues avec torch et glm\n",
        "df = pd.DataFrame({\n",
        "    'torch': theta_current.detach().numpy().tolist(),\n",
        "    'sklearn': sklearn_coeffs\n",
        "})\n",
        "print(df)"
      ],
      "id": "f5138f8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Attention** la mécanique présentée ci-dessus avec `.step()` ne fonctionne pas pour certaines routines d'optimisation (BFGS, gradient conjugué) qui nécessite de calculer plusieurs fois la fonction objective. Dans ce cas, il faut définir une *closure*, qui renvoie la fonction objective, et la passer en argument à `.step()`.\n"
      ],
      "id": "8f3496ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%time\n",
        "# Remise à zéro du paramètre courant\n",
        "theta_current = torch.zeros(len(theta), requires_grad=True)\n",
        "optimizer = optim.Rprop([theta_current], lr=0.01)\n",
        "\n",
        "# Définition de la closure\n",
        "def calc_loss():\n",
        "    optimizer.zero_grad()\n",
        "    loss = eval_loss(theta_current, verbose=False)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "# Optimisation avec la closure\n",
        "num_iterations = 100\n",
        "loss_vector = []\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    loss = optimizer.step(calc_loss).item()\n",
        "    loss_vector.append(loss)"
      ],
      "id": "c2f13766",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut vérifier qu'on obtient des résultats identiques dans les deux cas d'utilisation:\n"
      ],
      "id": "e6389788"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "theta_current"
      ],
      "id": "c2ec0cd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(range(1, num_iterations + 1), loss_vector)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Iterations')\n",
        "plt.show()"
      ],
      "id": "18f6b6a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exemple de régression multivariée\n",
        "\n",
        "On considère un exemple de régression multiple, réalisé à partir du blog [torch for optimization](https://blogs.rstudio.com/ai/posts/2021-04-22-torch-for-optimization/), où l'on cherche à estimer les paramètres de moyenne ainsi que la variance par maximisation de la vraisemblance.\n",
        "\n",
        "On génère les données\n"
      ],
      "id": "199e9716"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Définir la graine aléatoire pour la reproductibilité\n",
        "torch.manual_seed(45)\n",
        "# Générer la matrice X\n",
        "n = 100\n",
        "X = torch.cat((torch.ones(n, 1), torch.randn(n, 10)), dim=1)\n",
        "# Générer le vecteur Beta.true\n",
        "Beta_true = torch.randn(11)\n",
        "# Générer la variable dépendante Y\n",
        "Y = torch.matmul(X, Beta_true) + torch.randn(n)"
      ],
      "id": "982dcbd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La fonction de perte à optimiser (ici la log-vraisemblance) va dépendre d'inputs définis comme des \"tenseurs torch\":\n"
      ],
      "id": "5336735c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Declare the parameter for the loss function\n",
        "## 11 parameters for Beta, 1 for sigma\n",
        "Theta = torch.ones(12, requires_grad = True)"
      ],
      "id": "502a59e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quelques remarques :\n",
        "\n",
        "\\- le paramètre $\\theta$ à optimiser est ici défini comme un tenseur, i.e. un objet qui va notamment stocker la valeur courante de $\\theta$. Avec l'option \"requires_grad=True\" la valeur courante du gradient de la dernière fonction appelée dépendant de $\\theta$ va aussi être stockée.\n",
        "\n",
        "\\- la matrice $X$ est aussi définie comme un tenseur, mais l'option \"requires_grad=TRUE\" n'a pas été spécifiée, le gradient ne sera donc pas stocké pour cet objet. Cette distinction est explicitée lorsque l'on affiche les deux objets:\n"
      ],
      "id": "1f61a322"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Theta[:3]\n",
        "X[:3, :3]"
      ],
      "id": "35bcb081",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La fonction de perte est ici la log-vraisemblance, elle-même définie à partir d'opérateurs torch élémentaires :\n"
      ],
      "id": "84aa83a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def LogLik():\n",
        "    n = X.shape[0]  \n",
        "    # Last term of Theta is the std\n",
        "    sigma = Theta[11]\n",
        "    log_sigma = torch.log(sigma)\n",
        "    squared_residuals = torch.norm(Y - torch.matmul(X, Theta[:11])) ** 2\n",
        "    term1 = n * log_sigma\n",
        "    term2 = squared_residuals / (2 * (sigma ** 2))\n",
        "    return term1 + term2"
      ],
      "id": "926bdcb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La fonction LogLik peut être appliquée comme une fonction R qui prendra directement en argument les valeurs courantes de X.tensor et $\\theta$, et produira en sortie un tenseur\n"
      ],
      "id": "6041efb4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "LogLik()"
      ],
      "id": "de283b7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outre la valeur courante de la fonction, ce tenseur contient la \"recette\" du graphe computationnel utilisé dans calcul backward du gradient de la fonction LogLik par rapport à $\\theta$. On peut ainsi afficher la dernière opération de ce graphe\n"
      ],
      "id": "5e822e4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "toto = LogLik()\n",
        "toto.grad_fn"
      ],
      "id": "19df7363",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "correspondant à l'addition (AddBackward) des deux termes $$  n\\times \\log(\\theta[11]) \\quad \\text{et} \\quad ||Y-X\\theta[0:10]||^2/(2*\\theta[11]^2)$$ dans le calcul de la perte. On peut afficher les opérations suivantes dans le graphe comme suit:\n"
      ],
      "id": "bc75dcfd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "toto.grad_fn.next_functions"
      ],
      "id": "df5d1c33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'étape suivante consiste à choisir la méthode d'optimisation à appliquer. L'intérêt d'utiliser le package \\`{{torch}}\\` est d'avoir accès à une large gamme de méthodes d'optimisation, on considère ici la méthode rprop qui réalise une descente de gradient à pas adaptatif et spécifique à chaque coordonnée:\n"
      ],
      "id": "3dbf6c3c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Specify the optimization parameters\n",
        "lr = 0.01\n",
        "optimizer = optim.Rprop([Theta],lr)"
      ],
      "id": "bb637287",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On décrit maintenant un pas de calcul du gradient, contenant les étapes suivantes : - réinitialisation du gradient de $\\theta$,\\\n",
        "- évaluation de la fonction de perte (avec la valeur courante de $\\theta$),\\\n",
        "- calcul backward du gradient. On inclut tout cela dans une fonction:\n"
      ],
      "id": "21310955"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Optimization step description\n",
        "def calc_loss():\n",
        "    optimizer.zero_grad()\n",
        "    value = LogLik()\n",
        "    value.backward()\n",
        "    return value"
      ],
      "id": "ee10c4d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Commençons par regarder ce que fait concrètement cette fonction. L'état courant du paramètre est le suivant:\n"
      ],
      "id": "71aec4ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Theta\n",
        "Theta.grad"
      ],
      "id": "3993bae1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On applique une première fois la fonction, et on obtient la mise à jour suivante :\n"
      ],
      "id": "a95a0a83"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "calc_loss()\n",
        "Theta\n",
        "Theta.grad"
      ],
      "id": "58b90089",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme on le voit la valeur courante du paramètre n'a pas changée, en revanche `Theta.grad` contient maintenant le gradient de la fonction de perte calculé en $\\theta$. Dans le cas où la méthode d'optimisation considérée n'a besoin que de la valeur courante du gradient et du paramètre, on peut directement faire la mise à jour de $\\theta$ :\n"
      ],
      "id": "05bf59b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer.step()\n",
        "Theta\n",
        "Theta.grad"
      ],
      "id": "e3f5b5fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il n'y a plus qu'à itérer !\n"
      ],
      "id": "fbfeb550"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%time\n",
        "## Run the optimization\n",
        "num_iterations = 100\n",
        "loss_vector = torch.empty(num_iterations)\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    loss_vector[i] = calc_loss().item()\n",
        "    optimizer.step()"
      ],
      "id": "22148c50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On vérifie que l'optimisation s'est bien passée (ie que l'on a minimisé la fonction de perte)\n"
      ],
      "id": "c010e93d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## How does the loss function behave ?\n",
        "plt.plot(range(1, num_iterations + 1), loss_vector)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Iterations')\n",
        "plt.show()\n",
        "\n",
        "## Are the gradients at 0 ?\n",
        "Theta.grad"
      ],
      "id": "bec27c6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "et que le résultat est comparable à la solution classique obtenue par OLS :\n"
      ],
      "id": "dd7a86d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ajuster un modèle de régression linéaire avec scikit-learn\n",
        "regressor = LinearRegression(fit_intercept=False)\n",
        "regressor.fit(X, Y)\n",
        "\n",
        "# Obtenir les coefficients du modèle\n",
        "beta_hat = regressor.coef_\n",
        "\n",
        "# Afficher les coefficients et tracer une ligne y = x\n",
        "print(\"Coefficients du modèle de régression linéaire :\\n\", beta_hat)\n",
        "print(\"Coefficients de Theta :\\n\", Theta[:11].detach().numpy().tolist())\n",
        "\n",
        "# Tracer la ligne y = x pour la comparaison\n",
        "plt.scatter(beta_hat, Theta[:11].detach().numpy().tolist())\n",
        "plt.plot([beta_hat.min(), beta_hat.max()], [beta_hat.min(), beta_hat.max()], color='red', linestyle='--')\n",
        "plt.xlabel('Coefficients du modèle de régression linéaire')\n",
        "plt.ylabel('Coefficients de Theta')\n",
        "plt.title('Comparaison des coefficients')\n",
        "plt.show()\n",
        "\n",
        "# Calculer la variance des résidus\n",
        "residuals = Y - torch.matmul(X, torch.tensor(beta_hat).t())\n",
        "sigma_squared_lm = np.var(residuals.detach().numpy())\n",
        "sigma_squared_theta = Theta[11]\n",
        "\n",
        "print(\"Variance du modèle de régression linéaire :\", sigma_squared_lm)\n",
        "print(\"Variance de Theta[12] :\", sigma_squared_theta.item())"
      ],
      "id": "ff992658",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}